{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frank-northwest",
   "metadata": {},
   "source": [
    "# 1. Data Generator\n",
    "- Raw Data를 읽어옴\n",
    "- 여기서 만들어진 데이터는 모델의 입력으로 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "requested-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "architectural-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawForVAEGenerator(Sequence):\n",
    "    def __init__(self, source, wav_dir, files, sourNum='s1', batch_size=10, shuffle=True):\n",
    "        self.source = source\n",
    "        self.wav_dir = wav_dir\n",
    "        self.files = files\n",
    "        self.sourNum = sourNum\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        self.sample_rate = 8000\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.source))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __audioread__(self, path, offset=0.0, duration=None, sample_rate=16000):\n",
    "        signal = librosa.load(path, sr=self.sample_rate, mono=False, offset=offset, duration=duration)\n",
    "\n",
    "        return signal[0]\n",
    "    \n",
    "    def __padding__(self, data):\n",
    "        n_batch = len(data)\n",
    "        max_len = max([d.shape[0] for d in data])\n",
    "        extrapadding = int(np.ceil(max_len / self.sample_rate) * self.sample_rate)\n",
    "        pad = np.zeros((n_batch, extrapadding))\n",
    "        \n",
    "        for i in range(n_batch):\n",
    "            pad[i, :data[i].shape[0]] = data[i]\n",
    "        \n",
    "        return np.expand_dims(pad, -1)\n",
    "        \n",
    "    def __data_generation__(self, source_list):\n",
    "        wav_list = []\n",
    "        for name in source_list:\n",
    "            name = name.strip('\\n')\n",
    "            \n",
    "            s_wav_name = self.wav_dir + self.files + '/' + self.sourNum + '/' + name\n",
    "            \n",
    "            # ------- AUDIO READ -------\n",
    "            s_wav = (self.__audioread__(s_wav_name,  offset=0.0, duration=None, sample_rate=self.sample_rate))\n",
    "            # --------------------------\n",
    "            \n",
    "            # ------- PADDING -------\n",
    "#             pad_len = max(len(samples1),len(samples2))\n",
    "#             pad_s1 = np.concatenate([s1_wav, np.zeros([pad_len - len(s1_wav)])])\n",
    "            \n",
    "#             extrapadding = ceil(len(pad_s1) / sample_rate) * sample_rate - len(pad_s1)\n",
    "#             pad_s1 = np.concatenate([pad_s1, np.zeros([extrapadding - len(pad_s1)])])\n",
    "#             pad_s2 = np.concatenate([s2_wav, np.zeros([extrapadding - len(s2_wav)])])\n",
    "            # -----------------------\n",
    "            \n",
    "            wav_list.append(s_wav)\n",
    "        \n",
    "        return wav_list, wav_list\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.source) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        source_list = [self.source[k] for k in indexes]\n",
    "        \n",
    "        if self.files is not 'tt':\n",
    "            sour, labels = self.__data_generation__(source_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in sour])\n",
    "            exp = np.expand_dims(lengths, 1)\n",
    "            exp = np.expand_dims(exp, -1) # [Batch, 1, 1] (length)\n",
    "            \n",
    "            # Padding\n",
    "            sour_pad = self.__padding__(sour) # [Batch, Time_step, Dimension(=1)]\n",
    "            label_pad = self.__padding__(labels) # [Batch, Time_step, Dimension(=1)]\n",
    "            \n",
    "            return sour_pad, np.concatenate([label_pad, exp], axis=1)\n",
    "        else:\n",
    "            sour, labels = self.__data_generation__(source_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in sour])\n",
    "            exp = np.expand_dims(lengths, 1)\n",
    "            exp = np.expand_dims(exp, -1) # [Batch, 1, 1] (length)\n",
    "            \n",
    "            # Padding\n",
    "            sour_pad = self.__padding__(sour) # [Batch, Time_step, Dimension(=1)]\n",
    "            \n",
    "            return sour_pad, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-league",
   "metadata": {},
   "source": [
    "## Data를 어떻게 읽는지에 대한 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "martial-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_DIR = './mycode/wsj0_2mix/use_this/'\n",
    "LIST_DIR = './mycode/wsj0_2mix/use_this/lists/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attached-debate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate wav file to .lst done!\n"
     ]
    }
   ],
   "source": [
    "# Directory List file create\n",
    "\n",
    "wav_dir = WAV_DIR\n",
    "output_lst = LIST_DIR\n",
    "\n",
    "for folder in ['tr', 'cv', 'tt']:\n",
    "    wav_files = os.listdir(wav_dir + folder + '/mix')\n",
    "    output_lst_files = output_lst + folder + '_wav.lst'\n",
    "    with open(output_lst_files, 'w') as f:\n",
    "        for file in wav_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "print(\"Generate wav file to .lst done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comparable-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "train_dataset = 0\n",
    "valid_dataset = 0\n",
    "test_dataset = 0\n",
    "\n",
    "name_list = []\n",
    "for files in ['tr', 'cv', 'tt']:\n",
    "    # --- Lead lst file ---\"\"\n",
    "    output_lst_files = LIST_DIR + files + '_wav.lst'\n",
    "    fid = open(output_lst_files, 'r')\n",
    "    lines = fid.readlines()\n",
    "    fid.close()\n",
    "    # ---------------------\n",
    "    \n",
    "    if files == 'tr':\n",
    "        train_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "    elif files == 'cv':\n",
    "        valid_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "    else:\n",
    "        test_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "a, b = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-russian",
   "metadata": {},
   "source": [
    "# 2. Building VQ-VAE model with Gumbel Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "environmental-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras import backend as Kb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import time\n",
    "from tensorflow.keras.models import Model, Sequential, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sexual-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    \"\"\" Creates a path recursively without throwing an error if it already exists\n",
    "    :param path: path to create\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "piano-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./CKPT/') # model check point 폴더 만드는 코드\n",
    "filepath = \"./CKPT/CKP_ep_{epoch:d}__loss_{val_loss:.5f}_.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "printable-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "\n",
    "# learning rate를 점점 줄이는 부분\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# validation loss에 대해서 좋은 것만 저장됨\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min'\n",
    ")\n",
    "\n",
    "# early stop 하는 부분인데, validation loss에 대해서 제일 좋은 모델이 저장됨\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "forward-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(q_y, latent_dim):\n",
    "    def si_sdr_loss(y_true, y_pred):\n",
    "        ori_length = tf.shape(y_true)[1]\n",
    "\n",
    "        # Label & Length divide\n",
    "        labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 1]\n",
    "        lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "\n",
    "        \n",
    "        target = tf.reduce_sum([y_pred, labels]) * labels / tf.experimental.numpy.square(labels)\n",
    "        noise = y_pred - target\n",
    "        si_sdr = 10 * np.log10(pow_np_norm(target) / tf.experimental.numpy.square(noise))\n",
    "        sdr = si_sdr * -0.5\n",
    "\n",
    "        return sdr\n",
    "    \n",
    "    log_q_y = tf.math.log(q_y+1e-20)\n",
    "    kl_loss = tf.reduce_sum(q_y*(log_q_y-tf.math.log(1.0/latent_dim)), axis=[1,2])\n",
    "    \n",
    "    return si_sdr_loss - kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d0e63776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GumbelSoftmax(layers.Layer):\n",
    "    def __init__(self, temperature=1.0, hard=False, name = 'gumbel_softmax',**kwargs):\n",
    "        super(GumbelSoftmax, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.temperature = temperature\n",
    "        self.hard = hard\n",
    "    \n",
    "    def sample_gumbel(self, shape, eps=1e-20): \n",
    "        \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "        U = tf.random.uniform(shape,minval=0,maxval=1)\n",
    "        \n",
    "        return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
    "\n",
    "    def gumbel_softmax_sample(self, logits, temperature): \n",
    "        \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "        y = logits + self.sample_gumbel(tf.shape(logits))\n",
    "        \n",
    "        return tf.nn.softmax(y / temperature)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y = self.gumbel_softmax_sample(inputs, self.temperature)\n",
    "        \n",
    "        if self.hard:\n",
    "            y_hard = tf.cast(tf.equal(y, tf.reduce_max(y, 2, keep_dims=True)), y.dtype)\n",
    "            y = tf.stop_gradient(y_hard - y) + y\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, latent_dim, name = 'encoder',**kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.conv1d_1 = layers.Conv1D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "        self.conv1d_2 = layers.Conv1D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "        self.logit = layers.Conv1D(filters=latent_dim, kernel_size=3, strides=2, activation='relu', padding='same')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1d_1(inputs)\n",
    "        x = self.conv1d_2(x)\n",
    "        logit = self.logit(x)\n",
    "        \n",
    "        return logit\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, latent_dim, name = 'decoder',**kwargs):\n",
    "        super(Decoder, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.trans_conv1d_1 = layers.Conv1DTranspose(filters=latent_dim, kernel_size=3, strides=2, activation='relu', padding='same')\n",
    "        self.trans_conv1d_2 = layers.Conv1DTranspose(filters=64, kernel_size=3, strides=2, activation='relu', padding='same')\n",
    "        self.logit = layers.Conv1DTranspose(filters=1, kernel_size=3, strides=2, padding='same', activation=None)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.trans_conv1d_1(inputs)\n",
    "        x = self.trans_conv1d_2(x)\n",
    "        logit = self.logit(x)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "renewable-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vq_vae(keras.Model):\n",
    "    def __init__(self, latent_dim, name='vqvae', **kwargs):\n",
    "        super(Vq_vae, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.softmax = layers.Softmax(-1)\n",
    "        \n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "        self.gumbel = GumbelSoftmax()\n",
    "        \n",
    "    def call(self, inputs, load=False):\n",
    "        if load:\n",
    "            inputs = layers.Input(shape=(None, 1))\n",
    "        \n",
    "        encode = self.encoder(inputs)\n",
    "        gumbel = self.gumbel(encode)\n",
    "        decode = self.decoder(gumbel)\n",
    "        \n",
    "        # ------------------ KL loss ------------------\n",
    "        qy = self.softmax(encode)\n",
    "        log_qy = tf.math.log(qy + 1e-20)\n",
    "        log_uniform = qy * (log_qy - tf.math.log(1.0 / self.latent_dim))\n",
    "        kl_loss = tf.reduce_mean(log_uniform)\n",
    "        # ---------------------------------------------\n",
    "        \n",
    "        self.add_loss(kl_loss)\n",
    "        \n",
    "        return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "eb546953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mse(y_true, y_pred):\n",
    "    ori_length = tf.shape(y_true)[1]\n",
    "\n",
    "    # Label & Length divide\n",
    "    labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 129]\n",
    "    lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "\n",
    "    loss = tf.reduce_sum(tf.pow(y_pred - labels, 2))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "referenced-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "장치의 수: 1\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 5s 2s/step - loss: 291.8696 - val_loss: 162.0523\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 114.31430\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 1s 732ms/step - loss: 215.2762 - val_loss: 283.1801\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 114.31430\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 1s 782ms/step - loss: 252.5166 - val_loss: 167.0403\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 114.31430\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 1s 779ms/step - loss: 167.9736 - val_loss: 199.5206\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 114.31430\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 1s 773ms/step - loss: 209.9542 - val_loss: 200.6039\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 114.31430\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 1s 620ms/step - loss: 185.9506 - val_loss: 154.0908\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 114.31430\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 1s 856ms/step - loss: 156.7565 - val_loss: 173.1974\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 114.31430\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 1s 677ms/step - loss: 172.3246 - val_loss: 170.4468\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 114.31430\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 1s 785ms/step - loss: 161.3661 - val_loss: 147.0124\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 114.31430\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 1s 684ms/step - loss: 150.2271 - val_loss: 150.6995\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 114.31430\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 1s 686ms/step - loss: 153.6717 - val_loss: 153.0334\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 114.31430\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 1s 680ms/step - loss: 151.2031 - val_loss: 141.9267\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 114.31430\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 1s 741ms/step - loss: 140.3334 - val_loss: 140.9969\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 114.31430\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 1s 818ms/step - loss: 143.1679 - val_loss: 142.7248\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 114.31430\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 1s 704ms/step - loss: 142.6127 - val_loss: 136.1719\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 114.31430\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 136.2220 - val_loss: 134.7595\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 114.31430\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 1s 821ms/step - loss: 138.4023 - val_loss: 135.7903\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 114.31430\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 1s 772ms/step - loss: 133.5930 - val_loss: 132.0841\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 114.31430\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 1s 728ms/step - loss: 132.9353 - val_loss: 130.4099\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 114.31430\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 1s 744ms/step - loss: 131.6331 - val_loss: 130.5237\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 114.31430\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 1s 689ms/step - loss: 130.1502 - val_loss: 127.2797\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 114.31430\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 1s 737ms/step - loss: 126.5774 - val_loss: 125.1716\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 114.31430\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 1s 674ms/step - loss: 125.7988 - val_loss: 124.3585\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 114.31430\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 1s 820ms/step - loss: 123.2939 - val_loss: 123.8472\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 114.31430\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 1s 760ms/step - loss: 121.1763 - val_loss: 122.0834\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 114.31430\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 1s 734ms/step - loss: 120.5890 - val_loss: 120.6928\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 114.31430\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 1s 855ms/step - loss: 120.5235 - val_loss: 119.0745\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 114.31430\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 1s 641ms/step - loss: 120.4939 - val_loss: 118.7661\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 114.31430\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 117.9185 - val_loss: 118.5744\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 114.31430\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 1s 774ms/step - loss: 116.3379 - val_loss: 116.6215\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 114.31430\n"
     ]
    }
   ],
   "source": [
    "latent_size = 512\n",
    "epoch = 30\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(['cpu:0'])\n",
    "print('장치의 수: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    model_path = './CKPT/CKP_ep_30__loss_158.95885_.h5'\n",
    "    \n",
    "    vq_vae = Vq_vae(latent_size)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    vq_vae.compile(optimizer, loss=custom_mse)\n",
    "    \n",
    "    # 사용 안할 때는 load_model 주석 처리 하자\n",
    "    vq_vae(0, True)\n",
    "    vq_vae.load_weights(model_path)\n",
    "    # ----------------------------------------\n",
    "    \n",
    "    tf.executing_eagerly()\n",
    "\n",
    "history = vq_vae.fit(\n",
    "    train_dataset,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "worst-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:1317: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
     ]
    }
   ],
   "source": [
    "latent_size = 512\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model_path = './CKPT/CKP_ep_2__loss_628.39642_.index'\n",
    "    model = Vq_vae(latent_size)\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    data, _ = next(iter(test_dataset))\n",
    "\n",
    "    pre = model.predict(data)\n",
    "    pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "alleged-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "sd.play(pre[1], 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ee481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8314750",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = np.random.rand(2, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbe1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "temporal-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(None, 1)))\n",
    "model.add(layers.Conv1D(filters=4, kernel_size=3, padding='same'))\n",
    "model.add(layers.Softmax(-1))\n",
    "\n",
    "input_array = np.random.randn(2, 5, 4)\n",
    "with tf.device('/cpu:0'):\n",
    "    model.compile('rmsprop', 'mse')\n",
    "\n",
    "    output_array = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ba32a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbc8e699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23794276, 0.3758409 , 0.20595631, 0.18026009], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "clean-drink",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23794276, 0.3758409 , 0.20595631, 0.18026009],\n",
       "        [0.16875331, 0.20575501, 0.26814145, 0.35735017],\n",
       "        [0.08178392, 0.23333283, 0.32606637, 0.35881683],\n",
       "        [0.13777426, 0.4296873 , 0.2569556 , 0.17558284],\n",
       "        [0.2141833 , 0.3373918 , 0.2515016 , 0.19692335]],\n",
       "\n",
       "       [[0.2109271 , 0.3640199 , 0.20789267, 0.21716031],\n",
       "        [0.25047418, 0.33341768, 0.23042291, 0.18568526],\n",
       "        [0.22128512, 0.30281523, 0.21816052, 0.25773916],\n",
       "        [0.17393257, 0.30159497, 0.2893706 , 0.23510183],\n",
       "        [0.29052198, 0.27541766, 0.23140128, 0.2026591 ]]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5044d110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[0.24628553, 0.282701  , 0.2385324 , 0.23248109],\n",
       "        [0.2298986 , 0.23856457, 0.25392184, 0.27761498],\n",
       "        [0.2101039 , 0.2444843 , 0.26824066, 0.27717113],\n",
       "        [0.22202027, 0.29728216, 0.2501223 , 0.23057525],\n",
       "        [0.24084595, 0.2724257 , 0.25000373, 0.23672463]],\n",
       "\n",
       "       [[0.23988546, 0.27957046, 0.23915865, 0.24138539],\n",
       "        [0.24975686, 0.27135593, 0.24479878, 0.23408844],\n",
       "        [0.24278015, 0.26340333, 0.24202275, 0.25179377],\n",
       "        [0.23139507, 0.262904  , 0.25970972, 0.2459912 ],\n",
       "        [0.2601803 , 0.25627998, 0.24524413, 0.23829558]]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_softmax = tf.nn.softmax(output_array)\n",
    "output_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4122a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_reshape = tf.reshape(output_softmax, [-1, 4])\n",
    "output_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d31fcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[0.24628553, 0.282701  , 0.2385324 , 0.23248109],\n",
       "        [0.2298986 , 0.23856457, 0.25392184, 0.27761498],\n",
       "        [0.2101039 , 0.2444843 , 0.26824066, 0.27717113],\n",
       "        [0.22202027, 0.29728216, 0.2501223 , 0.23057525],\n",
       "        [0.24084595, 0.2724257 , 0.25000373, 0.23672463]],\n",
       "\n",
       "       [[0.23988546, 0.27957046, 0.23915865, 0.24138539],\n",
       "        [0.24975686, 0.27135593, 0.24479878, 0.23408844],\n",
       "        [0.24278015, 0.26340333, 0.24202275, 0.25179377],\n",
       "        [0.23139507, 0.262904  , 0.25970972, 0.2459912 ],\n",
       "        [0.2601803 , 0.25627998, 0.24524413, 0.23829558]]], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.nn.softmax(output_array), [-1, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "01c293c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.cast(tf.equal(y, tf.reduce_max(y,1,keep_dims=True)), y.dtype)\n",
    "output_hard = tf.cast(tf.equal(output_reshape, tf.math.reduce_max(output_reshape, 1, keepdims=True)), output_softmax.dtype)\n",
    "output_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7703002f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(output_hard, [-1, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "constitutional-coral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 4, 5])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(output_array, perm=[0, 2, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "prompt-distinction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.advanced_activations.Softmax at 0x26f14e934c8>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Softmax(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "treated-flash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-citizen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
