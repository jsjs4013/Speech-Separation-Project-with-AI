{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frank-northwest",
   "metadata": {},
   "source": [
    "# 1. Data Generator\n",
    "- Raw Data를 읽어옴\n",
    "- 여기서 만들어진 데이터는 모델의 입력으로 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "requested-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "architectural-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawForVAEGenerator(Sequence):\n",
    "    def __init__(self, source, wav_dir, files, sourNum='s1', batch_size=10, shuffle=True):\n",
    "        self.source = source\n",
    "        self.wav_dir = wav_dir\n",
    "        self.files = files\n",
    "        self.sourNum = sourNum\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        self.sample_rate = 8000\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.source))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __audioread__(self, path, offset=0.0, duration=None, sample_rate=16000):\n",
    "        signal = librosa.load(path, sr=self.sample_rate, mono=False, offset=offset, duration=duration)\n",
    "\n",
    "        return signal[0]\n",
    "    \n",
    "    def __padding__(self, data):\n",
    "        n_batch = len(data)\n",
    "        max_len = max([d.shape[0] for d in data])\n",
    "        extrapadding = int(np.ceil(max_len / self.sample_rate) * self.sample_rate)\n",
    "        pad = np.zeros((n_batch, extrapadding))\n",
    "        \n",
    "        for i in range(n_batch):\n",
    "            pad[i, :data[i].shape[0]] = data[i]\n",
    "        \n",
    "        return np.expand_dims(pad, -1)\n",
    "        \n",
    "    def __data_generation__(self, source_list):\n",
    "        wav_list = []\n",
    "        for name in source_list:\n",
    "            name = name.strip('\\n')\n",
    "            \n",
    "            s_wav_name = self.wav_dir + self.files + '/' + self.sourNum + '/' + name\n",
    "            \n",
    "            # ------- AUDIO READ -------\n",
    "            s_wav = (self.__audioread__(s_wav_name,  offset=0.0, duration=None, sample_rate=self.sample_rate))\n",
    "            # --------------------------\n",
    "            \n",
    "            # ------- PADDING -------\n",
    "#             pad_len = max(len(samples1),len(samples2))\n",
    "#             pad_s1 = np.concatenate([s1_wav, np.zeros([pad_len - len(s1_wav)])])\n",
    "            \n",
    "#             extrapadding = ceil(len(pad_s1) / sample_rate) * sample_rate - len(pad_s1)\n",
    "#             pad_s1 = np.concatenate([pad_s1, np.zeros([extrapadding - len(pad_s1)])])\n",
    "#             pad_s2 = np.concatenate([s2_wav, np.zeros([extrapadding - len(s2_wav)])])\n",
    "            # -----------------------\n",
    "            \n",
    "            wav_list.append(s_wav)\n",
    "        \n",
    "        return wav_list, wav_list\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.source) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        source_list = [self.source[k] for k in indexes]\n",
    "        \n",
    "        if self.files is not 'tt':\n",
    "            sour, labels = self.__data_generation__(source_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in sour])\n",
    "            exp = np.expand_dims(lengths, 1)\n",
    "            exp = np.expand_dims(exp, -1) # [Batch, 1, 1] (length)\n",
    "            \n",
    "            # Padding\n",
    "            sour_pad = self.__padding__(sour) # [Batch, Time_step, Dimension(=1)]\n",
    "            label_pad = self.__padding__(labels) # [Batch, Time_step, Dimension(=1)]\n",
    "            \n",
    "            return sour_pad, np.concatenate([label_pad, exp], axis=1)\n",
    "        else:\n",
    "            sour, labels = self.__data_generation__(source_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in sour])\n",
    "            exp = np.expand_dims(lengths, 1)\n",
    "            exp = np.expand_dims(exp, -1) # [Batch, 1, 1] (length)\n",
    "            \n",
    "            # Padding\n",
    "            sour_pad = self.__padding__(sour) # [Batch, Time_step, Dimension(=1)]\n",
    "            \n",
    "            return sour_pad, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-league",
   "metadata": {},
   "source": [
    "## Data를 어떻게 읽는지에 대한 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "martial-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_DIR = './mycode/wsj0_2mix/use_this/'\n",
    "LIST_DIR = './mycode/wsj0_2mix/use_this/lists/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attached-debate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate wav file to .lst done!\n"
     ]
    }
   ],
   "source": [
    "# Directory List file create\n",
    "\n",
    "wav_dir = WAV_DIR\n",
    "output_lst = LIST_DIR\n",
    "\n",
    "for folder in ['tr', 'cv', 'tt']:\n",
    "    wav_files = os.listdir(wav_dir + folder + '/mix')\n",
    "    output_lst_files = output_lst + folder + '_wav.lst'\n",
    "    with open(output_lst_files, 'w') as f:\n",
    "        for file in wav_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "print(\"Generate wav file to .lst done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comparable-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "train_dataset = 0\n",
    "valid_dataset = 0\n",
    "test_dataset = 0\n",
    "\n",
    "name_list = []\n",
    "for files in ['tr', 'cv', 'tt']:\n",
    "    # --- Lead lst file ---\"\"\n",
    "    output_lst_files = LIST_DIR + files + '_wav.lst'\n",
    "    fid = open(output_lst_files, 'r')\n",
    "    lines = fid.readlines()\n",
    "    fid.close()\n",
    "    # ---------------------\n",
    "    \n",
    "    if files == 'tr':\n",
    "        train_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "    elif files == 'cv':\n",
    "        valid_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "    else:\n",
    "        test_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "a, b = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-russian",
   "metadata": {},
   "source": [
    "# 2. Building VQ-VAE model with Gumbel Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "environmental-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras import backend as Kb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sexual-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    \"\"\" Creates a path recursively without throwing an error if it already exists\n",
    "    :param path: path to create\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "piano-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./CKPT/') # model check point 폴더 만드는 코드\n",
    "filepath = \"./CKPT/CKP_ep_{epoch:d}__loss_{val_loss:.5f}_.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "printable-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "\n",
    "# learning rate를 점점 줄이는 부분\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# validation loss에 대해서 좋은 것만 저장됨\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
    ")\n",
    "\n",
    "# early stop 하는 부분인데, validation loss에 대해서 제일 좋은 모델이 저장됨\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "forward-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(q_y, latent_dim):\n",
    "    def si_sdr_loss(y_true, y_pred):\n",
    "        ori_length = tf.shape(y_true)[1]\n",
    "\n",
    "        # Label & Length divide\n",
    "        labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 1]\n",
    "        lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "\n",
    "        \n",
    "        target = tf.reduce_sum([y_pred, labels]) * labels / tf.experimental.numpy.square(labels)\n",
    "        noise = y_pred - target\n",
    "        si_sdr = 10 * np.log10(pow_np_norm(target) / tf.experimental.numpy.square(noise))\n",
    "        sdr = si_sdr * -0.5\n",
    "\n",
    "        return sdr\n",
    "    \n",
    "    log_q_y = tf.math.log(q_y+1e-20)\n",
    "    kl_loss = tf.reduce_sum(q_y*(log_q_y-tf.math.log(1.0/latent_dim)), axis=[1,2])\n",
    "    \n",
    "    return si_sdr_loss - kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0d6a3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GumbelSoftmax(layers.Layer):\n",
    "    def __init__(self, temperature=1.0, hard=False, name = 'gumbel_softmax',**kwargs):\n",
    "        super(GumbelSoftmax, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.temperature = temperature\n",
    "        self.hard = hard\n",
    "    \n",
    "    def sample_gumbel(self, shape, eps=1e-20): \n",
    "        \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "        U = tf.random.uniform(shape,minval=0,maxval=1)\n",
    "        \n",
    "        return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
    "\n",
    "    def gumbel_softmax_sample(self, logits, temperature): \n",
    "        \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "        y = logits + self.sample_gumbel(tf.shape(logits))\n",
    "        \n",
    "        return tf.nn.softmax(y / temperature)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y = self.gumbel_softmax_sample(inputs, self.temperature)\n",
    "        \n",
    "        if self.hard:\n",
    "            y_hard = tf.cast(tf.equal(y, tf.reduce_max(y, 2, keep_dims=True)), y.dtype)\n",
    "            y = tf.stop_gradient(y_hard - y) + y\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, latent_dim, name = 'encoder',**kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.conv1d_1 = layers.Conv1D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "        self.conv1d_2 = layers.Conv1D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "        self.logit = layers.Conv1D(filters=latent_dim, kernel_size=3, strides=2, activation='relu', padding='same')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1d_1(inputs)\n",
    "        x = self.conv1d_2(x)\n",
    "        logit = self.logit(x)\n",
    "        \n",
    "        return logit\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, latent_dim, name = 'decoder',**kwargs):\n",
    "        super(Decoder, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.trans_conv1d_1 = layers.Conv1DTranspose(filters=latent_dim, kernel_size=3, strides=2, activation='relu', padding='same')\n",
    "        self.trans_conv1d_2 = layers.Conv1DTranspose(filters=64, kernel_size=3, strides=2, activation='relu', padding='same')\n",
    "        self.logit = layers.Conv1DTranspose(filters=1, kernel_size=3, strides=2, padding='same', activation=None)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.trans_conv1d_1(inputs)\n",
    "        x = self.trans_conv1d_2(x)\n",
    "        logit = self.logit(x)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "renewable-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vq_vae(keras.Model):\n",
    "    def __init__(self, latent_dim, name='vqvae', **kwargs):\n",
    "        super(Vq_vae, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.softmax = layers.Softmax(-1)\n",
    "        \n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "        self.gumbel = GumbelSoftmax()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        encode = self.encoder(inputs)\n",
    "        gumbel = self.gumbel(encode)\n",
    "        decode = self.decoder(gumbel)\n",
    "        \n",
    "        # ------------------ KL loss ------------------\n",
    "        qy = self.softmax(encode)\n",
    "        log_qy = tf.math.log(qy + 1e-20)\n",
    "        log_uniform = qy * (log_qy - tf.math.log(1.0 / self.latent_dim))\n",
    "        kl_loss = tf.reduce_mean(log_uniform)\n",
    "        # ---------------------------------------------\n",
    "        \n",
    "        self.add_loss(kl_loss)\n",
    "        \n",
    "        return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "124ba658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mse(y_true, y_pred):\n",
    "    ori_length = tf.shape(y_true)[1]\n",
    "\n",
    "    # Label & Length divide\n",
    "    labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 129]\n",
    "    lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "\n",
    "    loss = tf.reduce_sum(tf.pow(y_pred - labels, 2))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "referenced-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "장치의 수: 1\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 4s 2s/step - loss: 634.1272 - val_loss: 631.1151\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 1s 635ms/step - loss: 630.8201 - val_loss: 628.8809\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 1s 631ms/step - loss: 628.5059 - val_loss: 627.9719\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 628.0130 - val_loss: 627.7009\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 1s 584ms/step - loss: 627.6346 - val_loss: 627.4137\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 627.4485 - val_loss: 627.2621\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 627.3534 - val_loss: 627.2830\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 1s 525ms/step - loss: 627.2859 - val_loss: 627.2543\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 627.2554 - val_loss: 627.2035\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 1s 588ms/step - loss: 627.2186 - val_loss: 627.2015\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 627.1792 - val_loss: 627.1915\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 1s 567ms/step - loss: 627.2048 - val_loss: 627.2037\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 1s 590ms/step - loss: 627.1840 - val_loss: 627.1635\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 1s 583ms/step - loss: 627.1598 - val_loss: 627.1223\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 627.1440 - val_loss: 627.1434\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 1s 689ms/step - loss: 627.1642 - val_loss: 627.1362\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 627.1193 - val_loss: 627.0865\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 1s 675ms/step - loss: 627.0645 - val_loss: 627.0068\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 1s 640ms/step - loss: 627.0023 - val_loss: 626.8751\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 1s 594ms/step - loss: 626.8873 - val_loss: 626.6821\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 626.7189 - val_loss: 626.4346\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 1s 636ms/step - loss: 626.4145 - val_loss: 626.0621\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 1s 600ms/step - loss: 625.8621 - val_loss: 625.2983\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 1s 509ms/step - loss: 625.1118 - val_loss: 624.0319\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 623.5677 - val_loss: 621.8580\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 621.4252 - val_loss: 618.4094\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 617.3359 - val_loss: 613.1760\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 1s 610ms/step - loss: 611.3331 - val_loss: 605.5862\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 1s 624ms/step - loss: 603.4558 - val_loss: 594.3339\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 589.7652 - val_loss: 578.2260\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 1s 619ms/step - loss: 573.4772 - val_loss: 557.3634\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 1s 620ms/step - loss: 553.7939 - val_loss: 532.7192\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 1s 512ms/step - loss: 524.2629 - val_loss: 504.4818\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 1s 497ms/step - loss: 494.6567 - val_loss: 473.3173\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 1s 614ms/step - loss: 469.3850 - val_loss: 448.2675\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 1s 699ms/step - loss: 439.3477 - val_loss: 412.9702\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 1s 527ms/step - loss: 406.1701 - val_loss: 391.4652\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 1s 546ms/step - loss: 387.4844 - val_loss: 369.5956\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 1s 609ms/step - loss: 364.1036 - val_loss: 346.5223\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 1s 586ms/step - loss: 338.8812 - val_loss: 318.9381\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 311.9246 - val_loss: 294.8510\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 1s 614ms/step - loss: 288.8078 - val_loss: 266.2885\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 1s 592ms/step - loss: 261.0405 - val_loss: 243.3668\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 242.9549 - val_loss: 230.0630\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 1s 602ms/step - loss: 221.3279 - val_loss: 213.4316\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 1s 611ms/step - loss: 207.6290 - val_loss: 199.7414\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 1s 618ms/step - loss: 197.9222 - val_loss: 186.8436\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 1s 627ms/step - loss: 187.0564 - val_loss: 180.2550\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 1s 620ms/step - loss: 177.5475 - val_loss: 174.4260\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 1s 611ms/step - loss: 172.5288 - val_loss: 165.5489\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 165.8893 - val_loss: 160.7765\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 1s 619ms/step - loss: 160.4627 - val_loss: 155.0624\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 1s 599ms/step - loss: 152.7232 - val_loss: 148.1633\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 1s 594ms/step - loss: 147.2661 - val_loss: 143.7695\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 1s 521ms/step - loss: 141.1070 - val_loss: 139.4506\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 1s 645ms/step - loss: 137.2781 - val_loss: 136.8375\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 135.7797 - val_loss: 132.4380\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 131.1069 - val_loss: 128.9052\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 1s 525ms/step - loss: 127.7016 - val_loss: 126.4254\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 126.2313 - val_loss: 124.0219\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 1s 608ms/step - loss: 123.6553 - val_loss: 124.3724\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 1s 578ms/step - loss: 120.7188 - val_loss: 119.2607\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 120.8415 - val_loss: 118.0743\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 117.4793 - val_loss: 117.3938\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 1s 625ms/step - loss: 117.0806 - val_loss: 115.3433\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 114.0404 - val_loss: 113.6517\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 112.9295 - val_loss: 111.5664\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 1s 585ms/step - loss: 110.6427 - val_loss: 110.9044\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 108.6226 - val_loss: 108.5838\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 107.4722 - val_loss: 108.9327\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 107.8164 - val_loss: 106.7975\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 1s 648ms/step - loss: 108.5523 - val_loss: 105.7998\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 105.2724 - val_loss: 103.5784\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 1s 648ms/step - loss: 102.2788 - val_loss: 102.4399\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 102.6575 - val_loss: 101.7640\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 639ms/step - loss: 100.3541 - val_loss: 101.5048\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 100.1057 - val_loss: 98.8705\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 98.8522 - val_loss: 99.5896\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 97.6191 - val_loss: 97.5371\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 1s 638ms/step - loss: 96.7170 - val_loss: 98.2277\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 97.2889 - val_loss: 93.5203\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 1s 624ms/step - loss: 95.6992 - val_loss: 94.2728\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 93.4843 - val_loss: 93.1445\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 93.9307 - val_loss: 93.9287\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 1s 517ms/step - loss: 91.9048 - val_loss: 90.4862\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 1s 677ms/step - loss: 92.7236 - val_loss: 91.9556\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 1s 643ms/step - loss: 91.4974 - val_loss: 88.8740\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 1s 565ms/step - loss: 88.9769 - val_loss: 88.3799\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 1s 604ms/step - loss: 88.5385 - val_loss: 87.4525\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 1s 526ms/step - loss: 87.1157 - val_loss: 87.1098\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 1s 655ms/step - loss: 87.6602 - val_loss: 86.7645\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 1s 523ms/step - loss: 85.5362 - val_loss: 86.2505\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 1s 614ms/step - loss: 83.7849 - val_loss: 84.0949\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 1s 687ms/step - loss: 83.7100 - val_loss: 83.6045\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 81.9647 - val_loss: 82.3307\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 1s 637ms/step - loss: 83.5652 - val_loss: 82.0165\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 1s 721ms/step - loss: 81.9190 - val_loss: 82.6516\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 1s 572ms/step - loss: 80.7532 - val_loss: 79.8544\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 80.4654 - val_loss: 79.9693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 1s 628ms/step - loss: 80.3477 - val_loss: 77.9664\n"
     ]
    }
   ],
   "source": [
    "latent_size = 512\n",
    "epoch = 100\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(['cpu:0'])\n",
    "print('장치의 수: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # 사용 안할 때는 load_model 주석 처리 하자\n",
    "#     model = load_model('./CKPT/CKP_ep_29__loss_102.63367_.h5', custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "    \n",
    "    vq_vae = Vq_vae(latent_size)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    vq_vae.compile(optimizer, loss=custom_mse)\n",
    "    \n",
    "    tf.executing_eagerly()\n",
    "\n",
    "history = vq_vae.fit(\n",
    "    train_dataset,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "worst-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000284EA13C7B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.02677667],\n",
       "        [-0.01488497],\n",
       "        [-0.01291844],\n",
       "        ...,\n",
       "        [-0.00646507],\n",
       "        [-0.00839081],\n",
       "        [-0.00391942]],\n",
       "\n",
       "       [[-0.02742512],\n",
       "        [-0.01469865],\n",
       "        [-0.00962831],\n",
       "        ...,\n",
       "        [-0.02558249],\n",
       "        [-0.01939785],\n",
       "        [-0.00349818]]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, _ = next(iter(test_dataset))\n",
    "\n",
    "pre = vq_vae.predict(data)\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "alleged-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "sd.play(pre[1], 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-surveillance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8314750",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = np.random.rand(2, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbe1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "temporal-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(None, 1)))\n",
    "model.add(layers.Conv1D(filters=4, kernel_size=3, padding='same'))\n",
    "model.add(layers.Softmax(-1))\n",
    "\n",
    "input_array = np.random.randn(2, 5, 4)\n",
    "with tf.device('/cpu:0'):\n",
    "    model.compile('rmsprop', 'mse')\n",
    "\n",
    "    output_array = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f4d66c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36ff0c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23794276, 0.3758409 , 0.20595631, 0.18026009], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "clean-drink",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23794276, 0.3758409 , 0.20595631, 0.18026009],\n",
       "        [0.16875331, 0.20575501, 0.26814145, 0.35735017],\n",
       "        [0.08178392, 0.23333283, 0.32606637, 0.35881683],\n",
       "        [0.13777426, 0.4296873 , 0.2569556 , 0.17558284],\n",
       "        [0.2141833 , 0.3373918 , 0.2515016 , 0.19692335]],\n",
       "\n",
       "       [[0.2109271 , 0.3640199 , 0.20789267, 0.21716031],\n",
       "        [0.25047418, 0.33341768, 0.23042291, 0.18568526],\n",
       "        [0.22128512, 0.30281523, 0.21816052, 0.25773916],\n",
       "        [0.17393257, 0.30159497, 0.2893706 , 0.23510183],\n",
       "        [0.29052198, 0.27541766, 0.23140128, 0.2026591 ]]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76507c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[0.24628553, 0.282701  , 0.2385324 , 0.23248109],\n",
       "        [0.2298986 , 0.23856457, 0.25392184, 0.27761498],\n",
       "        [0.2101039 , 0.2444843 , 0.26824066, 0.27717113],\n",
       "        [0.22202027, 0.29728216, 0.2501223 , 0.23057525],\n",
       "        [0.24084595, 0.2724257 , 0.25000373, 0.23672463]],\n",
       "\n",
       "       [[0.23988546, 0.27957046, 0.23915865, 0.24138539],\n",
       "        [0.24975686, 0.27135593, 0.24479878, 0.23408844],\n",
       "        [0.24278015, 0.26340333, 0.24202275, 0.25179377],\n",
       "        [0.23139507, 0.262904  , 0.25970972, 0.2459912 ],\n",
       "        [0.2601803 , 0.25627998, 0.24524413, 0.23829558]]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_softmax = tf.nn.softmax(output_array)\n",
    "output_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e7ad8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_reshape = tf.reshape(output_softmax, [-1, 4])\n",
    "output_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5676eeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[0.24628553, 0.282701  , 0.2385324 , 0.23248109],\n",
       "        [0.2298986 , 0.23856457, 0.25392184, 0.27761498],\n",
       "        [0.2101039 , 0.2444843 , 0.26824066, 0.27717113],\n",
       "        [0.22202027, 0.29728216, 0.2501223 , 0.23057525],\n",
       "        [0.24084595, 0.2724257 , 0.25000373, 0.23672463]],\n",
       "\n",
       "       [[0.23988546, 0.27957046, 0.23915865, 0.24138539],\n",
       "        [0.24975686, 0.27135593, 0.24479878, 0.23408844],\n",
       "        [0.24278015, 0.26340333, 0.24202275, 0.25179377],\n",
       "        [0.23139507, 0.262904  , 0.25970972, 0.2459912 ],\n",
       "        [0.2601803 , 0.25627998, 0.24524413, 0.23829558]]], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.nn.softmax(output_array), [-1, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb586032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.cast(tf.equal(y, tf.reduce_max(y,1,keep_dims=True)), y.dtype)\n",
    "output_hard = tf.cast(tf.equal(output_reshape, tf.math.reduce_max(output_reshape, 1, keepdims=True)), output_softmax.dtype)\n",
    "output_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f77b3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(output_hard, [-1, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "constitutional-coral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 4, 5])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(output_array, perm=[0, 2, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "prompt-distinction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.advanced_activations.Softmax at 0x26f14e934c8>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Softmax(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "treated-flash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-citizen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
