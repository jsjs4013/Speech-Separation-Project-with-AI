{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7caaa2a3",
   "metadata": {},
   "source": [
    "# Data Loader?\n",
    "- hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b9996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4449ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc35ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, sys, os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816a77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.util.global_function import mkdir_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254f11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util.math_function import create_padding_mask, create_look_ahead_mask\n",
    "from src.losses.custom_loss import mse_with_proper_loss, MSE_Custom_Loss_No_Length, pit_with_outputsize, pit_with_stft_trace\n",
    "from src.models.Layers import TransformerSpeechSep\n",
    "from src.models.Schedulers import CustomSchedule\n",
    "from src.models.Real_Layers import T5Model, T5ModelNoMaskCreationModel, T5ModelYesMaskCreationModel\n",
    "from src.pre_processing.data_pre_processing import load_data\n",
    "from src.models.T5_variations import T5ChangedSTFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "83f42680",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = namedtuple('Config',  \n",
    "    field_names=\"d_ff,     d_kv,     d_model,              dropout, feed_forward_proj, num_layers, init_factor,\" \n",
    "                \"layer_norm_epsilon, model_type, num_heads, positional_embedding, n_epochs, vocab_size, relative_attention_num_buckets,\"\n",
    "                    \"model_path, wav_type, size_type, train_type, loss_type, learning_rate_type,\"\n",
    "                    \"input_size, output_size, batch_size, case, ckpt_path, tr_path, val_path, tt_path,\"\n",
    "                    \"test_wav_dir, is_load_model\")\n",
    "args = Config( 2048      , 64      , 512              , 0.1 , \"gated-gelu\", 4       , 1.,\n",
    "                1e-06    , \"t5\"             , 8 , \"absolute\" , 5     , 129   , 32,\n",
    "                \"CKPT\", \"wav8k\", \"min\", \"train-360\", \"mse\", \"inverse_root\",\n",
    "                40, 40, 25, 'trace', 'C:/J_and_J_Research/CKPT/gen_code', \n",
    "                'C:/J_and_J_Research/mycode/wsj0_2mix/use_this/tr/', \n",
    "                'C:/J_and_J_Research/mycode/wsj0_2mix/use_this/cv/',\n",
    "                'C:/J_and_J_Research/mycode/wsj0_2mix/use_this/tt/', \n",
    "                'C:/J_and_J_Research/test_wav/gen',\n",
    "                True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265a43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_masks(inp, tar, length=None):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp, length) # (batch, 1, 1, seq_len)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp, length)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1]) # (seq_len, seq_len)\n",
    "    dec_target_padding_mask = create_padding_mask(tar, length) # (batch, 1, 1, seq_len)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask) # (batch, 1, seq_len, seq_len)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a407ebe3",
   "metadata": {},
   "source": [
    "# Raw 1Conv Layer \n",
    "- 주원씨가 만든 raw data를 conv로 embedding한거 클래스임니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "177c0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataGenerator(Sequence):\n",
    "    def __init__(self, Mix, wav_dir, files, batch_size=10, shuffle=True):\n",
    "        self.Mix = Mix\n",
    "        self.wav_dir = wav_dir\n",
    "        self.files = files\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.Mix))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __audioread__(self, path, offset=0.0, duration=None, sample_rate=16000):\n",
    "        signal = librosa.load(path, sr=sample_rate, mono=False, offset=offset, duration=duration)\n",
    "\n",
    "        return signal[0]\n",
    "    \n",
    "    def __padding__(self, data):\n",
    "        n_batch = len(data)\n",
    "        max_len = max([d.shape[0] for d in data])\n",
    "        pad = np.zeros((n_batch, max_len, data[0].shape[1]))\n",
    "        \n",
    "        for i in range(n_batch):\n",
    "            pad[i, :data[i].shape[0]] = data[i]\n",
    "        \n",
    "        return pad\n",
    "        \n",
    "    def __data_generation__(self, Mix_list):\n",
    "        sample_rate = 8000\n",
    "        L = 40\n",
    "        \n",
    "        mix_wav_list = []\n",
    "        label_wav_list = []\n",
    "        for name in Mix_list:\n",
    "            name = name.strip('\\n')\n",
    "            \n",
    "            s1_wav_name = self.wav_dir + self.files + '/s1/' + name\n",
    "            \n",
    "            # ------- AUDIO READ -------\n",
    "            s1_wav = (self.__audioread__(s1_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate))\n",
    "            # --------------------------\n",
    "            \n",
    "            # ------- TIME AXIS CALCULATE -------\n",
    "            K = int(np.ceil(len(s1_wav) / L))\n",
    "            # -----------------------------------\n",
    "            \n",
    "            # ------- PADDING -------\n",
    "            pad_len = K * L\n",
    "            pad_s1 = np.concatenate([s1_wav, np.zeros([pad_len - len(s1_wav)])])\n",
    "            # -----------------------\n",
    "            \n",
    "            # ------- RESHAPE -------\n",
    "            s1 = np.reshape(pad_s1, [K, L])\n",
    "            # -----------------------\n",
    "            \n",
    "            # ------- CONCAT S1 S2 -------\n",
    "            # ----------------------------\n",
    "            \n",
    "            label_wav_list.append(s1)\n",
    "        \n",
    "        return label_wav_list, label_wav_list\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.Mix) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        Mix_list = [self.Mix[k] for k in indexes]\n",
    "        \n",
    "        if self.files is not 'tt':\n",
    "            mix, labels = self.__data_generation__(Mix_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in mix])\n",
    "            tiled = np.tile(np.expand_dims(lengths, 1), [1, labels[0].shape[1]])\n",
    "            tiled = np.expand_dims(tiled, 1)\n",
    "            \n",
    "            # Padding\n",
    "            mix_pad = self.__padding__(mix) # [Batch, Time_step, Dimension]\n",
    "            label_pad = self.__padding__(labels) # [Batch, Time_step, Dimension * 2]\n",
    "            \n",
    "            return mix_pad, np.concatenate([label_pad, tiled], axis=1), lengths\n",
    "        else:\n",
    "            mix, labels = self.__data_generation__(Mix_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in mix])\n",
    "            tiled = np.tile(np.expand_dims(lengths, 1), [1, labels[0].shape[1]])\n",
    "            tiled = np.expand_dims(tiled, 1)\n",
    "            \n",
    "            # Padding\n",
    "            mix_pad = self.__padding__(mix) # [Batch, Time_step, Dimension]\n",
    "            \n",
    "            return mix_pad, tiled, lengths, Mix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93d37566",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_DIR = './mycode/wsj0_2mix/use_this/'\n",
    "LIST_DIR = './mycode/wsj0_2mix/use_this/lists/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "816b2607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate wav file to .lst done!\n"
     ]
    }
   ],
   "source": [
    "# Directory List file create\n",
    "wav_dir = WAV_DIR\n",
    "output_lst = LIST_DIR\n",
    "\n",
    "for folder in ['tr', 'cv', 'tt']:\n",
    "    wav_files = os.listdir(wav_dir + folder + '/mix')\n",
    "    output_lst_files = output_lst + folder + '_wav.lst'\n",
    "    with open(output_lst_files, 'w') as f:\n",
    "        for file in wav_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "print(\"Generate wav file to .lst done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bfe62ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "train_dataset = 0\n",
    "valid_dataset = 0\n",
    "test_dataset = 0\n",
    "\n",
    "name_list = []\n",
    "for files in ['tr', 'cv', 'tt']:\n",
    "    # --- Lead lst file ---\n",
    "    output_lst_files = LIST_DIR + files + '_wav.lst'\n",
    "    fid = open(output_lst_files, 'r')\n",
    "    lines = fid.readlines()\n",
    "    fid.close()\n",
    "    # ---------------------\n",
    "    \n",
    "    if files == 'tr':\n",
    "        train_dataset = RawDataGenerator(lines, WAV_DIR, files, batch_size)\n",
    "    elif files == 'cv':\n",
    "        valid_dataset = RawDataGenerator(lines, WAV_DIR, files, batch_size)\n",
    "    else:\n",
    "        test_batch = 1\n",
    "        test_dataset = RawDataGenerator(lines, WAV_DIR, files, 's1', test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80faec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8eb2a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_real_T5(input_size, output_size, args):\n",
    "    inputs = (tf.keras.layers.Input(shape=(None, input_size)),\n",
    "    tf.keras.layers.Input(shape=(None, output_size)),\n",
    "    tf.keras.layers.Input(shape=(1)) )\n",
    "    # targets, length\n",
    "        \n",
    "    transformer = T5ModelNoMaskCreationModel(num_layers=args.num_layers, d_model=args.d_model, num_heads=args.num_heads, d_ff=args.d_ff, d_kv = args.d_kv, vocab_size=0, feed_forward_proj = args.feed_forward_proj, \n",
    "            relative_attention_num_buckets=args.relative_attention_num_buckets, eps=args.layer_norm_epsilon, dropout=args.dropout, factor=args.init_factor,\n",
    "            embed_or_dense=\"conv\", target_size=output_size)\n",
    "\n",
    "    inp, tar, length = inputs\n",
    "    #dec_padding_mask = tf.squeeze(dec_padding_mask)\n",
    "    #outputs = tf.keras.layers.Conv1D(filters=129, kernel_size=2, activation = 'sigmoid', padding='same')(inp)\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar, length)\n",
    "    enc_padding_mask = tf.squeeze(enc_padding_mask)\n",
    "    outputs = transformer(input_ids=inp, attention_mask=enc_padding_mask, \n",
    "            decoder_input_ids=tar, \n",
    "             training=False) # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    model = T5ChangedSTFT(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    learning_rate = CustomSchedule(args.d_model)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,epsilon=1e-8)\n",
    "    #optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999,epsilon=1e-8, weight_decay = 0.01)\n",
    "    #model.add_metric(tf.keras.metrics.Mean(name='train_loss')(outputs))\n",
    "    #model.compile(loss=mse_with_proper_loss(output_size), optimizer=optimizer)\n",
    "    model.compile(loss=pit_with_stft_trace(output_size), optimizer=optimizer)\n",
    "#     model.compile(loss=keras.losses.mean_squared_error, optimizer=adam)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "209de6bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "장치의 수: 1\n",
      "Model: \"t5_changed_stft_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_20 (TFOpLamb (3,)                 0           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_20 (TFOpLa None                 0           input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_35 (Sl ()                   0           tf.compat.v1.shape_20[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.sequence_mask_15 (TFOpLambda None                 0           tf.compat.v1.squeeze_20[0][0]    \n",
      "                                                                 tf.__operators__.getitem_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_15 (TFOpLambda)         None                 0           tf.sequence_mask_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_20 (TFOpLambda None                 0           tf.cast_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_36 (Sl None                 0           tf.math.subtract_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_23 (TFOpLa None                 0           tf.__operators__.getitem_36[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "t5_model_no_mask_creation_model (None, None, 40)     37833768    input_16[0][0]                   \n",
      "                                                                 tf.compat.v1.squeeze_23[0][0]    \n",
      "                                                                 input_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,833,768\n",
      "Trainable params: 37,833,768\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "INFO:tensorflow:Error reported to Coordinator: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"c:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_run.py\", line 208, in _call_for_each_replica\n",
      "    t.has_paused.wait()\n",
      "  File \"c:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"c:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-0150d7118137>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 760\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3308\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    988\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m                     \u001b[0muser_requested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m                 ))\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1286\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2849\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2851\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     return mirrored_run.call_for_each_replica(\n\u001b[1;32m--> 671\u001b[1;33m         self._container_strategy(), fn, args, kwargs)\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m   def _configure(self,\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_run.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_run.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m       \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m     \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_result\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[0;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mstop_on_exception\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=bare-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_run.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_paused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m             \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_paused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ckpt_path = args.ckpt_path\n",
    "mkdir_p(ckpt_path) # model check point 폴더 만드는 코드\n",
    "\n",
    "filepath = ckpt_path + \"/CKP_ep_{epoch:d}__loss_{val_loss:.5f}_.h5\"\n",
    "\n",
    "# validation loss에 대해서 좋은 것만 저장됨\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True\n",
    ")\n",
    "\n",
    "# early stop 하는 부분인데, validation loss에 대해서 제일 좋은 모델이 저장됨\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Training part\n",
    "\n",
    "epoch = args.n_epochs\n",
    "strategy = tf.distribute.MirroredStrategy() # '/gpu:0','/gpu:1','/gpu:2','/gpu:4','/gpu:5','/gpu:6','/gpu:7'\n",
    "#physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.set_visible_devices(physical_devices[0:7], 'GPU')\n",
    "#strategy =  tf.distribute.MultiWorkerMirroredStrategy()\n",
    "print('장치의 수: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # 사용 안할 때는 load_model 주석 처리 하자\n",
    "#     model = load_model('./CKPT/CKP_ep_29__loss_102.63367_.h5', custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "\n",
    "    model = build_real_T5(args.input_size, args.output_size, args)\n",
    "    #if args.is_load_model is True:\n",
    "\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49db6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training and validation loss graph\n",
    "\n",
    "def graph_util(history):\n",
    "    fig = plt.figure()\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plt.plot(history.history['loss'], c='b')\n",
    "    plt.plot(history.history['val_loss'], c='r')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training loss', 'validation loss'], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fea43a71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9a48caa76bb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgraph_util\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "graph_util(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f54d599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aad4e4",
   "metadata": {},
   "source": [
    "# Predict\n",
    "- 만들어봅시다. token by token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "832bf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7701076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp, transformer, output, length=None, max_length=1800):\n",
    "    # inp sentence is portuguese, hence adding the start and end token\n",
    "    encoder_input = inp\n",
    "    max_length = inp.shape[1]\n",
    "    cur_length = output.shape[1]\n",
    "    batch_size = inp.shape[0]\n",
    "    \n",
    "    # as the target is english, the first word to the transformer should be the\n",
    "    # english start token.\n",
    "    #startMask = tf.cast(tf.fill([1,258],-1),dtype=tf.float32)\n",
    "    #output = tf.expand_dims(startMask, 0)\n",
    "    #output = tf.repeat(output, batch_size, 0)\n",
    "    #zero_clipping = tf.constant([0.])\n",
    "    output = tf.cast(output,tf.float32)\n",
    "    print(\"output:\",output)\n",
    "\n",
    "    progress_bar = tqdm(range(max_length-cur_length))\n",
    "    for i in range(max_length-cur_length):\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions = transformer((encoder_input, output, length), training=False)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "        #predictions = tf.math.maximum(predictions, zero_clipping)\n",
    "        predicted_id = predictions\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=1)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e159bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p(args.test_wav_dir) # Result wav 폴더 만드는 코드\n",
    "\n",
    "sample_rate = 8000\n",
    "window_size = 256\n",
    "window_shift = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d27ad503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"t5_changed_stft_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_28 (TFOpLamb (3,)                 0           input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_28 (TFOpLa None                 0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_49 (Sl ()                   0           tf.compat.v1.shape_28[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.sequence_mask_21 (TFOpLambda None                 0           tf.compat.v1.squeeze_28[0][0]    \n",
      "                                                                 tf.__operators__.getitem_49[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_21 (TFOpLambda)         None                 0           tf.sequence_mask_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_28 (TFOpLambda None                 0           tf.cast_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_50 (Sl None                 0           tf.math.subtract_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_31 (TFOpLa None                 0           tf.__operators__.getitem_50[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "t5_model_no_mask_creation_model (None, None, 40)     37833768    input_22[0][0]                   \n",
      "                                                                 tf.compat.v1.squeeze_31[0][0]    \n",
      "                                                                 input_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,833,768\n",
      "Trainable params: 37,833,768\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    ckpt_path = args.ckpt_path\n",
    "    model_path = ckpt_path + \"/CKP_ep_8__loss_0.00011_.h5\"\n",
    "\n",
    "    # T5 load\n",
    "    if True:\n",
    "        model = build_real_T5(args.input_size, args.output_size, args)\n",
    "        model.load_weights(model_path)\n",
    "    # baseline\n",
    "    if False:\n",
    "        model = load_model(model_path, custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "    cnt = 0\n",
    "    check = 0\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7e59858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 40), dtype=float64, numpy=\n",
       "array([[[-1.52587891e-04,  9.15527344e-05,  1.22070312e-04,\n",
       "         -1.83105469e-04, -9.15527344e-05, -6.10351562e-05,\n",
       "         -3.05175781e-04, -3.05175781e-05, -9.15527344e-05,\n",
       "         -2.44140625e-04, -1.83105469e-04, -1.83105469e-04,\n",
       "          3.05175781e-05,  3.05175781e-05, -9.15527344e-05,\n",
       "         -5.49316406e-04, -6.71386719e-04, -1.22070312e-03,\n",
       "         -5.79833984e-04, -5.79833984e-04, -3.35693359e-04,\n",
       "         -5.49316406e-04, -3.05175781e-04, -1.52587891e-04,\n",
       "         -2.44140625e-04,  6.10351562e-05,  4.27246094e-04,\n",
       "          6.71386719e-04,  3.05175781e-04,  0.00000000e+00,\n",
       "         -3.05175781e-05, -2.74658203e-04, -6.10351562e-05,\n",
       "         -3.05175781e-04, -6.10351562e-05,  9.15527344e-05,\n",
       "         -3.96728516e-04, -3.96728516e-04, -6.10351562e-04,\n",
       "         -6.71386719e-04]],\n",
       "\n",
       "       [[-1.52587891e-04,  9.15527344e-05,  1.52587891e-04,\n",
       "         -2.13623047e-04, -1.22070312e-04, -9.15527344e-05,\n",
       "         -3.66210938e-04, -6.10351562e-05, -9.15527344e-05,\n",
       "         -2.74658203e-04, -2.13623047e-04, -2.13623047e-04,\n",
       "          6.10351562e-05,  3.05175781e-05, -9.15527344e-05,\n",
       "         -6.40869141e-04, -7.62939453e-04, -1.43432617e-03,\n",
       "         -6.71386719e-04, -7.01904297e-04, -3.96728516e-04,\n",
       "         -6.40869141e-04, -3.66210938e-04, -1.83105469e-04,\n",
       "         -3.05175781e-04,  9.15527344e-05,  4.88281250e-04,\n",
       "          7.93457031e-04,  3.35693359e-04,  0.00000000e+00,\n",
       "         -3.05175781e-05, -3.05175781e-04, -6.10351562e-05,\n",
       "         -3.66210938e-04, -6.10351562e-05,  9.15527344e-05,\n",
       "         -4.57763672e-04, -4.57763672e-04, -7.32421875e-04,\n",
       "         -7.93457031e-04]]])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.slice(mix_pad,[0,0,0],[-1,1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f7c247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tf.Tensor(\n",
      "[[[-1.5258789e-04  9.1552734e-05  1.5258789e-04 -2.1362305e-04\n",
      "   -9.1552734e-05 -9.1552734e-05 -3.3569336e-04 -3.0517578e-05\n",
      "   -9.1552734e-05 -2.4414062e-04 -2.1362305e-04 -2.1362305e-04\n",
      "    3.0517578e-05  3.0517578e-05 -9.1552734e-05 -6.1035156e-04\n",
      "   -7.3242188e-04 -1.3427734e-03 -6.1035156e-04 -6.4086914e-04\n",
      "   -3.6621094e-04 -6.1035156e-04 -3.3569336e-04 -1.5258789e-04\n",
      "   -2.7465820e-04  9.1552734e-05  4.5776367e-04  7.3242188e-04\n",
      "    3.3569336e-04  0.0000000e+00 -3.0517578e-05 -3.0517578e-04\n",
      "   -6.1035156e-05 -3.3569336e-04 -6.1035156e-05  9.1552734e-05\n",
      "   -4.2724609e-04 -4.2724609e-04 -6.7138672e-04 -7.6293945e-04]]\n",
      "\n",
      " [[ 3.6621094e-04 -9.1552734e-05 -9.1552734e-05 -6.1035156e-04\n",
      "   -3.9672852e-04 -1.5258789e-04 -5.1879883e-04 -5.4931641e-04\n",
      "   -4.2724609e-04  0.0000000e+00  3.6621094e-04 -2.7465820e-04\n",
      "   -3.6621094e-04 -2.4414062e-04 -3.9672852e-04  3.3569336e-04\n",
      "   -1.5258789e-04 -3.9672852e-04 -6.1035156e-05  2.4414062e-04\n",
      "    1.2207031e-04 -6.4086914e-04 -5.7983398e-04 -2.1362305e-04\n",
      "   -2.7465820e-04 -3.0517578e-05 -3.0517578e-05 -2.4414062e-04\n",
      "    1.2207031e-04  1.5258789e-04  0.0000000e+00 -4.5776367e-04\n",
      "    1.5258789e-04  6.1035156e-05  0.0000000e+00 -6.1035156e-05\n",
      "    1.5258789e-04  9.1552734e-05  0.0000000e+00  1.8310547e-04]]], shape=(2, 1, 40), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938a264f567d413cbbb672f5e6322451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-3f1b1f898d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtar_inp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmix_pad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmix_pad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmix_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-0cb54b470f27>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(inp, transformer, output, length, max_length)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcur_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# predictions.shape == (batch_size, seq_len, vocab_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# select the last word from the seq_len dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 415\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\J_and_J_Research\\src\\models\\Real_Layers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m         outputs = self.t5(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids, \n\u001b[1;32m-> 1134\u001b[1;33m              training=False) # (batch_size, tar_seq_len, target_vocab_size)\n\u001b[0m\u001b[0;32m   1135\u001b[0m         \u001b[1;31m#inputs = tf.concat([inp,inp],2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m         \u001b[1;31m#print('mask_output',final_output.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\J_and_J_Research\\src\\models\\Real_Layers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1043\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m             )\n\u001b[0;32m   1047\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseModelOutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\J_and_J_Research\\src\\models\\Real_Layers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    763\u001b[0m                 \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m                 \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             )\n\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\J_and_J_Research\\src\\models\\Real_Layers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m         )\n\u001b[0;32m    478\u001b[0m         \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpresent_key_value_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\J_and_J_Research\\src\\models\\Real_Layers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         )\n\u001b[0;32m    388\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\J_and_J_Research\\src\\models\\Real_Layers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 \u001b[0mposition_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposition_bias\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmask\u001b[0m  \u001b[1;31m# (batch_size, n_heads, seq_length, key_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mposition_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1698\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1699\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1700\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qkrwo\\anaconda3\\envs\\nlp_task\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 451\u001b[1;33m         _ctx, \"AddV2\", name, x, y)\n\u001b[0m\u001b[0;32m    452\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in test_dataset:\n",
    "    mix_pad, tiled, lengths, names = batch\n",
    "    # input_batch, angle_batch, label_batch, name, length\n",
    "    tf.executing_eagerly() # requires r1.7\n",
    "    \n",
    "    \n",
    "    #startMask = tf.cast(tf.fill([tf.shape(label_batch)[0], 1, tf.shape(label_batch)[-1]],-1),dtype=tf.float32)\n",
    "    #tar = tf.concat([startMask, label_batch],1)\n",
    "    max_length = 132\n",
    "    tar_inp = mix_pad[:, :-2, :]\n",
    "    cnt = 0\n",
    "    check = 0\n",
    "    results = tf.reshape(result,[mix_pad.shape[0],-1,1])\n",
    "    sample_rate = 8000\n",
    "    output = tf.slice(mix_pad,[0,0,0],[-1,1,-1])\n",
    "    result = evaluate(mix_pad, model, output, lengths, max_length)\n",
    "    for i in range(mix_pad.shape[0]):\n",
    "        wav_name = names[i]\n",
    "        wav_name1 = args.test_wav_dir + '/' + wav_name + '_s1.wav'\n",
    "        wav = tf.squeeze(results[i,:,:]).numpy()\n",
    "        audiowrite(wav, wav_name1, sample_rate, True, True)\n",
    "    if check == -1:\n",
    "        break\n",
    "\n",
    "    if (cnt + 1) % 10 == 0:\n",
    "        print((cnt + 1) * args.batch_size)\n",
    "\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6710bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "check = 0\n",
    "results = tf.reshape(result,[mix_pad.shape[0],-1,1])\n",
    "sample_rate = 8000\n",
    "for i in range(mix_pad.shape[0]):\n",
    "    wav_name = names[i].strip()\n",
    "    wav_name1 = args.test_wav_dir + '/' + wav_name + '_s1.wav'\n",
    "    wav = tf.squeeze(results[i,:,:]).numpy()\n",
    "    wav = wav[:lengths[i]*40]\n",
    "    audiowrite(wav, wav_name1, sample_rate, True, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "baadd843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.18641873 -0.18021329 -0.1403747  -0.09617954 -0.16668871 -0.12911767\n",
      " -0.11958054 -0.14608869 -0.1580817  -0.15201487 -0.1519129 ], shape=(11,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.2207031e-03, -1.0681152e-03, -7.6293945e-04, -3.6621094e-04,\n",
       "       -6.7138672e-04, -4.5776367e-04, -9.1552734e-05, -3.3569336e-04,\n",
       "       -5.7983398e-04, -2.7465820e-04, -9.1552734e-05], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result[0][1][0:11])\n",
    "signal[0][40:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8bf6b017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18021329, -0.1403747 , -0.09617954, -0.16668871, -0.12911767,\n",
       "       -0.11958054, -0.14608869, -0.1580817 , -0.15201487, -0.1519129 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = tf.reshape(result,[mix_pad.shape[0],-1,1])\n",
    "print(tf.squeeze(results[0,:,:]).numpy()[41:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b336908c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate = 8000\n",
    "audiowrite(tf.squeeze(results[0,:,:]).numpy(), \"C:/J_and_J_Research/test_wav/gen/test.wav\", sample_rate, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "for i in range(args.batch_size):\n",
    "    if i >= input_batch.shape[0]:\n",
    "        check = -1\n",
    "        break\n",
    "    else:\n",
    "        wav_name = name[i][0].numpy().decode('utf-8')\n",
    "\n",
    "        wav_name1 = args.test_wav_dir + '/' + wav_name + '_s1.wav'\n",
    "        wav_name2 = args.test_wav_dir + '/' + wav_name + '_s2.wav'\n",
    "        wav1 = istft(spec1[i, 0:input_batch[i].shape[0], :], size=window_size, shift=window_shift)\n",
    "        wav2 = istft(spec2[i, 0:input_batch[i].shape[0], :], size=window_size, shift=window_shift)\n",
    "        audiowrite(wav1, wav_name1, sample_rate, True, True)\n",
    "        audiowrite(wav2, wav_name2, sample_rate, True, True)\n",
    "\n",
    "if check == -1:\n",
    "    break\n",
    "\n",
    "if (cnt + 1) % 10 == 0:\n",
    "    print((cnt + 1) * args.batch_size)\n",
    "\n",
    "cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7ef9f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write as wav_write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "18012dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"example2.wav\", sample_rate, tf.squeeze(train_test[1,:,:]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3c41d932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20463917"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(results[0,:,:]).numpy().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "183ebba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = librosa.load(\"C:/J_and_J_Research/mycode/wsj0_2mix/use_this/tt/s1/447o0302_0.62948_441c0212_-0.62948.wav\", sr=sample_rate, mono=False, offset=0.0, duration=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "250e1f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 56480, 1), dtype=float64, numpy=\n",
       "array([[[-1.52587891e-04],\n",
       "        [ 9.15527344e-05],\n",
       "        [ 1.52587891e-04],\n",
       "        ...,\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00]],\n",
       "\n",
       "       [[-1.52587891e-04],\n",
       "        [ 9.15527344e-05],\n",
       "        [ 1.52587891e-04],\n",
       "        ...,\n",
       "        [-6.40869141e-04],\n",
       "        [ 7.62939453e-04],\n",
       "        [-6.22558594e-03]]])>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_test = tf.reshape(next(iter(train_dataset))[0],[mix_pad.shape[0],-1,1])\n",
    "train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "27201e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "write(\"test.wav\", sample_rate, signal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "41b08c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audiowrite(data, path, samplerate=16000, normalize=False, threaded=True):\n",
    "    \"\"\" Write the audio data ``data`` to the wav file ``path``\n",
    "    The file can be written in a threaded mode. In this case, the writing\n",
    "    process will be started at a separate thread. Consequently, the file will\n",
    "    not be written when this function exits.\n",
    "    :param data: A numpy array with the audio data\n",
    "    :param path: The wav file the data should be written to\n",
    "    :param samplerate: Samplerate of the audio data\n",
    "    :param normalize: Normalize the audio first so that the values are within\n",
    "        the range of [INTMIN, INTMAX]. E.g. no clipping occurs\n",
    "    :param threaded: If true, the write process will be started as a separate\n",
    "        thread\n",
    "    :return: The number of clipped samples\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    int16_max = np.iinfo(np.int16).max\n",
    "    int16_min = np.iinfo(np.int16).min\n",
    "\n",
    "    if normalize:\n",
    "        if not data.dtype.kind == 'f':\n",
    "            data = data.astype(np.float)\n",
    "        data /= np.max(np.abs(data))\n",
    "\n",
    "    if data.dtype.kind == 'f':\n",
    "        data *= int16_max\n",
    "\n",
    "    sample_to_clip = np.sum(data > int16_max)\n",
    "    if sample_to_clip > 0:\n",
    "        print('Warning, clipping {} samples'.format(sample_to_clip))\n",
    "    data = np.clip(data, int16_min, int16_max)\n",
    "    data = data.astype(np.int16)\n",
    "\n",
    "    if threaded:\n",
    "        threading.Thread(target=wav_write, args=(path, samplerate, data)).start()\n",
    "    else:\n",
    "        wav_write(path, samplerate, data)\n",
    "\n",
    "    return sample_to_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab19e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
