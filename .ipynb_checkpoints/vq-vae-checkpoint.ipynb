{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frank-northwest",
   "metadata": {},
   "source": [
    "# 1. Data Generator\n",
    "- Raw Data를 읽어옴\n",
    "- 여기서 만들어진 데이터는 모델의 입력으로 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "requested-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "architectural-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawForVAEGenerator(Sequence):\n",
    "    def __init__(self, source, wav_dir, files, sourNum='s1', batch_size=10, shuffle=True):\n",
    "        self.source = source\n",
    "        self.wav_dir = wav_dir\n",
    "        self.files = files\n",
    "        self.sourNum = sourNum\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        self.sample_rate = 8000\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.source))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __audioread__(self, path, offset=0.0, duration=None, sample_rate=16000):\n",
    "        signal = librosa.load(path, sr=self.sample_rate, mono=False, offset=offset, duration=duration)\n",
    "\n",
    "        return signal[0]\n",
    "    \n",
    "    def __padding__(self, data):\n",
    "        n_batch = len(data)\n",
    "        max_len = max([d.shape[0] for d in data])\n",
    "        extrapadding = int(np.ceil(max_len / self.sample_rate) * self.sample_rate)\n",
    "        pad = np.zeros((n_batch, extrapadding))\n",
    "        \n",
    "        for i in range(n_batch):\n",
    "            pad[i, :data[i].shape[0]] = data[i]\n",
    "        \n",
    "        return np.expand_dims(pad, -1)\n",
    "        \n",
    "    def __data_generation__(self, source_list):\n",
    "        wav_list = []\n",
    "        for name in source_list:\n",
    "            name = name.strip('\\n')\n",
    "            \n",
    "            s_wav_name = self.wav_dir + self.files + '/' + self.sourNum + '/' + name\n",
    "            \n",
    "            # ------- AUDIO READ -------\n",
    "            s_wav = (self.__audioread__(s_wav_name,  offset=0.0, duration=None, sample_rate=self.sample_rate))\n",
    "            # --------------------------\n",
    "            \n",
    "            # ------- PADDING -------\n",
    "#             pad_len = max(len(samples1),len(samples2))\n",
    "#             pad_s1 = np.concatenate([s1_wav, np.zeros([pad_len - len(s1_wav)])])\n",
    "            \n",
    "#             extrapadding = ceil(len(pad_s1) / sample_rate) * sample_rate - len(pad_s1)\n",
    "#             pad_s1 = np.concatenate([pad_s1, np.zeros([extrapadding - len(pad_s1)])])\n",
    "#             pad_s2 = np.concatenate([s2_wav, np.zeros([extrapadding - len(s2_wav)])])\n",
    "            # -----------------------\n",
    "            \n",
    "            wav_list.append(s_wav)\n",
    "        \n",
    "        return wav_list, wav_list\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.source) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        source_list = [self.source[k] for k in indexes]\n",
    "        \n",
    "        if self.files is not 'tt':\n",
    "            sour, labels = self.__data_generation__(source_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in sour])\n",
    "            exp = np.expand_dims(lengths, 1)\n",
    "            exp = np.expand_dims(exp, -1) # [Batch, 1, 1] (length)\n",
    "            \n",
    "            # Padding\n",
    "            sour_pad = self.__padding__(sour) # [Batch, Time_step, Dimension(=1)]\n",
    "            label_pad = self.__padding__(labels) # [Batch, Time_step, Dimension(=1)]\n",
    "            \n",
    "            return sour_pad, np.concatenate([label_pad, exp], axis=1)\n",
    "        else:\n",
    "            sour, labels = self.__data_generation__(source_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in sour])\n",
    "            exp = np.expand_dims(lengths, 1)\n",
    "            exp = np.expand_dims(exp, -1) # [Batch, 1, 1] (length)\n",
    "            \n",
    "            # Padding\n",
    "            sour_pad = self.__padding__(sour) # [Batch, Time_step, Dimension(=1)]\n",
    "            \n",
    "            return sour_pad, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-league",
   "metadata": {},
   "source": [
    "## Data를 어떻게 읽는지에 대한 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "martial-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_DIR = './mycode/wsj0_2mix/use_this/'\n",
    "LIST_DIR = './mycode/wsj0_2mix/use_this/lists/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attached-debate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate wav file to .lst done!\n"
     ]
    }
   ],
   "source": [
    "# Directory List file create\n",
    "\n",
    "wav_dir = WAV_DIR\n",
    "output_lst = LIST_DIR\n",
    "\n",
    "for folder in ['tr', 'cv', 'tt']:\n",
    "    wav_files = os.listdir(wav_dir + folder + '/mix')\n",
    "    output_lst_files = output_lst + folder + '_wav.lst'\n",
    "    with open(output_lst_files, 'w') as f:\n",
    "        for file in wav_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "print(\"Generate wav file to .lst done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comparable-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "train_dataset = 0\n",
    "valid_dataset = 0\n",
    "test_dataset = 0\n",
    "\n",
    "name_list = []\n",
    "for files in ['tr', 'cv', 'tt']:\n",
    "    # --- Lead lst file ---\"\"\n",
    "    output_lst_files = LIST_DIR + files + '_wav.lst'\n",
    "    fid = open(output_lst_files, 'r')\n",
    "    lines = fid.readlines()\n",
    "    fid.close()\n",
    "    # ---------------------\n",
    "    \n",
    "    if files == 'tr':\n",
    "        train_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "    elif files == 'cv':\n",
    "        valid_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "    else:\n",
    "        test_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "a, b = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-russian",
   "metadata": {},
   "source": [
    "# 2. Building VQ-VAE model with Gumbel Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "environmental-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras import backend as Kb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "sexual-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    \"\"\" Creates a path recursively without throwing an error if it already exists\n",
    "    :param path: path to create\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "piano-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./CKPT/') # model check point 폴더 만드는 코드\n",
    "filepath = \"./CKPT/CKP_ep_{epoch:d}__loss_{val_loss:.5f}_.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "printable-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "\n",
    "# learning rate를 점점 줄이는 부분\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# validation loss에 대해서 좋은 것만 저장됨\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
    ")\n",
    "\n",
    "# early stop 하는 부분인데, validation loss에 대해서 제일 좋은 모델이 저장됨\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "forward-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(q_y, latent_dim):\n",
    "    def si_sdr_loss(y_true, y_pred):\n",
    "        ori_length = tf.shape(y_true)[1]\n",
    "\n",
    "        # Label & Length divide\n",
    "        labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 1]\n",
    "        lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "\n",
    "        \n",
    "        target = tf.reduce_sum([y_pred, labels]) * labels / tf.experimental.numpy.square(labels)\n",
    "        noise = y_pred - target\n",
    "        si_sdr = 10 * np.log10(pow_np_norm(target) / tf.experimental.numpy.square(noise))\n",
    "        sdr = si_sdr * -0.5\n",
    "\n",
    "        return sdr\n",
    "    \n",
    "    log_q_y = tf.math.log(q_y+1e-20)\n",
    "    kl_loss = tf.reduce_sum(q_y*(log_q_y-tf.math.log(1.0/latent_dim)), axis=[1,2])\n",
    "    \n",
    "    return si_sdr_loss - kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "renewable-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vq_vae(keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Vq_vae, self).__init__(name='vqvae')\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer(input_shape=(None, 1)),\n",
    "                layers.Conv1D(\n",
    "                    filters=64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "                layers.Conv1D(\n",
    "                    filters=128, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "                layers.Conv1D(\n",
    "                    filters=self.latent_dim, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer(input_shape=(None, self.latent_dim)),\n",
    "                layers.Conv1DTranspose(\n",
    "                    filters=128, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "                layers.Conv1DTranspose(\n",
    "                    filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "                layers.Conv1DTranspose(\n",
    "                    filters=1, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def sample_gumbel(self, shape, eps=1e-20): \n",
    "        \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "        U = tf.random.uniform(shape,minval=0,maxval=1)\n",
    "        \n",
    "        return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
    "\n",
    "    def gumbel_softmax_sample(self, logits, temperature): \n",
    "        \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "        y = logits + self.sample_gumbel(tf.shape(logits))\n",
    "        \n",
    "        return tf.nn.softmax( y / temperature)\n",
    "\n",
    "    def gumbel_softmax(self, logits, temperature, hard=False):\n",
    "        y = self.gumbel_softmax_sample(logits, temperature)\n",
    "        if hard:\n",
    "            k = tf.shape(logits)[-1]\n",
    "            #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "            y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "            y = tf.stop_gradient(y_hard - y) + y\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def vae_loss(self, enc):\n",
    "        q_y = tf.nn.softmax(enc, axis=-1)\n",
    "        log_q_y = tf.math.log(q_y+1e-20)\n",
    "        kl_loss = tf.reduce_sum(q_y*(log_q_y-tf.math.log(1.0/self.latent_dim)), axis=[1,2])\n",
    "#         elbo = mse_loss - kl_loss\n",
    "#         loss=tf.reduce_mean(-elbo)\n",
    "        \n",
    "        return kl_loss\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        encoder = self.encoder(inputs)\n",
    "        z_latent = self.gumbel_softmax(encoder, 0.9)\n",
    "        decoder = self.decoder(z_latent)\n",
    "        \n",
    "        self.add_loss(tf.reduce_mean(tf.reduce_sum(keras.metrics.mean_squared_error(inputs, decoder), axis=[-1]) - self.vae_loss(encoder)))\n",
    "#         self.add_loss(tf.reduce_mean(tf.reduce_sum(keras.metrics.mean_squared_error(inputs, decoder), axis=[-1])))\n",
    "        \n",
    "        return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "lucky-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_loss(model, x, latent_dim):\n",
    "#     enc, latent = model.encode(x)\n",
    "#     x_logit = model.decode(enc)\n",
    "#     mse_loss = tf.reduce_sum(keras.metrics.mean_squared_error(x, x_logit), axis=[-1])\n",
    "    \n",
    "#     q_y = tf.nn.softmax(enc, axis=-1)\n",
    "#     log_q_y = tf.log(q_y+1e-20)\n",
    "#     kl_loss = tf.reduce_sum(q_y*(log_q_y-tf.log(1.0/latent_dim)), axis=[1,2])\n",
    "#     elbo = mse_loss - kl_loss\n",
    "#     loss=tf.reduce_mean(-elbo)\n",
    "    \n",
    "#     return loss\n",
    "\n",
    "# def train_step(model, x, optimizer, latent_size):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         loss = compute_loss(model, x, latent_size)\n",
    "#     gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "controlling-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 2\n",
    "# latent_size = 512\n",
    "# model = Vq_vae(latent_size)\n",
    "# optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     start_time = time.time()\n",
    "#     for train_x in train_dataset:\n",
    "#         train_step(model, train_x, optimizer, latent_size)\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     loss = keras.metrics.Mean()\n",
    "#     for valid_x in valid_dataset:\n",
    "#         loss(compute_loss(model, valid_x))\n",
    "#     elbo = -loss.result()\n",
    "#     display.clear_output(wait=False)\n",
    "#     print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "#         .format(epoch, elbo, end_time - start_time))\n",
    "#     generate_and_save_images(model, epoch, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "referenced-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "장치의 수: 1\n",
      "Model: \"vqvae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_19 (Sequential)   (None, None, 512)         222080    \n",
      "_________________________________________________________________\n",
      "sequential_20 (Sequential)   (None, None, 1)           221569    \n",
      "=================================================================\n",
      "Total params: 443,649\n",
      "Trainable params: 443,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 4s 2s/step - loss: 313.7568 - val_loss: 313.5043\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 313.4528 - val_loss: 313.1735\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 1s 575ms/step - loss: 312.9970 - val_loss: 312.2957\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 1s 527ms/step - loss: 311.7184 - val_loss: 310.0528\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 308.8851 - val_loss: 304.9203\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 301.8480 - val_loss: 293.0833\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 288.5620 - val_loss: 270.1513\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 1s 584ms/step - loss: 261.6838 - val_loss: 226.4555\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 1s 477ms/step - loss: 210.9068 - val_loss: 155.1283\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 120.6778 - val_loss: 22.5159\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 1s 592ms/step - loss: -46.8037 - val_loss: -216.8244\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 1s 501ms/step - loss: -287.3662 - val_loss: -522.2502\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 1s 544ms/step - loss: -701.2080 - val_loss: -1092.6537\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 1s 482ms/step - loss: -1149.8364 - val_loss: -1816.2581\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 1s 485ms/step - loss: -1873.2369 - val_loss: -2568.3630\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 1s 448ms/step - loss: -2766.6179 - val_loss: -3767.2466\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 1s 509ms/step - loss: -4001.0381 - val_loss: -4812.1270\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 1s 543ms/step - loss: -5032.7959 - val_loss: -5453.2109\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 1s 566ms/step - loss: -6045.4600 - val_loss: -6716.7627\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 1s 507ms/step - loss: -6931.8730 - val_loss: -7716.7627\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 1s 531ms/step - loss: -7568.5635 - val_loss: -8334.6621\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 1s 484ms/step - loss: -8591.3652 - val_loss: -9634.5586\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 1s 577ms/step - loss: -10649.2090 - val_loss: -11833.0332\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 1s 475ms/step - loss: -11507.2031 - val_loss: -13635.1719\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 1s 548ms/step - loss: -14147.7900 - val_loss: -15476.1885\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 1s 531ms/step - loss: -15962.8721 - val_loss: -17211.9004\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 1s 549ms/step - loss: -16714.3633 - val_loss: -18984.8809\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 1s 564ms/step - loss: -19434.4766 - val_loss: -21075.7871\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 1s 512ms/step - loss: -21579.3652 - val_loss: -22002.9688\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 1s 475ms/step - loss: -23795.1309 - val_loss: -23993.2305\n"
     ]
    }
   ],
   "source": [
    "latent_size = 512\n",
    "epoch = 30\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(['cpu:0'])\n",
    "print('장치의 수: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # 사용 안할 때는 load_model 주석 처리 하자\n",
    "#     model = load_model('./CKPT/CKP_ep_29__loss_102.63367_.h5', custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "    inputs = layers.Input(shape=(None, 1))\n",
    "    model = Vq_vae(latent_size)\n",
    "    model(inputs)\n",
    "    adam = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam)\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-roots",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a8314750",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = np.random.rand(2, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e108087",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vq_vae(keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Vq_vae, self).__init__(name='vqvae')\n",
    "        self.latent_dim = latent_dim\n",
    "#         self.encoder = keras.Sequential(\n",
    "#             [\n",
    "#                 layers.InputLayer(input_shape=(None, 1)),\n",
    "#                 layers.Conv1D(\n",
    "#                     filters=64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "#                 layers.Conv1D(\n",
    "#                     filters=128, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "#             ]\n",
    "#         )\n",
    "        \n",
    "        self.v1 = layers.Conv1D(\n",
    "                    filters=64, kernel_size=3, strides=2, activation='relu', padding='valid', input_shape=(None, 1))\n",
    "        self.v2 = layers.Conv1D(\n",
    "                    filters=1, kernel_size=3, strides=2, activation='relu', padding='same')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.v1(inputs)\n",
    "        x = self.v2(x)\n",
    "        \n",
    "#         self.add_loss(tf.reduce_mean(tf.reduce_sum(keras.metrics.mean_squared_error(inputs, decoder), axis=[-1]) - vae_loss(encoder)))\n",
    "#         self.add_loss(tf.reduce_mean(tf.reduce_sum(keras.metrics.mean_squared_error(inputs, x), axis=[-1])))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf110b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e4907347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model\n",
    "\n",
    "def uPIT(batch):\n",
    "    inputs = layers.Input(shape=(None, 1))\n",
    "    \n",
    "    outputs = layers.Conv1D(\n",
    "                    filters=32, kernel_size=3, strides=2, activation='relu', padding='same', input_shape=(None, 1))(inputs)\n",
    "    model = layers.Conv1D(\n",
    "                    filters=64, kernel_size=3, strides=2, activation='relu', padding='same')(outputs)\n",
    "    model = layers.Conv1DTranspose(\n",
    "                    filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(model)\n",
    "    model = layers.Conv1DTranspose(\n",
    "                    filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(model)\n",
    "    \n",
    "    model = keras.Model(inputs, model)\n",
    "    \n",
    "    model.summary()\n",
    "    adam = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(loss=keras.losses.mean_squared_error, optimizer=adam)\n",
    "#     model.compile(loss=keras.losses.mean_squared_error, optimizer=adam)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4569ddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "장치의 수: 1\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        [(None, None, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, None, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, None, 64)          6208      \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_28 (Conv1DT (None, None, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_29 (Conv1DT (None, None, 64)          12352     \n",
      "=================================================================\n",
      "Total params: 31,040\n",
      "Trainable params: 31,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  Incompatible shapes: [2,80000,64] vs. [2,80001,1]\n\t [[node gradient_tape/mean_squared_error/BroadcastGradientArgs (defined at \\threading.py:916) ]]\n\t [[GroupCrossDeviceControlEdges_0/Identity_2/_21]]\n  (1) Invalid argument:  Incompatible shapes: [2,80000,64] vs. [2,80001,1]\n\t [[node gradient_tape/mean_squared_error/BroadcastGradientArgs (defined at \\threading.py:916) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_31911]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-a5639475dd35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  Incompatible shapes: [2,80000,64] vs. [2,80001,1]\n\t [[node gradient_tape/mean_squared_error/BroadcastGradientArgs (defined at \\threading.py:916) ]]\n\t [[GroupCrossDeviceControlEdges_0/Identity_2/_21]]\n  (1) Invalid argument:  Incompatible shapes: [2,80000,64] vs. [2,80001,1]\n\t [[node gradient_tape/mean_squared_error/BroadcastGradientArgs (defined at \\threading.py:916) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_31911]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "latent_size = 512\n",
    "epoch = 5\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(['cpu:0'])\n",
    "print('장치의 수: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # 사용 안할 때는 load_model 주석 처리 하자\n",
    "#     model = load_model('./CKPT/CKP_ep_29__loss_102.63367_.h5', custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "#     inputs = layers.Input(shape=(None, 1))\n",
    "#     model = Vq_vae(latent_size)\n",
    "#     model(inputs)\n",
    "#     adam = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "#     model.summary()\n",
    "#     model.compile(loss=keras.losses.mean_squared_error, optimizer=adam)\n",
    "#     tf.executing_eagerly()\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     epochs=epoch,\n",
    "#     validation_data=valid_dataset,\n",
    "#     shuffle=True,\n",
    "#     callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "# )\n",
    "\n",
    "    model = uPIT(2)\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbe1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
