{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frank-northwest",
   "metadata": {},
   "source": [
    "# 1. Data Generator\n",
    "- Raw Data를 읽어옴\n",
    "- 여기서 만들어진 데이터는 모델의 입력으로 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "requested-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "architectural-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawForVAEGenerator(Sequence):\n",
    "    def __init__(self, source, wav_dir, files, sourNum='s1', batch_size=10, shuffle=True):\n",
    "        self.source = source\n",
    "        self.wav_dir = wav_dir\n",
    "        self.files = files\n",
    "        self.sourNum = sourNum\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        self.sample_rate = 8000\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.source))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __audioread__(self, path, offset=0.0, duration=None, sample_rate=16000):\n",
    "        signal = librosa.load(path, sr=self.sample_rate, mono=False, offset=offset, duration=duration)\n",
    "\n",
    "        return signal[0]\n",
    "    \n",
    "    def __padding__(self, data):\n",
    "        n_batch = len(data)\n",
    "        max_len = max([d.shape[0] for d in data])\n",
    "        extrapadding = int(np.ceil(max_len / self.sample_rate) * self.sample_rate)\n",
    "        pad = np.zeros((n_batch, extrapadding))\n",
    "        \n",
    "        for i in range(n_batch):\n",
    "            pad[i, :data[i].shape[0]] = data[i]\n",
    "        \n",
    "        return np.expand_dims(pad, -1)\n",
    "        \n",
    "    def __data_generation__(self, source_list):\n",
    "        wav_list = []\n",
    "        for name in source_list:\n",
    "            name = name.strip('\\n')\n",
    "            \n",
    "            s_wav_name = self.wav_dir + self.files + '/' + self.sourNum + '/' + name\n",
    "            \n",
    "            # ------- AUDIO READ -------\n",
    "            s_wav = (self.__audioread__(s_wav_name,  offset=0.0, duration=None, sample_rate=self.sample_rate))\n",
    "            # --------------------------\n",
    "            \n",
    "            # ------- PADDING -------\n",
    "#             pad_len = max(len(samples1),len(samples2))\n",
    "#             pad_s1 = np.concatenate([s1_wav, np.zeros([pad_len - len(s1_wav)])])\n",
    "            \n",
    "#             extrapadding = ceil(len(pad_s1) / sample_rate) * sample_rate - len(pad_s1)\n",
    "#             pad_s1 = np.concatenate([pad_s1, np.zeros([extrapadding - len(pad_s1)])])\n",
    "#             pad_s2 = np.concatenate([s2_wav, np.zeros([extrapadding - len(s2_wav)])])\n",
    "            # -----------------------\n",
    "            \n",
    "            wav_list.append(s_wav)\n",
    "        \n",
    "        return wav_list, wav_list\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.source) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        source_list = [self.source[k] for k in indexes]\n",
    "        \n",
    "        if self.files is not 'tt':\n",
    "            sour, labels = self.__data_generation__(source_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in sour])\n",
    "            exp = np.expand_dims(lengths, 1)\n",
    "            exp = np.expand_dims(exp, -1) # [Batch, 1, 1] (length)\n",
    "            \n",
    "            # Padding\n",
    "            sour_pad = self.__padding__(sour) # [Batch, Time_step, Dimension(=1)]\n",
    "            label_pad = self.__padding__(labels) # [Batch, Time_step, Dimension(=1)]\n",
    "            \n",
    "            return sour_pad, np.concatenate([label_pad, exp], axis=1)\n",
    "        else:\n",
    "            sour, labels = self.__data_generation__(source_list)\n",
    "            \n",
    "            # Get Lengths(K value of each batch)\n",
    "            lengths = np.array([m.shape[0] for m in sour])\n",
    "            exp = np.expand_dims(lengths, 1)\n",
    "            exp = np.expand_dims(exp, -1) # [Batch, 1, 1] (length)\n",
    "            \n",
    "            # Padding\n",
    "            sour_pad = self.__padding__(sour) # [Batch, Time_step, Dimension(=1)]\n",
    "            \n",
    "            return sour_pad, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-league",
   "metadata": {},
   "source": [
    "## Data를 어떻게 읽는지에 대한 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "martial-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_DIR = './mycode/wsj0_2mix/use_this/'\n",
    "LIST_DIR = './mycode/wsj0_2mix/use_this/lists/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attached-debate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate wav file to .lst done!\n"
     ]
    }
   ],
   "source": [
    "# Directory List file create\n",
    "\n",
    "wav_dir = WAV_DIR\n",
    "output_lst = LIST_DIR\n",
    "\n",
    "for folder in ['tr', 'cv', 'tt']:\n",
    "    wav_files = os.listdir(wav_dir + folder + '/mix')\n",
    "    output_lst_files = output_lst + folder + '_wav.lst'\n",
    "    with open(output_lst_files, 'w') as f:\n",
    "        for file in wav_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "print(\"Generate wav file to .lst done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comparable-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "train_dataset = 0\n",
    "valid_dataset = 0\n",
    "test_dataset = 0\n",
    "\n",
    "name_list = []\n",
    "for files in ['tr', 'cv', 'tt']:\n",
    "    # --- Lead lst file ---\"\"\n",
    "    output_lst_files = LIST_DIR + files + '_wav.lst'\n",
    "    fid = open(output_lst_files, 'r')\n",
    "    lines = fid.readlines()\n",
    "    fid.close()\n",
    "    # ---------------------\n",
    "    \n",
    "    if files == 'tr':\n",
    "        train_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "    elif files == 'cv':\n",
    "        valid_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "    else:\n",
    "        test_dataset = RawForVAEGenerator(lines, WAV_DIR, files, 's1', batch_size)\n",
    "a, b = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-russian",
   "metadata": {},
   "source": [
    "# 2. Building VQ-VAE model with Gumbel Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "environmental-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras import backend as Kb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sexual-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    \"\"\" Creates a path recursively without throwing an error if it already exists\n",
    "    :param path: path to create\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "piano-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./CKPT/') # model check point 폴더 만드는 코드\n",
    "filepath = \"./CKPT/CKP_ep_{epoch:d}__loss_{val_loss:.5f}_.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "printable-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "\n",
    "# learning rate를 점점 줄이는 부분\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# validation loss에 대해서 좋은 것만 저장됨\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
    ")\n",
    "\n",
    "# early stop 하는 부분인데, validation loss에 대해서 제일 좋은 모델이 저장됨\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "forward-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(q_y, latent_dim):\n",
    "    def si_sdr_loss(y_true, y_pred):\n",
    "        ori_length = tf.shape(y_true)[1]\n",
    "\n",
    "        # Label & Length divide\n",
    "        labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 1]\n",
    "        lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "\n",
    "        \n",
    "        target = tf.reduce_sum([y_pred, labels]) * labels / tf.experimental.numpy.square(labels)\n",
    "        noise = y_pred - target\n",
    "        si_sdr = 10 * np.log10(pow_np_norm(target) / tf.experimental.numpy.square(noise))\n",
    "        sdr = si_sdr * -0.5\n",
    "\n",
    "        return sdr\n",
    "    \n",
    "    log_q_y = tf.math.log(q_y+1e-20)\n",
    "    kl_loss = tf.reduce_sum(q_y*(log_q_y-tf.math.log(1.0/latent_dim)), axis=[1,2])\n",
    "    \n",
    "    return si_sdr_loss - kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "renewable-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vq_vae(keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Vq_vae, self).__init__(name='vqvae')\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer(input_shape=(None, 1)),\n",
    "                \n",
    "                layers.Conv1D(\n",
    "                    filters=64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "                layers.Conv1D(\n",
    "                    filters=64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "                layers.Conv1D(\n",
    "                    filters=self.latent_dim, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer(input_shape=(None, self.latent_dim)),\n",
    "                layers.Conv1DTranspose(\n",
    "                    filters=self.latent_dim, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "                layers.Conv1DTranspose(\n",
    "                    filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "                layers.Conv1DTranspose(\n",
    "                    filters=1, kernel_size=3, strides=2, padding='same', activation=None),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.softmax = layers.Softmax(-1)\n",
    "    \n",
    "    def sample_gumbel(self, shape, eps=1e-20): \n",
    "        \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "        U = tf.random.uniform(shape,minval=0,maxval=1)\n",
    "        \n",
    "        return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
    "\n",
    "    def gumbel_softmax_sample(self, logits, temperature): \n",
    "        \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "        y = logits + self.sample_gumbel(tf.shape(logits))\n",
    "        \n",
    "        return tf.nn.softmax( y / temperature)\n",
    "\n",
    "    def gumbel_softmax(self, logits, temperature, hard=False):\n",
    "        y = self.gumbel_softmax_sample(logits, temperature)\n",
    "        if hard:\n",
    "            k = tf.shape(logits)[-1]\n",
    "            #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "            y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "            y = tf.stop_gradient(y_hard - y) + y\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def vae_loss(self, enc):\n",
    "        q_y = tf.nn.softmax(enc, axis=-1)\n",
    "        log_q_y = tf.math.log(q_y+1e-20)\n",
    "        kl_loss = tf.reduce_sum(q_y*(log_q_y-tf.math.log(1.0/self.latent_dim)), axis=[1,2])\n",
    "#         elbo = mse_loss - kl_loss\n",
    "#         loss=tf.reduce_mean(-elbo)\n",
    "        \n",
    "        return kl_loss\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        encoder = self.encoder(inputs)\n",
    "        z_latent = self.gumbel_softmax(encoder, 0.9)\n",
    "        decoder = self.decoder(z_latent)\n",
    "        \n",
    "        qy = self.softmax(encoder)\n",
    "        log_qy = tf.math.log(qy + 1e-20)\n",
    "        log_uniform = qy * (log_qy - tf.math.log(1.0 / self.latent_dim))\n",
    "        kl = tf.reduce_sum(log_uniform, [1, 2])\n",
    "        print(kl.shape)\n",
    "        \n",
    "#         kl_div = keras.losses.KLDivergence(reduction=tf.keras.losses.Reduction.NONE)\n",
    "        recon = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "        loss = tf.reduce_mean(tf.reduce_sum(recon(inputs, decoder), [1]))\n",
    "#         loss = tf.reduce_mean(tf.reduce_sum(recon(inputs, decoder), [1]) + kl)\n",
    "#         loss = tf.reduce_mean(tf.reduce_sum(recon(inputs, decoder), [1]) + tf.reduce_sum(kl_div(log_qy, log_uniform), [1]))\n",
    "        \n",
    "        self.add_loss(loss)\n",
    "#         self.add_loss(tf.reduce_mean(tf.reduce_sum(keras.metrics.mean_squared_error(inputs, decoder), axis=[-1])))\n",
    "        \n",
    "        return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "lucky-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_loss(model, x, latent_dim):\n",
    "#     enc, latent = model.encode(x)\n",
    "#     x_logit = model.decode(enc)\n",
    "#     mse_loss = tf.reduce_sum(keras.metrics.mean_squared_error(x, x_logit), axis=[-1])\n",
    "    \n",
    "#     q_y = tf.nn.softmax(enc, axis=-1)\n",
    "#     log_q_y = tf.log(q_y+1e-20)\n",
    "#     kl_loss = tf.reduce_sum(q_y*(log_q_y-tf.log(1.0/latent_dim)), axis=[1,2])\n",
    "#     elbo = mse_loss - kl_loss\n",
    "#     loss=tf.reduce_mean(-elbo)\n",
    "    \n",
    "#     return loss\n",
    "\n",
    "# def train_step(model, x, optimizer, latent_size):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         loss = compute_loss(model, x, latent_size)\n",
    "#     gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "controlling-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 2\n",
    "# latent_size = 512\n",
    "# model = Vq_vae(latent_size)\n",
    "# optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     start_time = time.time()\n",
    "#     for train_x in train_dataset:\n",
    "#         train_step(model, train_x, optimizer, latent_size)\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     loss = keras.metrics.Mean()\n",
    "#     for valid_x in valid_dataset:\n",
    "#         loss(compute_loss(model, valid_x))\n",
    "#     elbo = -loss.result()\n",
    "#     display.clear_output(wait=False)\n",
    "#     print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "#         .format(epoch, elbo, end_time - start_time))\n",
    "#     generate_and_save_images(model, epoch, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "referenced-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "장치의 수: 1\n",
      "(None,)\n",
      "Model: \"vqvae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_119 (Sequential)  (None, None, 512)         111424    \n",
      "_________________________________________________________________\n",
      "sequential_120 (Sequential)  (None, None, 1)           885505    \n",
      "_________________________________________________________________\n",
      "softmax_80 (Softmax)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 996,929\n",
      "Trainable params: 996,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "(None,)\n",
      "(None,)\n",
      "2/2 [==============================] - ETA: 0s - loss: 323.4035(None,)\n",
      "2/2 [==============================] - 5s 2s/step - loss: 323.4035 - val_loss: 315.3296\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 315.5242 - val_loss: 317.1288\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 316.5795 - val_loss: 314.7923\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 1s 909ms/step - loss: 314.4385 - val_loss: 313.7832\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 1s 932ms/step - loss: 313.7586 - val_loss: 313.7109\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 1s 898ms/step - loss: 313.7409 - val_loss: 313.7654\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 313.7255 - val_loss: 313.7462\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 313.7201 - val_loss: 313.7206\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 1s 834ms/step - loss: 313.7001 - val_loss: 313.6531\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 1s 884ms/step - loss: 313.6470 - val_loss: 313.6299\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 313.6238 - val_loss: 313.6269\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 313.6066 - val_loss: 313.6171\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 313.6160 - val_loss: 313.6219\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 1s 848ms/step - loss: 313.6252 - val_loss: 313.6291\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 1s 997ms/step - loss: 313.6178 - val_loss: 313.6210\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 1s 992ms/step - loss: 313.6023 - val_loss: 313.6025\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 1s 843ms/step - loss: 313.6019 - val_loss: 313.6064\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 313.5922 - val_loss: 313.6004\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 313.5943 - val_loss: 313.6100\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 1s 830ms/step - loss: 313.6055 - val_loss: 313.6054\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 1s 841ms/step - loss: 313.5995 - val_loss: 313.6003\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 1s 823ms/step - loss: 313.6041 - val_loss: 313.5923\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 1s 885ms/step - loss: 313.5963 - val_loss: 313.5931\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 1s 1s/step - loss: 313.6023 - val_loss: 313.5954\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 1s 981ms/step - loss: 313.5889 - val_loss: 313.5923\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 1s 998ms/step - loss: 313.5961 - val_loss: 313.5961\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 1s 846ms/step - loss: 313.6038 - val_loss: 313.5969\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 1s 847ms/step - loss: 313.5984 - val_loss: 313.6011\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 1s 907ms/step - loss: 313.6010 - val_loss: 313.5939\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 1s 896ms/step - loss: 313.5924 - val_loss: 313.6005\n"
     ]
    }
   ],
   "source": [
    "latent_size = 512\n",
    "epoch = 30\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(['cpu:0'])\n",
    "print('장치의 수: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # 사용 안할 때는 load_model 주석 처리 하자\n",
    "#     model = load_model('./CKPT/CKP_ep_29__loss_102.63367_.h5', custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "    inputs = layers.Input(shape=(None, 1))\n",
    "    model = Vq_vae(latent_size)\n",
    "    model(inputs)\n",
    "    adam = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam)\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "worst-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[3.5958656e-06],\n",
       "        [3.5958656e-06],\n",
       "        [3.5958656e-06],\n",
       "        ...,\n",
       "        [3.5958656e-06],\n",
       "        [3.5958656e-06],\n",
       "        [3.5958656e-06]],\n",
       "\n",
       "       [[3.5958656e-06],\n",
       "        [3.5958656e-06],\n",
       "        [3.5958656e-06],\n",
       "        ...,\n",
       "        [3.5958656e-06],\n",
       "        [3.5958656e-06],\n",
       "        [3.5958656e-06]]], dtype=float32)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, _ = next(iter(test_dataset))\n",
    "\n",
    "pre = model.predict(data)\n",
    "pre[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "alleged-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "sd.play(pre[1][1], 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-surveillance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a8314750",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = np.random.rand(2, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbe1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "temporal-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(None, 1)))\n",
    "model.add(layers.Conv1D(filters=4, kernel_size=3, padding='same'))\n",
    "model.add(layers.Softmax(-1))\n",
    "\n",
    "input_array = np.random.randn(2, 5, 4)\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "clean-drink",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 4)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "constitutional-coral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 4, 5])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(output_array, perm=[0, 2, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "prompt-distinction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.advanced_activations.Softmax at 0x26f14e934c8>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Softmax(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "treated-flash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-citizen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
