{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increased-imperial",
   "metadata": {},
   "source": [
    "# Make wav list\n",
    "- 파일을 tr, cv, tt 폴더별로 무지성으로 읽어온 다음 각 폴더별 list를 .lst 파일로 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sound-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate wav file to .lst done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tr_wav.lst format:\n",
    "...\n",
    "447o030v_0.1232_050c0109_-0.1232.wav\n",
    "447o030v_1.7882_444o0310_-1.7882.wav\n",
    "447o030w_0.52605_446o030e_-0.52605.wav\n",
    "447o030w_1.9272_420c0203_-1.9272.wav\n",
    "447o030x_0.03457_441c0209_-0.03457.wav\n",
    "447o030x_0.70879_420o0307_-0.70879.wav\n",
    "447o030x_0.98832_441o0308_-0.98832.wav\n",
    "447o030x_1.4783_422o030p_-1.4783.wav\n",
    "...\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "wav_dir = './mycode/wsj0_2mix/use_this/'\n",
    "list_dir = './mycode/wsj0_2mix/use_this/lists/'\n",
    "\n",
    "wav_dir = wav_dir\n",
    "output_lst = list_dir\n",
    "\n",
    "for folder in ['tr', 'cv', 'tt']:\n",
    "    wav_files = os.listdir(wav_dir + folder + '/mix')\n",
    "    output_lst_files = output_lst + folder + '_wav.lst'\n",
    "    with open(output_lst_files, 'w') as f:\n",
    "        for file in wav_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "print(\"Generate wav file to .lst done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-desperate",
   "metadata": {},
   "source": [
    "# Make TFRecord file\n",
    "\n",
    "- 여기서는 위에서 만든 리스트 파일을 가지고 tfrecord data로 변환함\n",
    "- 이 섹션의 맨 아래 블럭의 코드가 본 코드인데, 읽어들인 raw data를 stft하고, stft한거를 입력으로 세팅함\n",
    "- 그리고 mix된 stft data를 통해서 label들을 뽑아내고, 따로 gender값도 읽어들임\n",
    "- 이렇게 얻게된 3개의 값(mix_stft, labels, gender)을 TFRecord 형식으로 저장함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eastern-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import argparse\n",
    "import os, sys\n",
    "from numpy.fft import rfft, irfft\n",
    "from scipy.io.wavfile import write as wav_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "severe-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    \"\"\" Creates a path recursively without throwing an error if it already exists\n",
    "    :param path: path to create\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entitled-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_axis(a, length, overlap=0, axis=None, end='cut', endvalue=0):\n",
    "    \"\"\"Generate a new array that chops the given array along the given axis into overlapping frames.\n",
    "    example:\n",
    "    >>> segment_axis(np.arange(10), 4, 2)\n",
    "    array([[0, 1, 2, 3],\n",
    "           [2, 3, 4, 5],\n",
    "           [4, 5, 6, 7],\n",
    "           [6, 7, 8, 9]])\n",
    "    arguments:\n",
    "    a       The array to segment\n",
    "    length  The length of each frame\n",
    "    overlap The number of array elements by which the frames should overlap\n",
    "    axis    The axis to operate on; if None, act on the flattened array\n",
    "    end     What to do with the last frame, if the array is not evenly\n",
    "            divisible into pieces. Options are:\n",
    "            'cut'   Simply discard the extra values\n",
    "            'wrap'  Copy values from the beginning of the array\n",
    "            'pad'   Pad with a constant value\n",
    "    endvalue    The value to use for end='pad'\n",
    "    The array is not copied unless necessary (either because it is\n",
    "    unevenly strided and being flattened or because end is set to\n",
    "    'pad' or 'wrap').\n",
    "    \"\"\"\n",
    "\n",
    "    if axis is None:\n",
    "        a = np.ravel(a)  # may copy\n",
    "        axis = 0\n",
    "\n",
    "    l = a.shape[axis]\n",
    "\n",
    "    if overlap >= length: raise ValueError(\n",
    "        \"frames cannot overlap by more than 100%\")\n",
    "    if overlap < 0 or length <= 0: raise ValueError(\n",
    "        \"overlap must be nonnegative and length must be positive\")\n",
    "\n",
    "    if l < length or (l - length) % (length - overlap):\n",
    "        if l > length:\n",
    "            roundup = length + (1 + (l - length) // (length - overlap)) * (\n",
    "                    length - overlap)\n",
    "            rounddown = length + ((l - length) // (length - overlap)) * (\n",
    "                    length - overlap)\n",
    "        else:\n",
    "            roundup = length\n",
    "            rounddown = 0\n",
    "        assert rounddown < l < roundup\n",
    "        assert roundup == rounddown + (length - overlap) or (\n",
    "                roundup == length and rounddown == 0)\n",
    "        a = a.swapaxes(-1, axis)\n",
    "\n",
    "        if end == 'cut':\n",
    "            a = a[..., :rounddown]\n",
    "        elif end in ['pad', 'wrap']:  # copying will be necessary\n",
    "            s = list(a.shape)\n",
    "            s[-1] = roundup\n",
    "            b = np.empty(s, dtype=a.dtype)\n",
    "            b[..., :l] = a\n",
    "            if end == 'pad':\n",
    "                b[..., l:] = endvalue\n",
    "            elif end == 'wrap':\n",
    "                b[..., l:] = a[..., :roundup - l]\n",
    "            a = b\n",
    "\n",
    "        a = a.swapaxes(-1, axis)\n",
    "\n",
    "    l = a.shape[axis]\n",
    "    if l == 0: raise ValueError(\n",
    "        \"Not enough data points to segment array in 'cut' mode; try 'pad' or 'wrap'\")\n",
    "    assert l >= length\n",
    "    assert (l - length) % (length - overlap) == 0\n",
    "    n = 1 + (l - length) // (length - overlap)\n",
    "    s = a.strides[axis]\n",
    "    newshape = a.shape[:axis] + (n, length) + a.shape[axis + 1:]\n",
    "    newstrides = a.strides[:axis] + ((length - overlap) * s, s) + a.strides[axis + 1:]\n",
    "\n",
    "    if not a.flags.contiguous:\n",
    "        a = a.copy()\n",
    "        newstrides = a.strides[:axis] + ((length - overlap) * s, s) + a.strides[axis + 1:]\n",
    "        return np.ndarray.__new__(np.ndarray, strides=newstrides, shape=newshape, buffer=a, dtype=a.dtype)\n",
    "\n",
    "    try:\n",
    "        return np.ndarray.__new__(np.ndarray, strides=newstrides, shape=newshape, buffer=a, dtype=a.dtype)\n",
    "    except TypeError or ValueError:\n",
    "        warnings.warn(\"Problem with ndarray creation forces copy.\")\n",
    "        a = a.copy()\n",
    "        # Shape doesn't change but strides does\n",
    "        newstrides = a.strides[:axis] + ((length - overlap) * s, s) + a.strides[axis + 1:]\n",
    "        return np.ndarray.__new__(np.ndarray, strides=newstrides, shape=newshape, buffer=a, dtype=a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pleased-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _samples_to_stft_frames(samples, size, shift):\n",
    "    \"\"\"\n",
    "    Calculates STFT frames from samples in time domain.\n",
    "    :param samples: Number of samples in time domain.\n",
    "    :param size: FFT size.\n",
    "    :param shift: Hop in samples.\n",
    "    :return: Number of STFT frames.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.ceil((float(samples) - size + shift) / shift).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "occupational-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft_frames_to_samples(frames, size, shift):\n",
    "    \"\"\"\n",
    "    Calculates samples in time domain from STFT frames\n",
    "    :param frames: Number of STFT frames.\n",
    "    :param size: FFT size.\n",
    "    :param shift: Hop in samples.\n",
    "    :return: Number of samples in time domain.\n",
    "    \"\"\"\n",
    "    return frames * shift + size - shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handled-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(time_signal, time_dim=None, size=1024, shift=256,\n",
    "         window=signal.blackman, fading=True, window_length=None):\n",
    "    \"\"\"\n",
    "    Calculates the short time Fourier transformation of a multi channel multi\n",
    "    speaker time signal. It is able to add additional zeros for fade-in and\n",
    "    fade out and should yield an STFT signal which allows perfect\n",
    "    reconstruction.\n",
    "    :param time_signal: multi channel time signal.\n",
    "    :param time_dim: Scalar dim of time.\n",
    "        Default: None means the biggest dimension\n",
    "    :param size: Scalar FFT-size.\n",
    "    :param shift: Scalar FFT-shift. Typically shift is a fraction of size.\n",
    "    :param window: Window function handle.\n",
    "    :param fading: Pads the signal with zeros for better reconstruction.\n",
    "    :param window_length: Sometimes one desires to use a shorter window than\n",
    "        the fft size. In that case, the window is padded with zeros.\n",
    "        The default is to use the fft-size as a window size.\n",
    "    :return: Single channel complex STFT signal\n",
    "        with dimensions frames times size/2+1.\n",
    "    \"\"\"\n",
    "    if time_dim is None:\n",
    "        time_dim = np.argmax(time_signal.shape)\n",
    "\n",
    "    # Pad with zeros to have enough samples for the window function to fade.\n",
    "    if fading:\n",
    "        pad = [(0, 0)] * time_signal.ndim\n",
    "        pad[time_dim] = [size - shift, size - shift]\n",
    "        time_signal = np.pad(time_signal, pad, mode='constant')\n",
    "\n",
    "    # Pad with trailing zeros, to have an integral number of frames.\n",
    "    frames = _samples_to_stft_frames(time_signal.shape[time_dim], size, shift)\n",
    "    samples = _stft_frames_to_samples(frames, size, shift)\n",
    "    pad = [(0, 0)] * time_signal.ndim\n",
    "    pad[time_dim] = [0, samples - time_signal.shape[time_dim]]\n",
    "    time_signal = np.pad(time_signal, pad, mode='constant')\n",
    "    \n",
    "\n",
    "    if window_length is None:\n",
    "        window = window(size)\n",
    "    else:\n",
    "        window = window(window_length)\n",
    "        window = np.pad(window, (0, size - window_length), mode='constant')\n",
    "\n",
    "    time_signal_seg = segment_axis(time_signal, size,\n",
    "                                   size - shift, axis=time_dim)\n",
    "\n",
    "    letters = string.ascii_lowercase\n",
    "    mapping = letters[:time_signal_seg.ndim] + ',' + letters[time_dim + 1] \\\n",
    "              + '->' + letters[:time_signal_seg.ndim]\n",
    "\n",
    "    return rfft(np.einsum(mapping, time_signal_seg, window), axis=time_dim + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioread(path, offset=0.0, duration=None, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Reads a wav file, converts it to 32 bit float values and reshapes accoring\n",
    "    to the number of channels.\n",
    "    Now, this is a wrapper of librosa with our common defaults.\n",
    "    :param path: Absolute or relative file path to audio file.\n",
    "    :type: String.\n",
    "    :param offset: Begin of loaded audio.\n",
    "    :type: Scalar in seconds.\n",
    "    :param duration: Duration of loaded audio.\n",
    "    :type: Scalar in seconds.\n",
    "    :param sample_rate: Sample rate of audio\n",
    "    :type: scalar in number of samples per second\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    signal = librosa.load(path, sr=sample_rate, mono=False, offset=offset, duration=duration)\n",
    "    \n",
    "    return signal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "yellow-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_tfrecord\\447o0302_0.62948_441c0212_-0.62948.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_tfrecord\\447o0302_1.3388_22ho010i_-1.3388.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_tfrecord\\447o0302_2.1067_422o030k_-2.1067.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_tfrecord\\447o0303_0.14144_441c0212_-0.14144.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_tfrecord\\447o0302_0.62948_441c0212_-0.62948.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_tfrecord\\447o0302_1.3388_22ho010i_-1.3388.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_tfrecord\\447o0302_2.1067_422o030k_-2.1067.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_tfrecord\\447o0303_0.14144_441c0212_-0.14144.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_tfrecord\\447o0302_0.62948_441c0212_-0.62948.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_tfrecord\\447o0302_1.3388_22ho010i_-1.3388.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_tfrecord\\447o0302_2.1067_422o030k_-2.1067.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_tfrecord\\447o0303_0.14144_441c0212_-0.14144.tfrecords\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import librosa.display\n",
    "from math import ceil\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "wav_dir = './mycode/wsj0_2mix/use_this/'\n",
    "list_dir = './mycode/wsj0_2mix/use_this/lists/'\n",
    "tfrecord_dir = './mycode/tfrecords/'\n",
    "gender_list = './wsj0-train-spkrinfo.txt'\n",
    "process_num = 8\n",
    "\n",
    "CASE = 'mixed' # mixed or signal\n",
    "\n",
    "mkdir_p(tfrecord_dir) # tfrecord_dir 폴더 만드는 코드\n",
    "sample_rate = 8000\n",
    "window_size = 256\n",
    "window_shift = 128\n",
    "\n",
    "# if gender_list is not '':\n",
    "#     apply_gender_info = True\n",
    "#     gender_dict = {}\n",
    "#     fid = open(gender_list, 'r')\n",
    "#     lines = fid.readlines()\n",
    "#     fid.close()\n",
    "#     for line in lines:\n",
    "#         spk = line.strip('\\n').split(' ')[0]\n",
    "#         gender = line.strip('\\n').split(' ')[1]\n",
    "#         if gender.lower() == 'm':\n",
    "#             gender_dict[spk] = 1\n",
    "#         else:\n",
    "#             gender_dict[spk] = 0\n",
    "\n",
    "\n",
    "def max_length(file, name, mix_or_not):\n",
    "    max_len = 0\n",
    "    \n",
    "    for name in lines:\n",
    "        name = name.strip('\\n')\n",
    "\n",
    "        wav_name = wav_dir + file + '/' + mix_or_not + '/' + name\n",
    "        audio_wav = audioread(wav_name, offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        mix_len = len(audio_wav)\n",
    "\n",
    "        if mix_len > max_len:\n",
    "            max_len = mix_len\n",
    "    \n",
    "    # 초 맞춰주는 부분\n",
    "    max_len = ceil(max_len / sample_rate) * sample_rate\n",
    "    \n",
    "    return max_len\n",
    "\n",
    "\n",
    "def make_sequence_example(inputs, labels, length, name, genders=False):\n",
    "    input_features = [tf.train.Feature(float_list=tf.train.FloatList(value=input_)) for input_ in inputs]\n",
    "    label_features = [tf.train.Feature(float_list=tf.train.FloatList(value=label)) for label in labels]\n",
    "    len_feature = [tf.train.Feature(float_list=tf.train.FloatList(value=[length]))]\n",
    "    name_feature = [tf.train.Feature(bytes_list=tf.train.BytesList(value=[name.encode('utf-8')]))]\n",
    "#     gender_features = [tf.train.Feature(float_list=tf.train.FloatList(value=genders))]\n",
    "    \n",
    "    feature_list = {\n",
    "        'inputs': tf.train.FeatureList(feature=input_features),\n",
    "        'labels': tf.train.FeatureList(feature=label_features),\n",
    "        'length': tf.train.FeatureList(feature=len_feature),\n",
    "        'name' : tf.train.FeatureList(feature=name_feature)\n",
    "#         'genders': tf.train.FeatureList(feature=gender_features)\n",
    "    }\n",
    "    feature_lists = tf.train.FeatureLists(feature_list=feature_list)\n",
    "    \n",
    "    return tf.train.SequenceExample(feature_lists=feature_lists)\n",
    "\n",
    "\n",
    "def gen_feats(wav_name, sample_rate, window_size, window_shift, file, max_len, case='mixed'):\n",
    "    mix_wav_name = wav_dir + file + '/mix/' + wav_name\n",
    "    s1_wav_name  = wav_dir + file + '/s1/' + wav_name\n",
    "    s2_wav_name  = wav_dir + file + '/s2/' + wav_name\n",
    "\n",
    "    # value initiallization\n",
    "    mix_wav = 0\n",
    "    s1_wav = 0\n",
    "    s2_wav = 0\n",
    "    mix_stft = 0\n",
    "    s1_stft = 0\n",
    "    s2_stft = 0\n",
    "    \n",
    "    if case == 'mixed':\n",
    "        # ------- AUDIO READ -------\n",
    "        mix_wav = audioread(mix_wav_name, offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s1_wav  = audioread(s1_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s2_wav  = audioread(s2_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        # --------------------------\n",
    "        \n",
    "        # ------- AUDIO PAD -------\n",
    "        mix_wav_pad = np.pad(mix_wav, (0, max_len - len(mix_wav)), 'constant', constant_values=(0))\n",
    "        s1_wav_pad = np.pad(s1_wav, (0, max_len - len(s1_wav)), 'constant', constant_values=(0))\n",
    "        s2_wav_pad = np.pad(s2_wav, (0, max_len - len(s2_wav)), 'constant', constant_values=(0))\n",
    "        # -------------------------\n",
    "\n",
    "        # ------- STFT -------\n",
    "        mix_stft = stft(mix_wav, time_dim=0, size=window_size, shift=window_shift)\n",
    "        \n",
    "        mix_stft_pad = stft(mix_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        s1_stft_pad = stft(s1_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        s2_stft_pad = stft(s2_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        # --------------------\n",
    "        \n",
    "        part_name = os.path.splitext(wav_name)[0]\n",
    "        tfrecords_name = tfrecord_dir + file + '_tfrecord\\\\' + part_name + '.tfrecords'\n",
    "        \n",
    "        with tf.io.TFRecordWriter(tfrecords_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_name)\n",
    "\n",
    "            mix_abs = np.abs(mix_stft_pad)\n",
    "            mix_angle = np.angle(mix_stft_pad)\n",
    "\n",
    "            s1_abs = np.abs(s1_stft_pad)\n",
    "            s1_angle = np.angle(s1_stft_pad)\n",
    "\n",
    "            s2_abs = np.abs(s2_stft_pad)\n",
    "            s2_angle = np.angle(s2_stft_pad)\n",
    "\n",
    "            inputs = np.concatenate((mix_abs, mix_angle), axis=1)\n",
    "            labels = np.concatenate((s1_abs * np.cos(mix_angle - s1_angle), s2_abs * np.cos(mix_angle - s2_angle)), axis=1)\n",
    "            \n",
    "            ex = make_sequence_example(inputs, labels, mix_stft.shape[0], part_name)\n",
    "            writer.write(ex.SerializeToString())\n",
    "    else:\n",
    "        # ------- AUDIO READ -------\n",
    "        s1_wav  = audioread(s1_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s2_wav  = audioread(s2_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        # --------------------------\n",
    "        \n",
    "        # ------- AUDIO PAD -------\n",
    "        s1_wav_pad = np.pad(s1_wav, (0, max_len - len(s1_wav)), 'constant', constant_values=(0))\n",
    "        s2_wav_pad = np.pad(s2_wav, (0, max_len - len(s2_wav)), 'constant', constant_values=(0))\n",
    "        # -------------------------\n",
    "        \n",
    "        # ------- STFT -------\n",
    "        s1_stft  = stft(s1_wav,  time_dim=0, size=window_size, shift=window_shift)\n",
    "        s2_stft  = stft(s2_wav,  time_dim=0, size=window_size, shift=window_shift)\n",
    "        \n",
    "        s1_stft_pad = stft(s1_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        s2_stft_pad = stft(s2_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        # --------------------\n",
    "        \n",
    "        part_name = os.path.splitext(wav_name)[0]\n",
    "        tfrecords_s1_name = tfrecord_dir + file + '_one_source_tfrecord\\\\' + part_name + '_s1.tfrecords'\n",
    "        tfrecords_s2_name = tfrecord_dir + file + '_one_source_tfrecord\\\\' + part_name + '_s2.tfrecords'\n",
    "        \n",
    "        with tf.io.TFRecordWriter(tfrecords_s1_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_s1_name)\n",
    "            \n",
    "            s1_abs = np.abs(s1_stft_pad)\n",
    "            s1_angle = np.angle(s1_stft_pad)\n",
    "            \n",
    "            ex = make_sequence_example(s1_abs, s1_angle, s1_stft.shape[0], part_name + '_s1')\n",
    "            writer.write(ex.SerializeToString())\n",
    "\n",
    "        with tf.io.TFRecordWriter(tfrecords_s2_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_s2_name)\n",
    "            \n",
    "            s2_abs = np.abs(s2_stft_pad)\n",
    "            s2_angle = np.angle(s2_stft_pad)\n",
    "            \n",
    "            ex = make_sequence_example(s2_abs, s2_angle, s2_stft.shape[0], part_name + '_s2')\n",
    "            writer.write(ex.SerializeToString())\n",
    "\n",
    "\n",
    "# 여기 멀티프로세싱 pool 적용 어케하는지 모르게씀\n",
    "for files in ['tr', 'cv', 'tt']:\n",
    "    max_len = 0\n",
    "    \n",
    "    output_lst_files = list_dir + files + '_wav.lst'\n",
    "    fid = open(output_lst_files, 'r')\n",
    "    lines = fid.readlines()\n",
    "    fid.close()\n",
    "    \n",
    "    \n",
    "    if CASE == 'mixed':\n",
    "        for name in lines:\n",
    "            name = name.strip('\\n')\n",
    "            max_len = max_length(files, name, 'mix')\n",
    "    else:\n",
    "        for name in lines:\n",
    "            name = name.strip('\\n')\n",
    "            max_len1 = max_length(files, name, 's1')\n",
    "            max_len2 = max_length(files, name, 's2')\n",
    "        \n",
    "        if max_len1 >= max_len2:\n",
    "            max_len = max_len1\n",
    "        else:\n",
    "            max_len = max_len2\n",
    "    \n",
    "    \n",
    "    mkdir_p(tfrecord_dir + files + '_tfrecord') # tfrecord_dir 폴더 만드는 코드\n",
    "    mkdir_p(tfrecord_dir + files + '_one_source_tfrecord') # one_source_tfrecord 폴더 만드는 코드\n",
    "    for name in lines:\n",
    "        name = name.strip('\\n')\n",
    "        gen_feats(name, sample_rate, window_size, window_shift, files, max_len, CASE)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-cuisine",
   "metadata": {},
   "source": [
    "# Deep learning part\n",
    "## 1. Data Loader\n",
    "- Data를 시바 읽어오자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dominant-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "urban-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 2\n",
    "INPUT_SIZE = 129\n",
    "OUTPUT_SIZE = 129\n",
    "\n",
    "CASE = 'mixed' # mixed or signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "guilty-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "if CASE == 'mixed':\n",
    "    tr_path = './mycode/tfrecords/tr_tfrecord/*.tfrecords'\n",
    "    val_path = './mycode/tfrecords/cv_tfrecord/*.tfrecords'\n",
    "    tt_path = './mycode/tfrecords/tt_tfrecord/*.tfrecords'\n",
    "else:\n",
    "    tr_path = './mycode/tfrecords/tr_one_source_tfrecord/*.tfrecords'\n",
    "    val_path = './mycode/tfrecords/cv_one_source_tfrecord/*.tfrecords'\n",
    "    tt_path = './mycode/tfrecords/tt_one_source_tfrecord/*.tfrecords'\n",
    "\n",
    "FILENAMES_TRAINING = tf.io.gfile.glob(tr_path)\n",
    "FILENAMES_VALIDATION = tf.io.gfile.glob(val_path)\n",
    "FILENAMES_TEST = tf.io.gfile.glob(tt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "satellite-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFRecord Files: 4\n",
      "Validation TFRecord Files: 4\n",
      "Test TFRecord Files: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0302_0.62948_441c0212_-0.62948.tfrecords',\n",
       " '.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0302_1.3388_22ho010i_-1.3388.tfrecords',\n",
       " '.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0302_2.1067_422o030k_-2.1067.tfrecords',\n",
       " '.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0303_0.14144_441c0212_-0.14144.tfrecords']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train TFRecord Files:\", len(FILENAMES_TRAINING))\n",
    "print(\"Validation TFRecord Files:\", len(FILENAMES_VALIDATION))\n",
    "print(\"Test TFRecord Files:\", len(FILENAMES_TEST))\n",
    "FILENAMES_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "economic-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data, check, input_size=129*2, output_size=129*2):\n",
    "    if check == 'inputs':\n",
    "        inputs = tf.slice(data, [0, 0], [-1, input_size//2])\n",
    "        angle = tf.slice(data, [0, input_size//2], [-1, -1])\n",
    "        \n",
    "        return inputs, angle\n",
    "    \n",
    "    elif check == 'labels':\n",
    "        label1 = tf.slice(data, [0, 0], [-1, output_size//2])\n",
    "        label2 = tf.slice(data, [0, output_size//2], [-1, -1])\n",
    "        \n",
    "        return label1, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "historic-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example, input_size=129*2, output_size=129*2, case='mixed'):\n",
    "    tfrecord_format = (\n",
    "        {\n",
    "            'inputs': tf.io.FixedLenSequenceFeature(shape=[input_size], dtype=tf.float32),\n",
    "            'labels': tf.io.FixedLenSequenceFeature(shape=[output_size], dtype=tf.float32),\n",
    "            'length': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32),\n",
    "            'name': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.string),\n",
    "#             'genders': tf.io.FixedLenSequenceFeature(shape=[2], dtype=tf.float32, allow_missing=True)\n",
    "        }\n",
    "    )\n",
    "    _, example = tf.io.parse_single_sequence_example(example, sequence_features=tfrecord_format)\n",
    "    \n",
    "    if case == 'mixed':\n",
    "        inputs, angle = data_preprocessing(example[\"inputs\"], 'inputs', input_size)\n",
    "    #     label1, label2 = data_preprocessing(example[\"labels\"], 'labels', input_size)\n",
    "\n",
    "        tiled = tf.tile(tf.expand_dims(example['length'], 1), [1, input_size])\n",
    "        \n",
    "        # 여기가 변경된 부분(length와 label을 concat 함)\n",
    "        return inputs, tf.concat([example['labels'], tiled], 0)\n",
    "#         return inputs, example['labels']\n",
    "    \n",
    "    else:\n",
    "        return example['inputs'], example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gross-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord_test(example, input_size=129*2, output_size=129*2, case='mixed'):\n",
    "    tfrecord_format = (\n",
    "        {\n",
    "            'inputs': tf.io.FixedLenSequenceFeature(shape=[input_size], dtype=tf.float32),\n",
    "            'labels': tf.io.FixedLenSequenceFeature(shape=[output_size], dtype=tf.float32),\n",
    "            'length': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32),\n",
    "            'name': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.string),\n",
    "#             'genders': tf.io.FixedLenSequenceFeature(shape=[2], dtype=tf.float32, allow_missing=True)\n",
    "        }\n",
    "    )\n",
    "    _, example = tf.io.parse_single_sequence_example(example, sequence_features=tfrecord_format)\n",
    "    \n",
    "    if case == 'mixed':\n",
    "        inputs, angle = data_preprocessing(example[\"inputs\"], 'inputs', input_size)\n",
    "\n",
    "        return inputs, angle, example['labels'], example['name']\n",
    "    \n",
    "    else:\n",
    "        return example['inputs'], example['labels'], example['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "agricultural-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, input_size=129*2, output_size=129*2, check='train', case='mixed'):\n",
    "    ignore_order = tf.data.Options()\n",
    "    \n",
    "    if check == 'train':\n",
    "        ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    else:\n",
    "        ignore_order.experimental_deterministic = True\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        filenames\n",
    "    )  # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(\n",
    "        ignore_order\n",
    "    )  # uses data as soon as it streams in, rather than in its original order\n",
    "    \n",
    "    if check == 'train':\n",
    "        if case == 'mixed':\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord, input_size=input_size, output_size=output_size), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord, input_size=input_size//2, output_size=output_size//2, case=case), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "    else:\n",
    "        if case == 'mixed':\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord_test, input_size=input_size, output_size=output_size), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord_test, input_size=input_size//2, output_size=output_size//2, case=case), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interracial-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames, input_size=129*2, output_size=129*2):\n",
    "    dataset = load_dataset(filenames, input_size, output_size, case=CASE)\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "#     dataset = dataset.padded_batch(BATCH_SIZE, padded_shapes=(None))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "essential-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_for_test(filenames, input_size=129*2, output_size=129*2):\n",
    "    dataset = load_dataset(filenames, input_size, output_size, check='test', case=CASE)\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "#     dataset = dataset.padded_batch(BATCH_SIZE, padded_shapes=(None))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comprehensive-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(FILENAMES_TRAINING, INPUT_SIZE*2, OUTPUT_SIZE*2)\n",
    "valid_dataset = get_dataset(FILENAMES_VALIDATION, INPUT_SIZE*2, OUTPUT_SIZE*2)\n",
    "\n",
    "test_dataset = get_dataset_for_test(FILENAMES_TEST, INPUT_SIZE*2, OUTPUT_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accessory-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 627, 258) (2, 626, 258) (2, 1, 1)\n",
      "tf.Tensor([583. 417.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a, b = next(iter(train_dataset))\n",
    "c1 = tf.slice(b, [0, 0, 0], [-1, b.shape[1]-1, -1])\n",
    "d1 = tf.slice(b, [0, b.shape[1]-1, 0], [-1, -1, 1])\n",
    "\n",
    "# tf.reduce_mean(tf.cast(tf.math.equal(lab, c1), dtype=tf.float32))\n",
    "print(b.shape, c1.shape, d1.shape)\n",
    "mask = tf.cast(tf.sequence_mask(tf.squeeze(d1), tf.shape(c1)[1]), tf.float32)\n",
    "print(tf.squeeze(d1))\n",
    "mask2 = tf.expand_dims(mask, axis=-1)\n",
    "mask2 = tf.tile(mask2, [1, 1, tf.shape(c1)[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-grenada",
   "metadata": {},
   "source": [
    "## 2. Building model\n",
    "\n",
    "- 이제 우리 모델을 시바 개쩔게 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surface-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, sys, os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, LSTM, Concatenate, Multiply, Bidirectional, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sunrise-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./CKPT/') # model check point 폴더 만드는 코드\n",
    "filepath = \"./CKPT/CKP_ep_{epoch:d}__loss_{val_loss:.5f}_.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "painful-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "\n",
    "# learning rate를 점점 줄이는 부분\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# validation loss에 대해서 좋은 것만 저장됨\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
    ")\n",
    "\n",
    "# early stop 하는 부분인데, validation loss에 대해서 제일 좋은 모델이 저장됨\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "qualified-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom PIT loss\n",
    "\n",
    "# def pit_with_outputsize(output_size):\n",
    "#     def pit_loss(y_true, y_pred):\n",
    "#         ori_length = tf.shape(y_true)[1]\n",
    "        \n",
    "#         # Label & Length divide\n",
    "#         labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 129]\n",
    "#         lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "        \n",
    "#         # Label value slice\n",
    "#         labels1 = tf.slice(labels, [0, 0, 0], [-1, -1, output_size])\n",
    "#         labels2 = tf.slice(labels, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "#         # Predict value slice\n",
    "#         pred1 = tf.slice(y_pred, [0, 0, 0], [-1, -1, output_size])\n",
    "#         pred2 = tf.slice(y_pred, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "#         # Permute calculate\n",
    "#         cost1 = tf.reduce_mean(tf.reduce_sum(tf.pow(pred1 - labels1, 2), 1) + tf.reduce_sum(tf.pow(pred2 - labels2, 2), 1), 1)\n",
    "#         cost2 = tf.reduce_mean(tf.reduce_sum(tf.pow(pred2 - labels1, 2), 1) + tf.reduce_sum(tf.pow(pred1 - labels2, 2), 1), 1)\n",
    "\n",
    "#         idx = tf.cast(cost1 > cost2, tf.float32) \n",
    "#         pit_loss = tf.reduce_sum(idx * cost2 + (1 - idx) * cost1)\n",
    "        \n",
    "#         return pit_loss\n",
    "    \n",
    "#     return pit_loss\n",
    "\n",
    "def pit_with_outputsize(output_size):\n",
    "    def pit_loss(y_true, y_pred):\n",
    "        ori_length = tf.shape(y_true)[1]\n",
    "\n",
    "        # Label & Length divide\n",
    "        labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 129]\n",
    "        lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "\n",
    "        mask = tf.cast(tf.sequence_mask(tf.squeeze(lengths), tf.shape(y_pred)[1]), tf.float32)\n",
    "        mask = tf.expand_dims(mask, axis=-1)\n",
    "        mask = tf.tile(mask, [1, 1, output_size])\n",
    "        print(tf.shape(mask))\n",
    "\n",
    "        # Label value slice\n",
    "        labels1 = tf.slice(labels, [0, 0, 0], [-1, -1, output_size])\n",
    "        labels2 = tf.slice(labels, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "        # Predict value slice\n",
    "        pred1 = tf.slice(y_pred, [0, 0, 0], [-1, -1, output_size])\n",
    "        pred2 = tf.slice(y_pred, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "        # Masking\n",
    "        mask_pred1 = pred1 * mask\n",
    "        mask_pred2 = pred2 * mask\n",
    "\n",
    "        # Permute calculate (batch, seqlen, 258) mask = (batch, seq_len)\n",
    "        cost1 = tf.reduce_sum(tf.pow(mask_pred1 - labels1, 2), 1) + tf.reduce_sum(tf.pow(mask_pred2 - labels2, 2), 1)\n",
    "        cost1 = tf.reduce_sum(cost1, 1) / tf.squeeze(lengths)\n",
    "        cost2 = tf.reduce_sum(tf.pow(mask_pred2 - labels1, 2), 1) + tf.reduce_sum(tf.pow(mask_pred1 - labels2, 2), 1)\n",
    "        cost2 = tf.reduce_sum(cost2, 1) / tf.squeeze(lengths)\n",
    "\n",
    "        idx = tf.cast(cost1 > cost2, tf.float32) \n",
    "        pit_loss = tf.reduce_sum(idx * cost2 + (1 - idx) * cost1)\n",
    "\n",
    "        return pit_loss\n",
    "        \n",
    "    return pit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "colonial-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model\n",
    "\n",
    "def uPIT(input_size, output_size, batch):\n",
    "    inputs = Input(shape=(None, input_size))\n",
    "    \n",
    "    outputs = Dense(496, activation = 'tanh')(inputs)\n",
    "    \n",
    "    outputs = Bidirectional(LSTM(496, activation = 'tanh', return_sequences=True),\n",
    "                           input_shape=(None, 496,))(outputs)\n",
    "    drop = Dropout(rate=0.8)(outputs)\n",
    "    outputs = Bidirectional(LSTM(496, activation = 'tanh', return_sequences=True))(drop)\n",
    "    drop = Dropout(rate=0.8)(outputs)\n",
    "    outputs = Bidirectional(LSTM(496, activation = 'tanh', return_sequences=True))(drop)\n",
    "    drop = Dropout(rate=0.8)(outputs)\n",
    "    \n",
    "    pred1 = Dense(output_size, activation = 'relu')(drop)\n",
    "    pred2 = Dense(output_size, activation = 'relu')(drop)\n",
    "    \n",
    "    cleaned1 = Multiply()([pred1, inputs])\n",
    "    cleaned2 = Multiply()([pred2, inputs])\n",
    "    \n",
    "    model = Concatenate()([cleaned1, cleaned2])\n",
    "    \n",
    "    model = keras.Model(inputs, model)\n",
    "    \n",
    "    model.summary()\n",
    "    adam = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(loss=pit_with_outputsize(output_size), optimizer=adam)\n",
    "#     model.compile(loss=keras.losses.mean_squared_error, optimizer=adam)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-jumping",
   "metadata": {},
   "source": [
    "## 3. Training model\n",
    "- 구축한 모델을 기반으로 딥러닝 학습을 진행하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dress-issue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "장치의 수: 1\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 129)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 496)    64480       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 992)    3940224     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 992)    0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 992)    5908352     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 992)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 992)    5908352     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 992)    0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 129)    128097      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 129)    128097      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, 129)    0           dense_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, 129)    0           dense_2[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 258)    0           multiply[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 16,077,602\n",
      "Trainable params: 16,077,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "Tensor(\"pit_loss/Shape_2:0\", shape=(3,), dtype=int32, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "Tensor(\"pit_loss/Shape_2:0\", shape=(3,), dtype=int32, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "      2/Unknown - 35s 14s/step - loss: 156.7903Tensor(\"pit_loss/Shape_2:0\", shape=(3,), dtype=int32, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "2/2 [==============================] - 39s 18s/step - loss: 156.7903 - val_loss: 139.1902\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 139.19025, saving model to ./CKPT\\CKP_ep_1__loss_139.19025_.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\moon\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "2/2 [==============================] - 29s 16s/step - loss: 135.9598 - val_loss: 116.0982\n",
      "\n",
      "Epoch 00002: val_loss improved from 139.19025 to 116.09821, saving model to ./CKPT\\CKP_ep_2__loss_116.09821_.h5\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 30s 16s/step - loss: 127.6843 - val_loss: 104.8720\n",
      "\n",
      "Epoch 00003: val_loss improved from 116.09821 to 104.87202, saving model to ./CKPT\\CKP_ep_3__loss_104.87202_.h5\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 29s 15s/step - loss: 121.0652 - val_loss: 87.0600\n",
      "\n",
      "Epoch 00004: val_loss improved from 104.87202 to 87.06000, saving model to ./CKPT\\CKP_ep_4__loss_87.06000_.h5\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 29s 15s/step - loss: 107.8913 - val_loss: 72.2059\n",
      "\n",
      "Epoch 00005: val_loss improved from 87.06000 to 72.20591, saving model to ./CKPT\\CKP_ep_5__loss_72.20591_.h5\n"
     ]
    }
   ],
   "source": [
    "# Training part\n",
    "\n",
    "epoch = 5\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('장치의 수: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # 사용 안할 때는 load_model 주석 처리 하자\n",
    "#     model = load_model('./CKPT/CKP_ep_29__loss_102.63367_.h5', custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "    \n",
    "    model = uPIT(INPUT_SIZE, OUTPUT_SIZE, BATCH_SIZE)\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-boutique",
   "metadata": {},
   "source": [
    "## 4. Training and validation loss plot\n",
    "- 학습한 모델의 loss값을 그래프로 그려봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "southeast-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training and validation loss graph\n",
    "\n",
    "def graph_util(history):\n",
    "    fig = plt.figure()\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plt.plot(history.history['loss'], c='b')\n",
    "    plt.plot(history.history['val_loss'], c='r')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training loss', 'validation loss'], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "important-disney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_util(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-royal",
   "metadata": {},
   "source": [
    "## 5. Test Model\n",
    "- 학습된 모델을 사용해서 테스트를 진행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "handed-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 8000\n",
    "window_size = 256\n",
    "window_shift = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dramatic-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./test_wav/') # Result wav 폴더 만드는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "attempted-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _biorthogonal_window_loopy(analysis_window, shift):\n",
    "    \"\"\"\n",
    "    This version of the synthesis calculation is as close as possible to the\n",
    "    Matlab impelementation in terms of variable names.\n",
    "    The results are equal.\n",
    "    The implementation follows equation A.92 in\n",
    "    Krueger, A. Modellbasierte Merkmalsverbesserung zur robusten automatischen\n",
    "    Spracherkennung in Gegenwart von Nachhall und Hintergrundstoerungen\n",
    "    Paderborn, Universitaet Paderborn, Diss., 2011, 2011\n",
    "    \"\"\"\n",
    "    fft_size = len(analysis_window)\n",
    "    assert np.mod(fft_size, shift) == 0\n",
    "    number_of_shifts = len(analysis_window) // shift\n",
    "\n",
    "    sum_of_squares = np.zeros(shift)\n",
    "    for synthesis_index in range(0, shift):\n",
    "        for sample_index in range(0, number_of_shifts + 1):\n",
    "            analysis_index = synthesis_index + sample_index * shift\n",
    "\n",
    "            if analysis_index + 1 < fft_size:\n",
    "                sum_of_squares[synthesis_index] \\\n",
    "                    += analysis_window[analysis_index] ** 2\n",
    "\n",
    "    sum_of_squares = np.kron(np.ones(number_of_shifts), sum_of_squares)\n",
    "    synthesis_window = analysis_window / sum_of_squares / fft_size\n",
    "    return synthesis_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "north-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def istft(stft_signal, size=1024, shift=256,\n",
    "          window=signal.blackman, fading=True, window_length=None):\n",
    "    \"\"\"\n",
    "    Calculated the inverse short time Fourier transform to exactly reconstruct\n",
    "    the time signal.\n",
    "    :param stft_signal: Single channel complex STFT signal\n",
    "        with dimensions frames times size/2+1.\n",
    "    :param size: Scalar FFT-size.\n",
    "    :param shift: Scalar FFT-shift. Typically shift is a fraction of size.\n",
    "    :param window: Window function handle.\n",
    "    :param fading: Removes the additional padding, if done during STFT.\n",
    "    :param window_length: Sometimes one desires to use a shorter window than\n",
    "        the fft size. In that case, the window is padded with zeros.\n",
    "        The default is to use the fft-size as a window size.\n",
    "    :return: Single channel complex STFT signal\n",
    "    :return: Single channel time signal.\n",
    "    \"\"\"\n",
    "    assert stft_signal.shape[1] == size // 2 + 1\n",
    "\n",
    "    if window_length is None:\n",
    "        window = window(size)\n",
    "    else:\n",
    "        window = window(window_length)\n",
    "        window = np.pad(window, (0, size - window_length), mode='constant')\n",
    "\n",
    "    window = _biorthogonal_window_loopy(window, shift)\n",
    "\n",
    "    # Why? Line created by Hai, Lukas does not know, why it exists.\n",
    "    window *= size\n",
    "    time_signal = scipy.zeros(stft_signal.shape[0] * shift + size - shift)\n",
    "\n",
    "    for j, i in enumerate(range(0, len(time_signal) - size + shift, shift)):\n",
    "        time_signal[i:i + size] += window * np.real(irfft(stft_signal[j]))\n",
    "\n",
    "    # Compensate fade-in and fade-out\n",
    "    if fading:\n",
    "        time_signal = time_signal[size - shift:len(time_signal) - (size - shift)]\n",
    "\n",
    "    return time_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "detailed-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audiowrite(data, path, samplerate=16000, normalize=False, threaded=True):\n",
    "    \"\"\" Write the audio data ``data`` to the wav file ``path``\n",
    "    The file can be written in a threaded mode. In this case, the writing\n",
    "    process will be started at a separate thread. Consequently, the file will\n",
    "    not be written when this function exits.\n",
    "    :param data: A numpy array with the audio data\n",
    "    :param path: The wav file the data should be written to\n",
    "    :param samplerate: Samplerate of the audio data\n",
    "    :param normalize: Normalize the audio first so that the values are within\n",
    "        the range of [INTMIN, INTMAX]. E.g. no clipping occurs\n",
    "    :param threaded: If true, the write process will be started as a separate\n",
    "        thread\n",
    "    :return: The number of clipped samples\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    int16_max = np.iinfo(np.int16).max\n",
    "    int16_min = np.iinfo(np.int16).min\n",
    "\n",
    "    if normalize:\n",
    "        if not data.dtype.kind == 'f':\n",
    "            data = data.astype(np.float)\n",
    "        data /= np.max(np.abs(data))\n",
    "\n",
    "    if data.dtype.kind == 'f':\n",
    "        data *= int16_max\n",
    "\n",
    "    sample_to_clip = np.sum(data > int16_max)\n",
    "    if sample_to_clip > 0:\n",
    "        print('Warning, clipping {} samples'.format(sample_to_clip))\n",
    "    data = np.clip(data, int16_min, int16_max)\n",
    "    data = data.astype(np.int16)\n",
    "\n",
    "    if threaded:\n",
    "        threading.Thread(target=wav_write, args=(path, samplerate, data)).start()\n",
    "    else:\n",
    "        wav_write(path, samplerate, data)\n",
    "\n",
    "    return sample_to_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "textile-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\moon\\anaconda3\\envs\\study\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: scipy.zeros is deprecated and will be removed in SciPy 2.0.0, use numpy.zeros instead\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model_path = './CKPT/CKP_ep_5__loss_82.12920_.h5'\n",
    "    model = load_model(model_path, custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "\n",
    "    cnt = 0\n",
    "    check = 0\n",
    "    for batch in test_dataset:\n",
    "        input_batch, angle_batch, label_batch, name = batch\n",
    "        tf.executing_eagerly() # requires r1.7\n",
    "        angle_numpy = tf.constant(angle_batch)\n",
    "        angle_numpy = angle_numpy.numpy()\n",
    "\n",
    "        result = model.predict(input_batch)\n",
    "        label1 = tf.slice(result, [0, 0, 0], [-1, -1, OUTPUT_SIZE])\n",
    "        label2 = tf.slice(result, [0, 0, OUTPUT_SIZE], [-1, -1, -1])\n",
    "        spec1 = label1 * np.exp(angle_numpy * 1j)\n",
    "        spec2 = label2 * np.exp(angle_numpy * 1j)\n",
    "\n",
    "        num = cnt * BATCH_SIZE\n",
    "        for i in range(BATCH_SIZE):\n",
    "            if i >= input_batch.shape[0]:\n",
    "                check = -1\n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                wav_name = name[i][0].numpy().decode('utf-8')\n",
    "\n",
    "                wav_name1 = './test_wav/' + wav_name + '_s1.wav'\n",
    "                wav_name2 = './test_wav/' + wav_name + '_s2.wav'\n",
    "                wav1 = istft(spec1[i, 0:input_batch[i].shape[0], :], size=window_size, shift=window_shift)\n",
    "                wav2 = istft(spec2[i, 0:input_batch[i].shape[0], :], size=window_size, shift=window_shift)\n",
    "                audiowrite(wav1, wav_name1, sample_rate, True, True)\n",
    "                audiowrite(wav2, wav_name2, sample_rate, True, True)\n",
    "        \n",
    "        if check == -1:\n",
    "            break\n",
    "\n",
    "        if (cnt + 1) % 10 == 0:\n",
    "            print((cnt + 1) * BATCH_SIZE)\n",
    "\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-africa",
   "metadata": {},
   "source": [
    "- 원본(ref)과 모델을 통해 만들어진 파일(est)을 SI-SDR SDR과 같이 정확도를 비교한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "natural-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "agreed-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir = './mycode/wsj0_2mix/use_this/'\n",
    "test_dir = './test_wav/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "liable-arrangement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SI-SDR (db) : -5.221896190196276\n",
      "The SDR (db) : -2.35193774686289\n"
     ]
    }
   ],
   "source": [
    "si_sdr = evaluate_metrics.eval_si_sdr(wav_dir, test_dir)\n",
    "sdr = evaluate_metrics.eval_sdr(wav_dir, test_dir)\n",
    "\n",
    "print(\"The SI-SDR (db) :\", si_sdr)\n",
    "print(\"The SDR (db) :\", sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-naples",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
