{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increased-imperial",
   "metadata": {},
   "source": [
    "# Make wav list\n",
    "- 파일을 tr, cv, tt 폴더별로 무지성으로 읽어온 다음 각 폴더별 list를 .lst 파일로 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sound-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate wav file to .lst done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tr_wav.lst format:\n",
    "...\n",
    "447o030v_0.1232_050c0109_-0.1232.wav\n",
    "447o030v_1.7882_444o0310_-1.7882.wav\n",
    "447o030w_0.52605_446o030e_-0.52605.wav\n",
    "447o030w_1.9272_420c0203_-1.9272.wav\n",
    "447o030x_0.03457_441c0209_-0.03457.wav\n",
    "447o030x_0.70879_420o0307_-0.70879.wav\n",
    "447o030x_0.98832_441o0308_-0.98832.wav\n",
    "447o030x_1.4783_422o030p_-1.4783.wav\n",
    "...\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "wav_dir = './mycode/wsj0_2mix/use_this/'\n",
    "list_dir = './mycode/wsj0_2mix/use_this/lists/'\n",
    "\n",
    "wav_dir = wav_dir\n",
    "output_lst = list_dir\n",
    "\n",
    "for folder in ['tr', 'cv', 'tt']:\n",
    "    wav_files = os.listdir(wav_dir + folder + '/mix')\n",
    "    output_lst_files = output_lst + folder + '_wav.lst'\n",
    "    with open(output_lst_files, 'w') as f:\n",
    "        for file in wav_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "print(\"Generate wav file to .lst done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-desperate",
   "metadata": {},
   "source": [
    "# Make TFRecord file\n",
    "\n",
    "- 여기서는 위에서 만든 리스트 파일을 가지고 tfrecord data로 변환함\n",
    "- 이 섹션의 맨 아래 블럭의 코드가 본 코드인데, 읽어들인 raw data를 stft하고, stft한거를 입력으로 세팅함\n",
    "- 그리고 mix된 stft data를 통해서 label들을 뽑아내고, 따로 gender값도 읽어들임\n",
    "- 이렇게 얻게된 3개의 값(mix_stft, labels, gender)을 TFRecord 형식으로 저장함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eastern-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import argparse\n",
    "import os, sys\n",
    "from numpy.fft import rfft, irfft\n",
    "from scipy.io.wavfile import write as wav_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "severe-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    \"\"\" Creates a path recursively without throwing an error if it already exists\n",
    "    :param path: path to create\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "entitled-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_axis(a, length, overlap=0, axis=None, end='cut', endvalue=0):\n",
    "    \"\"\"Generate a new array that chops the given array along the given axis into overlapping frames.\n",
    "    example:\n",
    "    >>> segment_axis(np.arange(10), 4, 2)\n",
    "    array([[0, 1, 2, 3],\n",
    "           [2, 3, 4, 5],\n",
    "           [4, 5, 6, 7],\n",
    "           [6, 7, 8, 9]])\n",
    "    arguments:\n",
    "    a       The array to segment\n",
    "    length  The length of each frame\n",
    "    overlap The number of array elements by which the frames should overlap\n",
    "    axis    The axis to operate on; if None, act on the flattened array\n",
    "    end     What to do with the last frame, if the array is not evenly\n",
    "            divisible into pieces. Options are:\n",
    "            'cut'   Simply discard the extra values\n",
    "            'wrap'  Copy values from the beginning of the array\n",
    "            'pad'   Pad with a constant value\n",
    "    endvalue    The value to use for end='pad'\n",
    "    The array is not copied unless necessary (either because it is\n",
    "    unevenly strided and being flattened or because end is set to\n",
    "    'pad' or 'wrap').\n",
    "    \"\"\"\n",
    "\n",
    "    if axis is None:\n",
    "        a = np.ravel(a)  # may copy\n",
    "        axis = 0\n",
    "\n",
    "    l = a.shape[axis]\n",
    "\n",
    "    if overlap >= length: raise ValueError(\n",
    "        \"frames cannot overlap by more than 100%\")\n",
    "    if overlap < 0 or length <= 0: raise ValueError(\n",
    "        \"overlap must be nonnegative and length must be positive\")\n",
    "\n",
    "    if l < length or (l - length) % (length - overlap):\n",
    "        if l > length:\n",
    "            roundup = length + (1 + (l - length) // (length - overlap)) * (\n",
    "                    length - overlap)\n",
    "            rounddown = length + ((l - length) // (length - overlap)) * (\n",
    "                    length - overlap)\n",
    "        else:\n",
    "            roundup = length\n",
    "            rounddown = 0\n",
    "        assert rounddown < l < roundup\n",
    "        assert roundup == rounddown + (length - overlap) or (\n",
    "                roundup == length and rounddown == 0)\n",
    "        a = a.swapaxes(-1, axis)\n",
    "\n",
    "        if end == 'cut':\n",
    "            a = a[..., :rounddown]\n",
    "        elif end in ['pad', 'wrap']:  # copying will be necessary\n",
    "            s = list(a.shape)\n",
    "            s[-1] = roundup\n",
    "            b = np.empty(s, dtype=a.dtype)\n",
    "            b[..., :l] = a\n",
    "            if end == 'pad':\n",
    "                b[..., l:] = endvalue\n",
    "            elif end == 'wrap':\n",
    "                b[..., l:] = a[..., :roundup - l]\n",
    "            a = b\n",
    "\n",
    "        a = a.swapaxes(-1, axis)\n",
    "\n",
    "    l = a.shape[axis]\n",
    "    if l == 0: raise ValueError(\n",
    "        \"Not enough data points to segment array in 'cut' mode; try 'pad' or 'wrap'\")\n",
    "    assert l >= length\n",
    "    assert (l - length) % (length - overlap) == 0\n",
    "    n = 1 + (l - length) // (length - overlap)\n",
    "    s = a.strides[axis]\n",
    "    newshape = a.shape[:axis] + (n, length) + a.shape[axis + 1:]\n",
    "    newstrides = a.strides[:axis] + ((length - overlap) * s, s) + a.strides[axis + 1:]\n",
    "\n",
    "    if not a.flags.contiguous:\n",
    "        a = a.copy()\n",
    "        newstrides = a.strides[:axis] + ((length - overlap) * s, s) + a.strides[axis + 1:]\n",
    "        return np.ndarray.__new__(np.ndarray, strides=newstrides, shape=newshape, buffer=a, dtype=a.dtype)\n",
    "\n",
    "    try:\n",
    "        return np.ndarray.__new__(np.ndarray, strides=newstrides, shape=newshape, buffer=a, dtype=a.dtype)\n",
    "    except TypeError or ValueError:\n",
    "        warnings.warn(\"Problem with ndarray creation forces copy.\")\n",
    "        a = a.copy()\n",
    "        # Shape doesn't change but strides does\n",
    "        newstrides = a.strides[:axis] + ((length - overlap) * s, s) + a.strides[axis + 1:]\n",
    "        return np.ndarray.__new__(np.ndarray, strides=newstrides, shape=newshape, buffer=a, dtype=a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "pleased-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _samples_to_stft_frames(samples, size, shift):\n",
    "    \"\"\"\n",
    "    Calculates STFT frames from samples in time domain.\n",
    "    :param samples: Number of samples in time domain.\n",
    "    :param size: FFT size.\n",
    "    :param shift: Hop in samples.\n",
    "    :return: Number of STFT frames.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.ceil((float(samples) - size + shift) / shift).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "occupational-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft_frames_to_samples(frames, size, shift):\n",
    "    \"\"\"\n",
    "    Calculates samples in time domain from STFT frames\n",
    "    :param frames: Number of STFT frames.\n",
    "    :param size: FFT size.\n",
    "    :param shift: Hop in samples.\n",
    "    :return: Number of samples in time domain.\n",
    "    \"\"\"\n",
    "    return frames * shift + size - shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "handled-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(time_signal, time_dim=None, size=1024, shift=256,\n",
    "         window=signal.blackman, fading=True, window_length=None):\n",
    "    \"\"\"\n",
    "    Calculates the short time Fourier transformation of a multi channel multi\n",
    "    speaker time signal. It is able to add additional zeros for fade-in and\n",
    "    fade out and should yield an STFT signal which allows perfect\n",
    "    reconstruction.\n",
    "    :param time_signal: multi channel time signal.\n",
    "    :param time_dim: Scalar dim of time.\n",
    "        Default: None means the biggest dimension\n",
    "    :param size: Scalar FFT-size.\n",
    "    :param shift: Scalar FFT-shift. Typically shift is a fraction of size.\n",
    "    :param window: Window function handle.\n",
    "    :param fading: Pads the signal with zeros for better reconstruction.\n",
    "    :param window_length: Sometimes one desires to use a shorter window than\n",
    "        the fft size. In that case, the window is padded with zeros.\n",
    "        The default is to use the fft-size as a window size.\n",
    "    :return: Single channel complex STFT signal\n",
    "        with dimensions frames times size/2+1.\n",
    "    \"\"\"\n",
    "    if time_dim is None:\n",
    "        time_dim = np.argmax(time_signal.shape)\n",
    "\n",
    "    # Pad with zeros to have enough samples for the window function to fade.\n",
    "    if fading:\n",
    "        pad = [(0, 0)] * time_signal.ndim\n",
    "        pad[time_dim] = [size - shift, size - shift]\n",
    "        time_signal = np.pad(time_signal, pad, mode='constant')\n",
    "\n",
    "    # Pad with trailing zeros, to have an integral number of frames.\n",
    "    frames = _samples_to_stft_frames(time_signal.shape[time_dim], size, shift)\n",
    "    samples = _stft_frames_to_samples(frames, size, shift)\n",
    "    pad = [(0, 0)] * time_signal.ndim\n",
    "    pad[time_dim] = [0, samples - time_signal.shape[time_dim]]\n",
    "    time_signal = np.pad(time_signal, pad, mode='constant')\n",
    "    \n",
    "\n",
    "    if window_length is None:\n",
    "        window = window(size)\n",
    "    else:\n",
    "        window = window(window_length)\n",
    "        window = np.pad(window, (0, size - window_length), mode='constant')\n",
    "\n",
    "    time_signal_seg = segment_axis(time_signal, size,\n",
    "                                   size - shift, axis=time_dim)\n",
    "\n",
    "    letters = string.ascii_lowercase\n",
    "    mapping = letters[:time_signal_seg.ndim] + ',' + letters[time_dim + 1] \\\n",
    "              + '->' + letters[:time_signal_seg.ndim]\n",
    "\n",
    "    return rfft(np.einsum(mapping, time_signal_seg, window), axis=time_dim + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "baking-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioread(path, offset=0.0, duration=None, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Reads a wav file, converts it to 32 bit float values and reshapes accoring\n",
    "    to the number of channels.\n",
    "    Now, this is a wrapper of librosa with our common defaults.\n",
    "    :param path: Absolute or relative file path to audio file.\n",
    "    :type: String.\n",
    "    :param offset: Begin of loaded audio.\n",
    "    :type: Scalar in seconds.\n",
    "    :param duration: Duration of loaded audio.\n",
    "    :type: Scalar in seconds.\n",
    "    :param sample_rate: Sample rate of audio\n",
    "    :type: scalar in number of samples per second\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    signal = librosa.load(path, sr=sample_rate, mono=False, offset=offset, duration=duration)\n",
    "    \n",
    "    return signal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "yellow-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_tfrecord\\447o0302_0.62948_441c0212_-0.62948.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_tfrecord\\447o0302_1.3388_22ho010i_-1.3388.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_tfrecord\\447o0302_2.1067_422o030k_-2.1067.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_tfrecord\\447o0303_0.14144_441c0212_-0.14144.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_tfrecord\\447o0302_0.62948_441c0212_-0.62948.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_tfrecord\\447o0302_1.3388_22ho010i_-1.3388.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_tfrecord\\447o0302_2.1067_422o030k_-2.1067.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_tfrecord\\447o0303_0.14144_441c0212_-0.14144.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_tfrecord\\447o0302_0.62948_441c0212_-0.62948.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_tfrecord\\447o0302_1.3388_22ho010i_-1.3388.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_tfrecord\\447o0302_2.1067_422o030k_-2.1067.tfrecords\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_tfrecord\\447o0303_0.14144_441c0212_-0.14144.tfrecords\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import librosa.display\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "wav_dir = './mycode/wsj0_2mix/use_this/'\n",
    "list_dir = './mycode/wsj0_2mix/use_this/lists/'\n",
    "tfrecord_dir = './mycode/tfrecords/'\n",
    "gender_list = './wsj0-train-spkrinfo.txt'\n",
    "process_num = 8\n",
    "\n",
    "CASE = 'mixed' # mixed or signal\n",
    "\n",
    "mkdir_p(tfrecord_dir) # tfrecord_dir 폴더 만드는 코드\n",
    "sample_rate = 8000\n",
    "window_size = 256\n",
    "window_shift = 128\n",
    "\n",
    "# if gender_list is not '':\n",
    "#     apply_gender_info = True\n",
    "#     gender_dict = {}\n",
    "#     fid = open(gender_list, 'r')\n",
    "#     lines = fid.readlines()\n",
    "#     fid.close()\n",
    "#     for line in lines:\n",
    "#         spk = line.strip('\\n').split(' ')[0]\n",
    "#         gender = line.strip('\\n').split(' ')[1]\n",
    "#         if gender.lower() == 'm':\n",
    "#             gender_dict[spk] = 1\n",
    "#         else:\n",
    "#             gender_dict[spk] = 0\n",
    "\n",
    "\n",
    "def make_sequence_example(inputs, labels, name, genders=False):\n",
    "    input_features = [tf.train.Feature(float_list=tf.train.FloatList(value=input_)) for input_ in inputs]\n",
    "    label_features = [tf.train.Feature(float_list=tf.train.FloatList(value=label)) for label in labels]\n",
    "    name_feature = [tf.train.Feature(bytes_list=tf.train.BytesList(value=[name.encode('utf-8')]))]\n",
    "#     gender_features = [tf.train.Feature(float_list=tf.train.FloatList(value=genders))]\n",
    "    \n",
    "    feature_list = {\n",
    "        'inputs': tf.train.FeatureList(feature=input_features),\n",
    "        'labels': tf.train.FeatureList(feature=label_features),\n",
    "        'name' : tf.train.FeatureList(feature=name_feature)\n",
    "#         'genders': tf.train.FeatureList(feature=gender_features)\n",
    "    }\n",
    "    feature_lists = tf.train.FeatureLists(feature_list=feature_list)\n",
    "    \n",
    "    return tf.train.SequenceExample(feature_lists=feature_lists)\n",
    "\n",
    "\n",
    "def gen_feats(wav_name, sample_rate, window_size, window_shift, file, case='mixed'):\n",
    "    mix_wav_name = wav_dir + file + '/mix/' + wav_name\n",
    "    s1_wav_name  = wav_dir + file + '/s1/' + wav_name\n",
    "    s2_wav_name  = wav_dir + file + '/s2/' + wav_name\n",
    "\n",
    "    # value initiallization\n",
    "    mix_wav = 0\n",
    "    s1_wav = 0\n",
    "    s2_wav = 0\n",
    "    mix_stft = 0\n",
    "    s1_stft = 0\n",
    "    s2_stft = 0\n",
    "    \n",
    "    if case == 'mixed':\n",
    "        mix_wav = audioread(mix_wav_name, offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s1_wav  = audioread(s1_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s2_wav  = audioread(s2_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "\n",
    "        mix_stft = stft(mix_wav, time_dim=0, size=window_size, shift=window_shift)\n",
    "        s1_stft  = stft(s1_wav,  time_dim=0, size=window_size, shift=window_shift)\n",
    "        s2_stft  = stft(s2_wav,  time_dim=0, size=window_size, shift=window_shift)\n",
    "        \n",
    "        part_name = os.path.splitext(wav_name)[0]\n",
    "        tfrecords_name = tfrecord_dir + file + '_tfrecord\\\\' + part_name + '.tfrecords'\n",
    "        \n",
    "        with tf.io.TFRecordWriter(tfrecords_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_name)\n",
    "\n",
    "            mix_abs = np.abs(mix_stft)\n",
    "            mix_angle = np.angle(mix_stft)\n",
    "\n",
    "            s1_abs = np.abs(s1_stft)\n",
    "            s1_angle = np.angle(s1_stft)\n",
    "\n",
    "            s2_abs = np.abs(s2_stft)\n",
    "            s2_angle = np.angle(s2_stft)\n",
    "\n",
    "            inputs = np.concatenate((mix_abs, mix_angle), axis=1)\n",
    "            labels = np.concatenate((s1_abs * np.cos(mix_angle - s1_angle), s2_abs * np.cos(mix_angle - s2_angle)), axis=1)\n",
    "            \n",
    "            ex = make_sequence_example(inputs, labels, part_name)\n",
    "            writer.write(ex.SerializeToString())\n",
    "    else:\n",
    "        s1_wav  = audioread(s1_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s2_wav  = audioread(s2_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        \n",
    "        s1_stft  = stft(s1_wav,  time_dim=0, size=window_size, shift=window_shift)\n",
    "        s2_stft  = stft(s2_wav,  time_dim=0, size=window_size, shift=window_shift)\n",
    "        \n",
    "        part_name = os.path.splitext(wav_name)[0]\n",
    "        tfrecords_s1_name = tfrecord_dir + file + '_one_source_tfrecord\\\\' + part_name + '_s1.tfrecords'\n",
    "        tfrecords_s2_name = tfrecord_dir + file + '_one_source_tfrecord\\\\' + part_name + '_s2.tfrecords'\n",
    "        \n",
    "        with tf.io.TFRecordWriter(tfrecords_s1_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_s1_name)\n",
    "            \n",
    "            s1_abs = np.abs(s1_stft)\n",
    "            s1_angle = np.angle(s1_stft)\n",
    "            \n",
    "            ex = make_sequence_example(s1_abs, s1_angle, part_name + '_s1')\n",
    "            writer.write(ex.SerializeToString())\n",
    "\n",
    "        with tf.io.TFRecordWriter(tfrecords_s2_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_s2_name)\n",
    "            \n",
    "            s2_abs = np.abs(s2_stft)\n",
    "            s2_angle = np.angle(s2_stft)\n",
    "            \n",
    "            ex = make_sequence_example(s2_abs, s2_angle, part_name + '_s2')\n",
    "            writer.write(ex.SerializeToString())\n",
    "        \n",
    "\n",
    "    \n",
    "#     mix2_stft = librosa.stft(mix_wav, n_fft=window_size, hop_length=window_shift, window=signal.blackman)\n",
    "#     db = librosa.amplitude_to_db(np.transpose(np.abs(s2_stft)),ref=np.max)\n",
    "#     db2 = librosa.amplitude_to_db(np.abs(mix2_stft),ref=np.max)\n",
    "#     librosa.display.specshow(db, sr=sample_rate, y_axis='linear', x_axis='time')\n",
    "#     librosa.display.specshow(db2, sr=sample_rate, y_axis='log', x_axis='time')\n",
    "#     print(np.transpose(np.abs(mix_stft)).shape)\n",
    "\n",
    "#     s1_gender = gender_dict[wav_name.split('_')[0][0:3]]\n",
    "#     s2_gender = gender_dict[wav_name.split('_')[2][0:3]]\n",
    "\n",
    "#     part_name = os.path.splitext(wav_name)[0]\n",
    "#     tfrecords_name = tfrecord_dir + file + '_tfrecord\\\\' + part_name + '.tfrecords'\n",
    "#     #print(tfrecords_name)\n",
    "\n",
    "#     with tf.io.TFRecordWriter(tfrecords_name) as writer:\n",
    "#         tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_name)\n",
    "\n",
    "#         mix_abs = np.abs(mix_stft)\n",
    "#         mix_angle = np.angle(mix_stft)\n",
    "\n",
    "#         s1_abs = np.abs(s1_stft)\n",
    "#         s1_angle = np.angle(s1_stft)\n",
    "\n",
    "#         s2_abs = np.abs(s2_stft)\n",
    "#         s2_angle = np.angle(s2_stft)\n",
    "\n",
    "#         inputs = np.concatenate((mix_abs, mix_angle), axis=1)\n",
    "#         labels = np.concatenate((s1_abs * np.cos(mix_angle - s1_angle), s2_abs * np.cos(mix_angle - s2_angle)), axis=1)\n",
    "#         gender = [s1_gender, s2_gender]\n",
    "        \n",
    "# #         print(inputs.shape)\n",
    "# #         print(mix_abs)\n",
    "# #         print(labels.shape)\n",
    "# #         print(np.array(gender).shape)\n",
    "\n",
    "#         ex = make_sequence_example(inputs, labels, gender)\n",
    "#         writer.write(ex.SerializeToString())\n",
    "\n",
    "\n",
    "# 여기 멀티프로세싱 pool 적용 어케하는지 모르게씀\n",
    "for files in ['tr', 'cv', 'tt']:\n",
    "#     pool = multiprocessing.Pool(processes=process_num)\n",
    "    output_lst_files = list_dir + files + '_wav.lst'\n",
    "    fid = open(output_lst_files, 'r')\n",
    "    lines = fid.readlines()\n",
    "    fid.close()\n",
    "    \n",
    "    mkdir_p(tfrecord_dir + files + '_tfrecord') # tfrecord_dir 폴더 만드는 코드\n",
    "    mkdir_p(tfrecord_dir + files + '_one_source_tfrecord') # one_source_tfrecord 폴더 만드는 코드\n",
    "    for name in lines:\n",
    "        name = name.strip('\\n')\n",
    "#         pool.map_async(gen_feats, (name, sample_rate, window_size, window_shift, files))\n",
    "        gen_feats(name, sample_rate, window_size, window_shift, files, CASE)\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-cuisine",
   "metadata": {},
   "source": [
    "# Deep learning part\n",
    "## 1. Data Loader\n",
    "- Data를 시바 읽어오자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dominant-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "urban-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 2\n",
    "INPUT_SIZE = 129\n",
    "OUTPUT_SIZE = 129\n",
    "\n",
    "CASE = 'mixed' # mixed or signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "guilty-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "if CASE == 'mixed':\n",
    "    tr_path = './mycode/tfrecords/tr_tfrecord/*.tfrecords'\n",
    "    val_path = './mycode/tfrecords/cv_tfrecord/*.tfrecords'\n",
    "    tt_path = './mycode/tfrecords/tt_tfrecord/*.tfrecords'\n",
    "else:\n",
    "    tr_path = './mycode/tfrecords/tr_one_source_tfrecord/*.tfrecords'\n",
    "    val_path = './mycode/tfrecords/cv_one_source_tfrecord/*.tfrecords'\n",
    "    tt_path = './mycode/tfrecords/tt_one_source_tfrecord/*.tfrecords'\n",
    "\n",
    "FILENAMES_TRAINING = tf.io.gfile.glob(tr_path)\n",
    "FILENAMES_VALIDATION = tf.io.gfile.glob(val_path)\n",
    "FILENAMES_TEST = tf.io.gfile.glob(tt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "satellite-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFRecord Files: 4\n",
      "Validation TFRecord Files: 4\n",
      "Test TFRecord Files: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0302_0.62948_441c0212_-0.62948.tfrecords',\n",
       " '.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0302_1.3388_22ho010i_-1.3388.tfrecords',\n",
       " '.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0302_2.1067_422o030k_-2.1067.tfrecords',\n",
       " '.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0303_0.14144_441c0212_-0.14144.tfrecords']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train TFRecord Files:\", len(FILENAMES_TRAINING))\n",
    "print(\"Validation TFRecord Files:\", len(FILENAMES_VALIDATION))\n",
    "print(\"Test TFRecord Files:\", len(FILENAMES_TEST))\n",
    "FILENAMES_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "economic-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data, check, input_size=129*2, output_size=129*2):\n",
    "    if check == 'inputs':\n",
    "        inputs = tf.slice(data, [0, 0], [-1, input_size//2])\n",
    "        angle = tf.slice(data, [0, input_size//2], [-1, -1])\n",
    "        \n",
    "        return inputs, angle\n",
    "    \n",
    "    elif check == 'labels':\n",
    "        label1 = tf.slice(data, [0, 0], [-1, output_size//2])\n",
    "        label2 = tf.slice(data, [0, output_size//2], [-1, -1])\n",
    "        \n",
    "        return label1, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "historic-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example, input_size=129*2, output_size=129*2, case='mixed'):\n",
    "    tfrecord_format = (\n",
    "        {\n",
    "            'inputs': tf.io.FixedLenSequenceFeature(shape=[input_size], dtype=tf.float32, allow_missing=True),\n",
    "            'labels': tf.io.FixedLenSequenceFeature(shape=[output_size], dtype=tf.float32, allow_missing=True),\n",
    "            'name': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.string, allow_missing=True),\n",
    "#             'genders': tf.io.FixedLenSequenceFeature(shape=[2], dtype=tf.float32, allow_missing=True)\n",
    "        }\n",
    "    )\n",
    "    _, example = tf.io.parse_single_sequence_example(example, sequence_features=tfrecord_format)\n",
    "    \n",
    "    if case == 'mixed':\n",
    "        inputs, angle = data_preprocessing(example[\"inputs\"], 'inputs', input_size)\n",
    "    #     label1, label2 = data_preprocessing(example[\"labels\"], 'labels', input_size)\n",
    "\n",
    "        return inputs, example['labels']\n",
    "    \n",
    "    else:\n",
    "        return example['inputs'], example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gross-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord_test(example, input_size=129*2, output_size=129*2, case='mixed'):\n",
    "    tfrecord_format = (\n",
    "        {\n",
    "            'inputs': tf.io.FixedLenSequenceFeature(shape=[input_size], dtype=tf.float32, allow_missing=True),\n",
    "            'labels': tf.io.FixedLenSequenceFeature(shape=[output_size], dtype=tf.float32, allow_missing=True),\n",
    "            'name': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.string, allow_missing=True),\n",
    "#             'genders': tf.io.FixedLenSequenceFeature(shape=[2], dtype=tf.float32, allow_missing=True)\n",
    "        }\n",
    "    )\n",
    "    _, example = tf.io.parse_single_sequence_example(example, sequence_features=tfrecord_format)\n",
    "    \n",
    "    if case == 'mixed':\n",
    "        inputs, angle = data_preprocessing(example[\"inputs\"], 'inputs', input_size)\n",
    "\n",
    "        return inputs, angle, example['labels'], example['name']\n",
    "    \n",
    "    else:\n",
    "        return example['inputs'], example['labels'], example['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "agricultural-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, input_size=129*2, output_size=129*2, check='train', case='mixed'):\n",
    "    ignore_order = tf.data.Options()\n",
    "    \n",
    "    if check == 'train':\n",
    "        ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    else:\n",
    "        ignore_order.experimental_deterministic = True\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        filenames\n",
    "    )  # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(\n",
    "        ignore_order\n",
    "    )  # uses data as soon as it streams in, rather than in its original order\n",
    "    \n",
    "    if check == 'train':\n",
    "        if case == 'mixed':\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord, input_size=input_size, output_size=output_size), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord, input_size=input_size//2, output_size=output_size//2, case=case), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "    else:\n",
    "        if case == 'mixed':\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord_test, input_size=input_size, output_size=output_size), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord_test, input_size=input_size//2, output_size=output_size//2, case=case), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interracial-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames, input_size=129*2, output_size=129*2):\n",
    "    dataset = load_dataset(filenames, input_size, output_size, case=CASE)\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.padded_batch(BATCH_SIZE, padded_shapes=(None))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "essential-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_for_test(filenames, input_size=129*2, output_size=129*2):\n",
    "    dataset = load_dataset(filenames, input_size, output_size, check='test', case=CASE)\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.padded_batch(BATCH_SIZE, padded_shapes=(None))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comprehensive-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(FILENAMES_TRAINING, INPUT_SIZE*2, OUTPUT_SIZE*2)\n",
    "valid_dataset = get_dataset(FILENAMES_VALIDATION, INPUT_SIZE*2, OUTPUT_SIZE*2)\n",
    "\n",
    "test_dataset = get_dataset_for_test(FILENAMES_TEST, INPUT_SIZE*2, OUTPUT_SIZE*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-grenada",
   "metadata": {},
   "source": [
    "## 2. Building model\n",
    "\n",
    "- 이제 우리 모델을 시바 개쩔게 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surface-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, sys, os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, LSTM, Concatenate, Multiply, Bidirectional, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sunrise-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./CKPT/') # model check point 폴더 만드는 코드\n",
    "filepath = \"./CKPT/CKP_ep_{epoch:d}__loss_{val_loss:.5f}_.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qualified-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PIT loss\n",
    "\n",
    "def pit_with_outputsize(output_size):\n",
    "    def pit_loss(y_true, y_pred):\n",
    "        labels1 = tf.slice(y_true, [0, 0, 0], [-1, -1, output_size])\n",
    "        labels2 = tf.slice(y_true, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "        pred1 = tf.slice(y_pred, [0, 0, 0], [-1, -1, output_size])\n",
    "        pred2 = tf.slice(y_pred, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "        cost1 = tf.reduce_mean(tf.reduce_sum(tf.pow(pred1 - labels1, 2), 1) + tf.reduce_sum(tf.pow(pred2 - labels2, 2), 1), 1)\n",
    "        cost2 = tf.reduce_mean(tf.reduce_sum(tf.pow(pred2 - labels1, 2), 1) + tf.reduce_sum(tf.pow(pred1 - labels2, 2), 1), 1)\n",
    "\n",
    "        idx = tf.cast(cost1 > cost2, tf.float32) \n",
    "        pit_loss = tf.reduce_sum(idx * cost2 + (1 - idx) * cost1)\n",
    "        \n",
    "        return pit_loss\n",
    "    \n",
    "    return pit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "colonial-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model\n",
    "\n",
    "def uPIT(input_size, output_size, batch):\n",
    "    inputs = Input(shape=(None, input_size))\n",
    "    \n",
    "    outputs = Dense(496, activation = 'tanh')(inputs)\n",
    "    \n",
    "    outputs = Bidirectional(LSTM(496, activation = 'tanh', return_sequences=True),\n",
    "                           input_shape=(None, 496,))(outputs)\n",
    "    drop = Dropout(rate=0.8)(outputs)\n",
    "    outputs = Bidirectional(LSTM(496, activation = 'tanh', return_sequences=True))(drop)\n",
    "    drop = Dropout(rate=0.8)(outputs)\n",
    "    outputs = Bidirectional(LSTM(496, activation = 'tanh', return_sequences=True))(drop)\n",
    "    drop = Dropout(rate=0.8)(outputs)\n",
    "    \n",
    "    pred1 = Dense(output_size, activation = 'relu')(drop)\n",
    "    pred2 = Dense(output_size, activation = 'relu')(drop)\n",
    "    \n",
    "    cleaned1 = Multiply()([pred1, inputs])\n",
    "    cleaned2 = Multiply()([pred2, inputs])\n",
    "    \n",
    "    model = Concatenate()([cleaned1, cleaned2])\n",
    "    \n",
    "    model = keras.Model(inputs, model)\n",
    "    \n",
    "    model.summary()\n",
    "    adam = tf.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss=pit_with_outputsize(output_size), optimizer=adam)\n",
    "#     model.compile(loss=keras.losses.mean_squared_error, optimizer=adam)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-jumping",
   "metadata": {},
   "source": [
    "## 3. Training model\n",
    "- 구축한 모델을 기반으로 딥러닝 학습을 진행하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ordered-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.01\n",
    "\n",
    "# learning rate를 점점 줄이는 부분\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# validation loss에 대해서 좋은 것만 저장됨\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
    ")\n",
    "\n",
    "# early stop 하는 부분인데, validation loss에 대해서 제일 좋은 모델이 저장됨\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dress-issue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "장치의 수: 1\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, 129)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 496)    64480       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 992)    3940224     dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 992)    0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 992)    5908352     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 992)    0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 992)    5908352     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, None, 992)    0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 129)    128097      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, None, 129)    128097      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, None, 129)    0           dense_7[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, None, 129)    0           dense_8[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 258)    0           multiply_4[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 16,077,602\n",
      "Trainable params: 16,077,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 35s 15s/step - loss: 542.4763 - val_loss: 487.2392\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 487.23923, saving model to ./CKPT\\CKP_ep_1__loss_487.23923_.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\moon\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "2/2 [==============================] - 25s 12s/step - loss: 490.4598 - val_loss: 411.1589\n",
      "\n",
      "Epoch 00002: val_loss improved from 487.23923 to 411.15891, saving model to ./CKPT\\CKP_ep_2__loss_411.15891_.h5\n"
     ]
    }
   ],
   "source": [
    "# Training part\n",
    "\n",
    "epoch = 2\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('장치의 수: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # 사용 안할 때는 load_model 주석 처리 하자\n",
    "#     model = load_model('./CKPT/CKP_ep_29__loss_102.63367_.h5', custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "    \n",
    "    model = uPIT(INPUT_SIZE, OUTPUT_SIZE, BATCH_SIZE)\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-boutique",
   "metadata": {},
   "source": [
    "## 4. Training and validation loss plot\n",
    "- 학습한 모델의 loss값을 그래프로 그려봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "southeast-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training and validation loss graph\n",
    "\n",
    "def graph_util(history):\n",
    "    fig = plt.figure()\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plt.plot(history.history['loss'], c='b')\n",
    "    plt.plot(history.history['val_loss'], c='r')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training loss', 'validation loss'], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "important-disney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_util(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-royal",
   "metadata": {},
   "source": [
    "## 5. Test Model\n",
    "- 학습된 모델을 사용해서 테스트를 진행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "handed-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 8000\n",
    "window_size = 256\n",
    "window_shift = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dramatic-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./test_wav/') # Result wav 폴더 만드는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "attempted-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _biorthogonal_window_loopy(analysis_window, shift):\n",
    "    \"\"\"\n",
    "    This version of the synthesis calculation is as close as possible to the\n",
    "    Matlab impelementation in terms of variable names.\n",
    "    The results are equal.\n",
    "    The implementation follows equation A.92 in\n",
    "    Krueger, A. Modellbasierte Merkmalsverbesserung zur robusten automatischen\n",
    "    Spracherkennung in Gegenwart von Nachhall und Hintergrundstoerungen\n",
    "    Paderborn, Universitaet Paderborn, Diss., 2011, 2011\n",
    "    \"\"\"\n",
    "    fft_size = len(analysis_window)\n",
    "    assert np.mod(fft_size, shift) == 0\n",
    "    number_of_shifts = len(analysis_window) // shift\n",
    "\n",
    "    sum_of_squares = np.zeros(shift)\n",
    "    for synthesis_index in range(0, shift):\n",
    "        for sample_index in range(0, number_of_shifts + 1):\n",
    "            analysis_index = synthesis_index + sample_index * shift\n",
    "\n",
    "            if analysis_index + 1 < fft_size:\n",
    "                sum_of_squares[synthesis_index] \\\n",
    "                    += analysis_window[analysis_index] ** 2\n",
    "\n",
    "    sum_of_squares = np.kron(np.ones(number_of_shifts), sum_of_squares)\n",
    "    synthesis_window = analysis_window / sum_of_squares / fft_size\n",
    "    return synthesis_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "north-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def istft(stft_signal, size=1024, shift=256,\n",
    "          window=signal.blackman, fading=True, window_length=None):\n",
    "    \"\"\"\n",
    "    Calculated the inverse short time Fourier transform to exactly reconstruct\n",
    "    the time signal.\n",
    "    :param stft_signal: Single channel complex STFT signal\n",
    "        with dimensions frames times size/2+1.\n",
    "    :param size: Scalar FFT-size.\n",
    "    :param shift: Scalar FFT-shift. Typically shift is a fraction of size.\n",
    "    :param window: Window function handle.\n",
    "    :param fading: Removes the additional padding, if done during STFT.\n",
    "    :param window_length: Sometimes one desires to use a shorter window than\n",
    "        the fft size. In that case, the window is padded with zeros.\n",
    "        The default is to use the fft-size as a window size.\n",
    "    :return: Single channel complex STFT signal\n",
    "    :return: Single channel time signal.\n",
    "    \"\"\"\n",
    "    assert stft_signal.shape[1] == size // 2 + 1\n",
    "\n",
    "    if window_length is None:\n",
    "        window = window(size)\n",
    "    else:\n",
    "        window = window(window_length)\n",
    "        window = np.pad(window, (0, size - window_length), mode='constant')\n",
    "\n",
    "    window = _biorthogonal_window_loopy(window, shift)\n",
    "\n",
    "    # Why? Line created by Hai, Lukas does not know, why it exists.\n",
    "    window *= size\n",
    "    time_signal = scipy.zeros(stft_signal.shape[0] * shift + size - shift)\n",
    "\n",
    "    for j, i in enumerate(range(0, len(time_signal) - size + shift, shift)):\n",
    "        time_signal[i:i + size] += window * np.real(irfft(stft_signal[j]))\n",
    "\n",
    "    # Compensate fade-in and fade-out\n",
    "    if fading:\n",
    "        time_signal = time_signal[size - shift:len(time_signal) - (size - shift)]\n",
    "\n",
    "    return time_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "detailed-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audiowrite(data, path, samplerate=16000, normalize=False, threaded=True):\n",
    "    \"\"\" Write the audio data ``data`` to the wav file ``path``\n",
    "    The file can be written in a threaded mode. In this case, the writing\n",
    "    process will be started at a separate thread. Consequently, the file will\n",
    "    not be written when this function exits.\n",
    "    :param data: A numpy array with the audio data\n",
    "    :param path: The wav file the data should be written to\n",
    "    :param samplerate: Samplerate of the audio data\n",
    "    :param normalize: Normalize the audio first so that the values are within\n",
    "        the range of [INTMIN, INTMAX]. E.g. no clipping occurs\n",
    "    :param threaded: If true, the write process will be started as a separate\n",
    "        thread\n",
    "    :return: The number of clipped samples\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    int16_max = np.iinfo(np.int16).max\n",
    "    int16_min = np.iinfo(np.int16).min\n",
    "\n",
    "    if normalize:\n",
    "        if not data.dtype.kind == 'f':\n",
    "            data = data.astype(np.float)\n",
    "        data /= np.max(np.abs(data))\n",
    "\n",
    "    if data.dtype.kind == 'f':\n",
    "        data *= int16_max\n",
    "\n",
    "    sample_to_clip = np.sum(data > int16_max)\n",
    "    if sample_to_clip > 0:\n",
    "        print('Warning, clipping {} samples'.format(sample_to_clip))\n",
    "    data = np.clip(data, int16_min, int16_max)\n",
    "    data = data.astype(np.int16)\n",
    "\n",
    "    if threaded:\n",
    "        threading.Thread(target=wav_write, args=(path, samplerate, data)).start()\n",
    "    else:\n",
    "        wav_write(path, samplerate, data)\n",
    "\n",
    "    return sample_to_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "textile-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\moon\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6236: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  _ctx, \"Mul\", name, x, y)\n",
      "c:\\users\\moon\\anaconda3\\envs\\study\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: scipy.zeros is deprecated and will be removed in SciPy 2.0.0, use numpy.zeros instead\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model_path = './CKPT/CKP_ep_2__loss_411.15891_.h5'\n",
    "    model = load_model(model_path, custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "\n",
    "    cnt = 0\n",
    "    check = 0\n",
    "    for batch in test_dataset:\n",
    "        input_batch, angle_batch, label_batch, name = batch\n",
    "        tf.executing_eagerly() # requires r1.7\n",
    "        angle_numpy = tf.constant(angle_batch)\n",
    "        angle_numpy = angle_numpy.numpy()\n",
    "\n",
    "        result = model.predict(input_batch)\n",
    "        label1 = tf.slice(result, [0, 0, 0], [-1, -1, OUTPUT_SIZE])\n",
    "        label2 = tf.slice(result, [0, 0, OUTPUT_SIZE], [-1, -1, -1])\n",
    "        spec1 = label1 * np.exp(angle_numpy * 1j)\n",
    "        spec2 = label2 * np.exp(angle_numpy * 1j)\n",
    "\n",
    "        num = cnt * BATCH_SIZE\n",
    "        for i in range(BATCH_SIZE):\n",
    "            if i >= input_batch.shape[0]:\n",
    "                check = -1\n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                wav_name = name[i][0].numpy().decode('utf-8')\n",
    "\n",
    "                wav_name1 = './test_wav/' + wav_name + '_s1.wav'\n",
    "                wav_name2 = './test_wav/' + wav_name + '_s2.wav'\n",
    "                wav1 = istft(spec1[i, 0:input_batch[i].shape[0], :], size=window_size, shift=window_shift)\n",
    "                wav2 = istft(spec2[i, 0:input_batch[i].shape[0], :], size=window_size, shift=window_shift)\n",
    "                audiowrite(wav1, wav_name1, sample_rate, True, True)\n",
    "                audiowrite(wav2, wav_name2, sample_rate, True, True)\n",
    "        \n",
    "        if check == -1:\n",
    "            break\n",
    "\n",
    "        if (cnt + 1) % 10 == 0:\n",
    "            print((cnt + 1) * BATCH_SIZE)\n",
    "\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-africa",
   "metadata": {},
   "source": [
    "- 원본(ref)과 모델을 통해 만들어진 파일(est)을 SI-SDR SDR과 같이 정확도를 비교한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "natural-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "agreed-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir = './mycode/wsj0_2mix/use_this/'\n",
    "test_dir = './test_wav/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "liable-arrangement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SI-SDR (db) : -7.791285775601864\n",
      "The SDR (db) : -2.3582835316785915\n"
     ]
    }
   ],
   "source": [
    "si_sdr = evaluate_metrics.eval_si_sdr(wav_dir, test_dir)\n",
    "sdr = evaluate_metrics.eval_sdr(wav_dir, test_dir)\n",
    "\n",
    "print(\"The SI-SDR (db) :\", si_sdr)\n",
    "print(\"The SDR (db) :\", sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-naples",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
