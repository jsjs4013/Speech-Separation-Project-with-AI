{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increased-imperial",
   "metadata": {},
   "source": [
    "# Make wav list\n",
    "- 파일을 tr, cv, tt 폴더별로 무지성으로 읽어온 다음 각 폴더별 list를 .lst 파일로 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sound-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate wav file to .lst done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tr_wav.lst format:\n",
    "...\n",
    "447o030v_0.1232_050c0109_-0.1232.wav\n",
    "447o030v_1.7882_444o0310_-1.7882.wav\n",
    "447o030w_0.52605_446o030e_-0.52605.wav\n",
    "447o030w_1.9272_420c0203_-1.9272.wav\n",
    "447o030x_0.03457_441c0209_-0.03457.wav\n",
    "447o030x_0.70879_420o0307_-0.70879.wav\n",
    "447o030x_0.98832_441o0308_-0.98832.wav\n",
    "447o030x_1.4783_422o030p_-1.4783.wav\n",
    "...\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "wav_dir = './mycode/wsj0_2mix/use_this/'\n",
    "list_dir = './mycode/wsj0_2mix/use_this/lists/'\n",
    "\n",
    "wav_dir = wav_dir\n",
    "output_lst = list_dir\n",
    "\n",
    "for folder in ['tr', 'cv', 'tt']:\n",
    "    wav_files = os.listdir(wav_dir + folder + '/mix')\n",
    "    output_lst_files = output_lst + folder + '_wav.lst'\n",
    "    with open(output_lst_files, 'w') as f:\n",
    "        for file in wav_files:\n",
    "            f.write(file + \"\\n\")\n",
    "\n",
    "print(\"Generate wav file to .lst done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-desperate",
   "metadata": {},
   "source": [
    "# Make TFRecord file\n",
    "\n",
    "- 여기서는 위에서 만든 리스트 파일을 가지고 tfrecord data로 변환함\n",
    "- 이 섹션의 맨 아래 블럭의 코드가 본 코드인데, 읽어들인 raw data를 stft하고, stft한거를 입력으로 세팅함\n",
    "- 그리고 mix된 stft data를 통해서 label들을 뽑아내고, 따로 gender값도 읽어들임\n",
    "- 이렇게 얻게된 3개의 값(mix_stft, labels, gender)을 TFRecord 형식으로 저장함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eastern-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import argparse\n",
    "import os, sys\n",
    "from numpy.fft import rfft, irfft\n",
    "from scipy.io.wavfile import write as wav_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "severe-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    \"\"\" Creates a path recursively without throwing an error if it already exists\n",
    "    :param path: path to create\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entitled-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_axis(a, length, overlap=0, axis=None, end='cut', endvalue=0):\n",
    "    \"\"\"Generate a new array that chops the given array along the given axis into overlapping frames.\n",
    "    example:\n",
    "    >>> segment_axis(np.arange(10), 4, 2)\n",
    "    array([[0, 1, 2, 3],\n",
    "           [2, 3, 4, 5],\n",
    "           [4, 5, 6, 7],\n",
    "           [6, 7, 8, 9]])\n",
    "    arguments:\n",
    "    a       The array to segment\n",
    "    length  The length of each frame\n",
    "    overlap The number of array elements by which the frames should overlap\n",
    "    axis    The axis to operate on; if None, act on the flattened array\n",
    "    end     What to do with the last frame, if the array is not evenly\n",
    "            divisible into pieces. Options are:\n",
    "            'cut'   Simply discard the extra values\n",
    "            'wrap'  Copy values from the beginning of the array\n",
    "            'pad'   Pad with a constant value\n",
    "    endvalue    The value to use for end='pad'\n",
    "    The array is not copied unless necessary (either because it is\n",
    "    unevenly strided and being flattened or because end is set to\n",
    "    'pad' or 'wrap').\n",
    "    \"\"\"\n",
    "\n",
    "    if axis is None:\n",
    "        a = np.ravel(a)  # may copy\n",
    "        axis = 0\n",
    "\n",
    "    l = a.shape[axis]\n",
    "\n",
    "    if overlap >= length: raise ValueError(\n",
    "        \"frames cannot overlap by more than 100%\")\n",
    "    if overlap < 0 or length <= 0: raise ValueError(\n",
    "        \"overlap must be nonnegative and length must be positive\")\n",
    "\n",
    "    if l < length or (l - length) % (length - overlap):\n",
    "        if l > length:\n",
    "            roundup = length + (1 + (l - length) // (length - overlap)) * (\n",
    "                    length - overlap)\n",
    "            rounddown = length + ((l - length) // (length - overlap)) * (\n",
    "                    length - overlap)\n",
    "        else:\n",
    "            roundup = length\n",
    "            rounddown = 0\n",
    "        assert rounddown < l < roundup\n",
    "        assert roundup == rounddown + (length - overlap) or (\n",
    "                roundup == length and rounddown == 0)\n",
    "        a = a.swapaxes(-1, axis)\n",
    "\n",
    "        if end == 'cut':\n",
    "            a = a[..., :rounddown]\n",
    "        elif end in ['pad', 'wrap']:  # copying will be necessary\n",
    "            s = list(a.shape)\n",
    "            s[-1] = roundup\n",
    "            b = np.empty(s, dtype=a.dtype)\n",
    "            b[..., :l] = a\n",
    "            if end == 'pad':\n",
    "                b[..., l:] = endvalue\n",
    "            elif end == 'wrap':\n",
    "                b[..., l:] = a[..., :roundup - l]\n",
    "            a = b\n",
    "\n",
    "        a = a.swapaxes(-1, axis)\n",
    "\n",
    "    l = a.shape[axis]\n",
    "    if l == 0: raise ValueError(\n",
    "        \"Not enough data points to segment array in 'cut' mode; try 'pad' or 'wrap'\")\n",
    "    assert l >= length\n",
    "    assert (l - length) % (length - overlap) == 0\n",
    "    n = 1 + (l - length) // (length - overlap)\n",
    "    s = a.strides[axis]\n",
    "    newshape = a.shape[:axis] + (n, length) + a.shape[axis + 1:]\n",
    "    newstrides = a.strides[:axis] + ((length - overlap) * s, s) + a.strides[axis + 1:]\n",
    "\n",
    "    if not a.flags.contiguous:\n",
    "        a = a.copy()\n",
    "        newstrides = a.strides[:axis] + ((length - overlap) * s, s) + a.strides[axis + 1:]\n",
    "        return np.ndarray.__new__(np.ndarray, strides=newstrides, shape=newshape, buffer=a, dtype=a.dtype)\n",
    "\n",
    "    try:\n",
    "        return np.ndarray.__new__(np.ndarray, strides=newstrides, shape=newshape, buffer=a, dtype=a.dtype)\n",
    "    except TypeError or ValueError:\n",
    "        warnings.warn(\"Problem with ndarray creation forces copy.\")\n",
    "        a = a.copy()\n",
    "        # Shape doesn't change but strides does\n",
    "        newstrides = a.strides[:axis] + ((length - overlap) * s, s) + a.strides[axis + 1:]\n",
    "        return np.ndarray.__new__(np.ndarray, strides=newstrides, shape=newshape, buffer=a, dtype=a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pleased-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _samples_to_stft_frames(samples, size, shift):\n",
    "    \"\"\"\n",
    "    Calculates STFT frames from samples in time domain.\n",
    "    :param samples: Number of samples in time domain.\n",
    "    :param size: FFT size.\n",
    "    :param shift: Hop in samples.\n",
    "    :return: Number of STFT frames.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.ceil((float(samples) - size + shift) / shift).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "occupational-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft_frames_to_samples(frames, size, shift):\n",
    "    \"\"\"\n",
    "    Calculates samples in time domain from STFT frames\n",
    "    :param frames: Number of STFT frames.\n",
    "    :param size: FFT size.\n",
    "    :param shift: Hop in samples.\n",
    "    :return: Number of samples in time domain.\n",
    "    \"\"\"\n",
    "    return frames * shift + size - shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handled-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(time_signal, time_dim=None, size=1024, shift=256,\n",
    "         window=signal.blackman, fading=True, window_length=None):\n",
    "    \"\"\"\n",
    "    Calculates the short time Fourier transformation of a multi channel multi\n",
    "    speaker time signal. It is able to add additional zeros for fade-in and\n",
    "    fade out and should yield an STFT signal which allows perfect\n",
    "    reconstruction.\n",
    "    :param time_signal: multi channel time signal.\n",
    "    :param time_dim: Scalar dim of time.\n",
    "        Default: None means the biggest dimension\n",
    "    :param size: Scalar FFT-size.\n",
    "    :param shift: Scalar FFT-shift. Typically shift is a fraction of size.\n",
    "    :param window: Window function handle.\n",
    "    :param fading: Pads the signal with zeros for better reconstruction.\n",
    "    :param window_length: Sometimes one desires to use a shorter window than\n",
    "        the fft size. In that case, the window is padded with zeros.\n",
    "        The default is to use the fft-size as a window size.\n",
    "    :return: Single channel complex STFT signal\n",
    "        with dimensions frames times size/2+1.\n",
    "    \"\"\"\n",
    "    if time_dim is None:\n",
    "        time_dim = np.argmax(time_signal.shape)\n",
    "\n",
    "    # Pad with zeros to have enough samples for the window function to fade.\n",
    "    if fading:\n",
    "        pad = [(0, 0)] * time_signal.ndim\n",
    "        pad[time_dim] = [size - shift, size - shift]\n",
    "        time_signal = np.pad(time_signal, pad, mode='constant')\n",
    "\n",
    "    # Pad with trailing zeros, to have an integral number of frames.\n",
    "    frames = _samples_to_stft_frames(time_signal.shape[time_dim], size, shift)\n",
    "    samples = _stft_frames_to_samples(frames, size, shift)\n",
    "    pad = [(0, 0)] * time_signal.ndim\n",
    "    pad[time_dim] = [0, samples - time_signal.shape[time_dim]]\n",
    "    time_signal = np.pad(time_signal, pad, mode='constant')\n",
    "    \n",
    "\n",
    "    if window_length is None:\n",
    "        window = window(size)\n",
    "    else:\n",
    "        window = window(window_length)\n",
    "        window = np.pad(window, (0, size - window_length), mode='constant')\n",
    "\n",
    "    time_signal_seg = segment_axis(time_signal, size,\n",
    "                                   size - shift, axis=time_dim)\n",
    "\n",
    "    letters = string.ascii_lowercase\n",
    "    mapping = letters[:time_signal_seg.ndim] + ',' + letters[time_dim + 1] \\\n",
    "              + '->' + letters[:time_signal_seg.ndim]\n",
    "\n",
    "    return rfft(np.einsum(mapping, time_signal_seg, window), axis=time_dim + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baking-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioread(path, offset=0.0, duration=None, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Reads a wav file, converts it to 32 bit float values and reshapes accoring\n",
    "    to the number of channels.\n",
    "    Now, this is a wrapper of librosa with our common defaults.\n",
    "    :param path: Absolute or relative file path to audio file.\n",
    "    :type: String.\n",
    "    :param offset: Begin of loaded audio.\n",
    "    :type: Scalar in seconds.\n",
    "    :param duration: Duration of loaded audio.\n",
    "    :type: Scalar in seconds.\n",
    "    :param sample_rate: Sample rate of audio\n",
    "    :type: scalar in number of samples per second\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    signal = librosa.load(path, sr=sample_rate, mono=False, offset=offset, duration=duration)\n",
    "    \n",
    "    return signal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "yellow-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_raw_tfrecord\\447o0302_0.62948_441c0212_-0.62948.tfrecords\n",
      "74388\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_raw_tfrecord\\447o0302_1.3388_22ho010i_-1.3388.tfrecords\n",
      "56480\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_raw_tfrecord\\447o0302_2.1067_422o030k_-2.1067.tfrecords\n",
      "53242\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tr_raw_tfrecord\\447o0303_0.14144_441c0212_-0.14144.tfrecords\n",
      "48951\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_raw_tfrecord\\447o0302_0.62948_441c0212_-0.62948.tfrecords\n",
      "74388\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_raw_tfrecord\\447o0302_1.3388_22ho010i_-1.3388.tfrecords\n",
      "56480\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_raw_tfrecord\\447o0302_2.1067_422o030k_-2.1067.tfrecords\n",
      "53242\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/cv_raw_tfrecord\\447o0303_0.14144_441c0212_-0.14144.tfrecords\n",
      "48951\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_raw_tfrecord\\447o0302_0.62948_441c0212_-0.62948.tfrecords\n",
      "74388\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_raw_tfrecord\\447o0302_1.3388_22ho010i_-1.3388.tfrecords\n",
      "56480\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_raw_tfrecord\\447o0302_2.1067_422o030k_-2.1067.tfrecords\n",
      "53242\n",
      "INFO:tensorflow:Writing utterance ./mycode/tfrecords/tt_raw_tfrecord\\447o0303_0.14144_441c0212_-0.14144.tfrecords\n",
      "48951\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import librosa.display\n",
    "from math import ceil\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "wav_dir = './mycode/wsj0_2mix/use_this/'\n",
    "list_dir = './mycode/wsj0_2mix/use_this/lists/'\n",
    "tfrecord_dir = './mycode/tfrecords/'\n",
    "gender_list = './wsj0-train-spkrinfo.txt'\n",
    "process_num = 8\n",
    "\n",
    "CASE = 'raw' # mixed or signal or raw\n",
    "\n",
    "mkdir_p(tfrecord_dir) # tfrecord_dir 폴더 만드는 코드\n",
    "sample_rate = 8000\n",
    "window_size = 256\n",
    "window_shift = 128\n",
    "\n",
    "# if gender_list is not '':\n",
    "#     apply_gender_info = True\n",
    "#     gender_dict = {}\n",
    "#     fid = open(gender_list, 'r')\n",
    "#     lines = fid.readlines()\n",
    "#     fid.close()\n",
    "#     for line in lines:\n",
    "#         spk = line.strip('\\n').split(' ')[0]\n",
    "#         gender = line.strip('\\n').split(' ')[1]\n",
    "#         if gender.lower() == 'm':\n",
    "#             gender_dict[spk] = 1\n",
    "#         else:\n",
    "#             gender_dict[spk] = 0\n",
    "\n",
    "\n",
    "def max_length(file, name, mix_or_not):\n",
    "    max_len = 0\n",
    "    \n",
    "    for name in lines:\n",
    "        name = name.strip('\\n')\n",
    "\n",
    "        wav_name = wav_dir + file + '/' + mix_or_not + '/' + name\n",
    "        audio_wav = audioread(wav_name, offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        mix_len = len(audio_wav)\n",
    "\n",
    "        if mix_len > max_len:\n",
    "            max_len = mix_len\n",
    "    \n",
    "    # 초 맞춰주는 부분\n",
    "    max_len = ceil(max_len / sample_rate) * sample_rate\n",
    "    \n",
    "    return max_len\n",
    "\n",
    "\n",
    "def make_sequence_example(inputs, labels, length, name, genders=False):\n",
    "    input_features = [tf.train.Feature(float_list=tf.train.FloatList(value=input_)) for input_ in inputs]\n",
    "    label_features = [tf.train.Feature(float_list=tf.train.FloatList(value=label)) for label in labels]\n",
    "    len_feature = [tf.train.Feature(float_list=tf.train.FloatList(value=[length]))]\n",
    "    name_feature = [tf.train.Feature(bytes_list=tf.train.BytesList(value=[name.encode('utf-8')]))]\n",
    "#     gender_features = [tf.train.Feature(float_list=tf.train.FloatList(value=genders))]\n",
    "    \n",
    "    feature_list = {\n",
    "        'inputs': tf.train.FeatureList(feature=input_features),\n",
    "        'labels': tf.train.FeatureList(feature=label_features),\n",
    "        'length': tf.train.FeatureList(feature=len_feature),\n",
    "        'name' : tf.train.FeatureList(feature=name_feature)\n",
    "#         'genders': tf.train.FeatureList(feature=gender_features)\n",
    "    }\n",
    "    feature_lists = tf.train.FeatureLists(feature_list=feature_list)\n",
    "    \n",
    "    return tf.train.SequenceExample(feature_lists=feature_lists)\n",
    "\n",
    "\n",
    "def gen_feats(wav_name, sample_rate, window_size, window_shift, file, max_len, case='mixed'):\n",
    "    mix_wav_name = wav_dir + file + '/mix/' + wav_name\n",
    "    s1_wav_name  = wav_dir + file + '/s1/' + wav_name\n",
    "    s2_wav_name  = wav_dir + file + '/s2/' + wav_name\n",
    "\n",
    "    # value initiallization\n",
    "    mix_wav = 0\n",
    "    s1_wav = 0\n",
    "    s2_wav = 0\n",
    "    mix_stft = 0\n",
    "    s1_stft = 0\n",
    "    s2_stft = 0\n",
    "    \n",
    "    if case == 'mixed':\n",
    "        # ------- AUDIO READ -------\n",
    "        mix_wav = audioread(mix_wav_name, offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s1_wav  = audioread(s1_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s2_wav  = audioread(s2_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        # --------------------------\n",
    "        \n",
    "        # ------- AUDIO PAD -------\n",
    "        mix_wav_pad = np.pad(mix_wav, (0, max_len - len(mix_wav)), 'constant', constant_values=(0))\n",
    "        s1_wav_pad = np.pad(s1_wav, (0, max_len - len(s1_wav)), 'constant', constant_values=(0))\n",
    "        s2_wav_pad = np.pad(s2_wav, (0, max_len - len(s2_wav)), 'constant', constant_values=(0))\n",
    "        # -------------------------\n",
    "\n",
    "        # ------- STFT -------\n",
    "        mix_stft = stft(mix_wav, time_dim=0, size=window_size, shift=window_shift)\n",
    "        \n",
    "        mix_stft_pad = stft(mix_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        s1_stft_pad = stft(s1_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        s2_stft_pad = stft(s2_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        # --------------------\n",
    "        \n",
    "        part_name = os.path.splitext(wav_name)[0]\n",
    "        tfrecords_name = tfrecord_dir + file + '_tfrecord\\\\' + part_name + '.tfrecords'\n",
    "        \n",
    "        with tf.io.TFRecordWriter(tfrecords_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_name)\n",
    "\n",
    "            mix_abs = np.abs(mix_stft_pad)\n",
    "            mix_angle = np.angle(mix_stft_pad)\n",
    "\n",
    "            s1_abs = np.abs(s1_stft_pad)\n",
    "            s1_angle = np.angle(s1_stft_pad)\n",
    "\n",
    "            s2_abs = np.abs(s2_stft_pad)\n",
    "            s2_angle = np.angle(s2_stft_pad)\n",
    "\n",
    "            inputs = np.concatenate((mix_abs, mix_angle), axis=1)\n",
    "            labels = np.concatenate((s1_abs * np.cos(mix_angle - s1_angle), s2_abs * np.cos(mix_angle - s2_angle)), axis=1)\n",
    "            \n",
    "            ex = make_sequence_example(inputs, labels, mix_stft.shape[0], part_name)\n",
    "            writer.write(ex.SerializeToString())\n",
    "    elif case == 'signal':\n",
    "        # ------- AUDIO READ -------\n",
    "        s1_wav  = audioread(s1_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s2_wav  = audioread(s2_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        # --------------------------\n",
    "        \n",
    "        # ------- AUDIO PAD -------\n",
    "        s1_wav_pad = np.pad(s1_wav, (0, max_len - len(s1_wav)), 'constant', constant_values=(0))\n",
    "        s2_wav_pad = np.pad(s2_wav, (0, max_len - len(s2_wav)), 'constant', constant_values=(0))\n",
    "        # -------------------------\n",
    "        \n",
    "        # ------- STFT -------\n",
    "        s1_stft  = stft(s1_wav,  time_dim=0, size=window_size, shift=window_shift)\n",
    "        s2_stft  = stft(s2_wav,  time_dim=0, size=window_size, shift=window_shift)\n",
    "        \n",
    "        s1_stft_pad = stft(s1_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        s2_stft_pad = stft(s2_wav_pad, time_dim=0, size=window_size, shift=window_shift)\n",
    "        # --------------------\n",
    "        \n",
    "        part_name = os.path.splitext(wav_name)[0]\n",
    "        tfrecords_s1_name = tfrecord_dir + file + '_one_source_tfrecord\\\\' + part_name + '_s1.tfrecords'\n",
    "        tfrecords_s2_name = tfrecord_dir + file + '_one_source_tfrecord\\\\' + part_name + '_s2.tfrecords'\n",
    "        \n",
    "        with tf.io.TFRecordWriter(tfrecords_s1_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_s1_name)\n",
    "            \n",
    "            s1_abs = np.abs(s1_stft_pad)\n",
    "            s1_angle = np.angle(s1_stft_pad)\n",
    "            \n",
    "            ex = make_sequence_example(s1_abs, s1_angle, s1_stft.shape[0], part_name + '_s1')\n",
    "            writer.write(ex.SerializeToString())\n",
    "\n",
    "        with tf.io.TFRecordWriter(tfrecords_s2_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_s2_name)\n",
    "            \n",
    "            s2_abs = np.abs(s2_stft_pad)\n",
    "            s2_angle = np.angle(s2_stft_pad)\n",
    "            \n",
    "            ex = make_sequence_example(s2_abs, s2_angle, s2_stft.shape[0], part_name + '_s2')\n",
    "            writer.write(ex.SerializeToString())\n",
    "    else:\n",
    "        # ------- AUDIO READ -------\n",
    "        mix_wav = audioread(mix_wav_name, offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s1_wav  = audioread(s1_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        s2_wav  = audioread(s2_wav_name,  offset=0.0, duration=None, sample_rate=sample_rate)\n",
    "        # --------------------------\n",
    "        \n",
    "        part_name = os.path.splitext(wav_name)[0]\n",
    "        tfrecords_name = tfrecord_dir + file + '_raw_tfrecord\\\\' + part_name + '.tfrecords'\n",
    "        \n",
    "        with tf.io.TFRecordWriter(tfrecords_name) as writer:\n",
    "            tf.compat.v1.logging.info(\"Writing utterance %s\" %tfrecords_name)\n",
    "\n",
    "            inputs = np.expand_dims(mix_wav, 1)\n",
    "            s1_raw = np.expand_dims(s1_wav, 1)\n",
    "            s2_raw = np.expand_dims(s2_wav, 1)\n",
    "            labels = np.concatenate((s1_raw, s2_raw), axis=1)\n",
    "            print(inputs.shape[0])\n",
    "            \n",
    "            ex = make_sequence_example(inputs, labels, inputs.shape[0], part_name)\n",
    "            writer.write(ex.SerializeToString())\n",
    "\n",
    "\n",
    "# 여기 멀티프로세싱 pool 적용 어케하는지 모르게씀\n",
    "for files in ['tr', 'cv', 'tt']:\n",
    "    max_len = 0\n",
    "    \n",
    "    output_lst_files = list_dir + files + '_wav.lst'\n",
    "    fid = open(output_lst_files, 'r')\n",
    "    lines = fid.readlines()\n",
    "    fid.close()\n",
    "    \n",
    "    \n",
    "    if CASE == 'mixed':\n",
    "        for name in lines:\n",
    "            name = name.strip('\\n')\n",
    "            max_len = max_length(files, name, 'mix')\n",
    "    else:\n",
    "        for name in lines:\n",
    "            name = name.strip('\\n')\n",
    "            max_len1 = max_length(files, name, 's1')\n",
    "            max_len2 = max_length(files, name, 's2')\n",
    "        \n",
    "        if max_len1 >= max_len2:\n",
    "            max_len = max_len1\n",
    "        else:\n",
    "            max_len = max_len2\n",
    "    \n",
    "    \n",
    "    mkdir_p(tfrecord_dir + files + '_tfrecord') # tfrecord_dir 폴더 만드는 코드\n",
    "    mkdir_p(tfrecord_dir + files + '_one_source_tfrecord') # one_source_tfrecord 폴더 만드는 코드\n",
    "    for name in lines:\n",
    "        name = name.strip('\\n')\n",
    "        gen_feats(name, sample_rate, window_size, window_shift, files, max_len, CASE)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-cuisine",
   "metadata": {},
   "source": [
    "# Deep learning part\n",
    "## 1. Data Loader\n",
    "- Data를 시바 읽어오자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dominant-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "urban-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 2\n",
    "INPUT_SIZE = 129\n",
    "OUTPUT_SIZE = 129\n",
    "\n",
    "CASE = 'mixed' # mixed or signal or raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "guilty-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "if CASE == 'mixed':\n",
    "    tr_path = './mycode/tfrecords/tr_tfrecord/*.tfrecords'\n",
    "    val_path = './mycode/tfrecords/cv_tfrecord/*.tfrecords'\n",
    "    tt_path = './mycode/tfrecords/tt_tfrecord/*.tfrecords'\n",
    "elif CASE == 'signal':\n",
    "    tr_path = './mycode/tfrecords/tr_one_source_tfrecord/*.tfrecords'\n",
    "    val_path = './mycode/tfrecords/cv_one_source_tfrecord/*.tfrecords'\n",
    "    tt_path = './mycode/tfrecords/tt_one_source_tfrecord/*.tfrecords'\n",
    "else:\n",
    "    tr_path = './mycode/tfrecords/tr_raw_tfrecord/*.tfrecords'\n",
    "    val_path = './mycode/tfrecords/cv_raw_tfrecord/*.tfrecords'\n",
    "    tt_path = './mycode/tfrecords/tt_raw_tfrecord/*.tfrecords'\n",
    "\n",
    "FILENAMES_TRAINING = tf.io.gfile.glob(tr_path)\n",
    "FILENAMES_VALIDATION = tf.io.gfile.glob(val_path)\n",
    "FILENAMES_TEST = tf.io.gfile.glob(tt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "satellite-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFRecord Files: 4\n",
      "Validation TFRecord Files: 4\n",
      "Test TFRecord Files: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0302_0.62948_441c0212_-0.62948.tfrecords',\n",
       " '.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0302_1.3388_22ho010i_-1.3388.tfrecords',\n",
       " '.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0302_2.1067_422o030k_-2.1067.tfrecords',\n",
       " '.\\\\mycode\\\\tfrecords\\\\tt_tfrecord\\\\447o0303_0.14144_441c0212_-0.14144.tfrecords']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train TFRecord Files:\", len(FILENAMES_TRAINING))\n",
    "print(\"Validation TFRecord Files:\", len(FILENAMES_VALIDATION))\n",
    "print(\"Test TFRecord Files:\", len(FILENAMES_TEST))\n",
    "FILENAMES_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "economic-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data, check, input_size=129*2, output_size=129*2):\n",
    "    if check == 'inputs':\n",
    "        inputs = tf.slice(data, [0, 0], [-1, input_size//2])\n",
    "        angle = tf.slice(data, [0, input_size//2], [-1, -1])\n",
    "        \n",
    "        return inputs, angle\n",
    "    \n",
    "    elif check == 'labels':\n",
    "        label1 = tf.slice(data, [0, 0], [-1, output_size//2])\n",
    "        label2 = tf.slice(data, [0, output_size//2], [-1, -1])\n",
    "        \n",
    "        return label1, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "historic-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example, input_size=129*2, output_size=129*2, case='mixed'):\n",
    "    if case == 'raw':\n",
    "        tfrecord_format = (\n",
    "            {\n",
    "                'inputs': tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32),\n",
    "                'labels': tf.io.FixedLenSequenceFeature(shape=[2], dtype=tf.float32),\n",
    "                'length': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32),\n",
    "                'name': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.string),\n",
    "    #             'genders': tf.io.FixedLenSequenceFeature(shape=[2], dtype=tf.float32, allow_missing=True)\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        tfrecord_format = (\n",
    "            {\n",
    "                'inputs': tf.io.FixedLenSequenceFeature(shape=[input_size], dtype=tf.float32),\n",
    "                'labels': tf.io.FixedLenSequenceFeature(shape=[output_size], dtype=tf.float32),\n",
    "                'length': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32),\n",
    "                'name': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.string),\n",
    "    #             'genders': tf.io.FixedLenSequenceFeature(shape=[2], dtype=tf.float32, allow_missing=True)\n",
    "            }\n",
    "        )\n",
    "    _, example = tf.io.parse_single_sequence_example(example, sequence_features=tfrecord_format)\n",
    "    \n",
    "    if case == 'mixed':\n",
    "        inputs, angle = data_preprocessing(example[\"inputs\"], 'inputs', input_size)\n",
    "    #     label1, label2 = data_preprocessing(example[\"labels\"], 'labels', input_size)\n",
    "\n",
    "        tiled = tf.tile(tf.expand_dims(example['length'], 1), [1, output_size])\n",
    "        \n",
    "        # 여기가 변경된 부분(length와 label을 concat 함)\n",
    "        return inputs, tf.concat([example['labels'], tiled], 0)\n",
    "#         return inputs, example['labels']\n",
    "    \n",
    "    elif case == 'raw':\n",
    "        tiled = tf.tile(tf.expand_dims(example['length'], 1), [1, 2])\n",
    "        \n",
    "        return example['inputs'], tf.concat([example['labels'], tiled], 0), example['length']\n",
    "    \n",
    "    else:\n",
    "        return example['inputs'], example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "gross-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord_test(example, input_size=129*2, output_size=129*2, case='mixed'):\n",
    "    tfrecord_format = (\n",
    "        {\n",
    "            'inputs': tf.io.FixedLenSequenceFeature(shape=[input_size], dtype=tf.float32),\n",
    "            'labels': tf.io.FixedLenSequenceFeature(shape=[output_size], dtype=tf.float32),\n",
    "            'length': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32),\n",
    "            'name': tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.string),\n",
    "#             'genders': tf.io.FixedLenSequenceFeature(shape=[2], dtype=tf.float32, allow_missing=True)\n",
    "        }\n",
    "    )\n",
    "    _, example = tf.io.parse_single_sequence_example(example, sequence_features=tfrecord_format)\n",
    "    \n",
    "    if case == 'mixed':\n",
    "        inputs, angle = data_preprocessing(example[\"inputs\"], 'inputs', input_size)\n",
    "\n",
    "        return inputs, angle, example['labels'], example['name']\n",
    "    \n",
    "    else:\n",
    "        return example['inputs'], example['labels'], example['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "agricultural-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, input_size=129*2, output_size=129*2, check='train', case='mixed'):\n",
    "    ignore_order = tf.data.Options()\n",
    "    \n",
    "    if check == 'train':\n",
    "        ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    else:\n",
    "        ignore_order.experimental_deterministic = True\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        filenames\n",
    "    )  # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(\n",
    "        ignore_order\n",
    "    )  # uses data as soon as it streams in, rather than in its original order\n",
    "    \n",
    "    if check == 'train':\n",
    "        if case == 'mixed':\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord, input_size=input_size, output_size=output_size), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord, input_size=input_size//2, output_size=output_size//2, case=case), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "    else:\n",
    "        if case == 'mixed':\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord_test, input_size=input_size, output_size=output_size), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset.map(\n",
    "                partial(read_tfrecord_test, input_size=input_size//2, output_size=output_size//2, case=case), num_parallel_calls=AUTOTUNE\n",
    "            )\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interracial-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames, input_size=129*2, output_size=129*2):\n",
    "    dataset = load_dataset(filenames, input_size, output_size, case=CASE)\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "#     dataset = dataset.padded_batch(BATCH_SIZE, padded_shapes=(None))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "essential-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_for_test(filenames, input_size=129*2, output_size=129*2):\n",
    "    dataset = load_dataset(filenames, input_size, output_size, check='test', case=CASE)\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "#     dataset = dataset.padded_batch(BATCH_SIZE, padded_shapes=(None))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comprehensive-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(FILENAMES_TRAINING, INPUT_SIZE*2, OUTPUT_SIZE*2)\n",
    "valid_dataset = get_dataset(FILENAMES_VALIDATION, INPUT_SIZE*2, OUTPUT_SIZE*2)\n",
    "\n",
    "test_dataset = get_dataset_for_test(FILENAMES_TEST, INPUT_SIZE*2, OUTPUT_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accessory-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 626, 129)\n",
      "(2, 627, 258)\n"
     ]
    }
   ],
   "source": [
    "a, b = next(iter(train_dataset))\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-grenada",
   "metadata": {},
   "source": [
    "## 2. Building model\n",
    "\n",
    "- 이제 우리 모델을 시바 개쩔게 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surface-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, sys, os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, LSTM, Concatenate, Multiply, Bidirectional, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sunrise-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./CKPT/') # model check point 폴더 만드는 코드\n",
    "filepath = \"./CKPT/CKP_ep_{epoch:d}__loss_{val_loss:.5f}_.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "painful-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "\n",
    "# learning rate를 점점 줄이는 부분\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# validation loss에 대해서 좋은 것만 저장됨\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
    ")\n",
    "\n",
    "# early stop 하는 부분인데, validation loss에 대해서 제일 좋은 모델이 저장됨\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "qualified-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom PIT loss\n",
    "\n",
    "# def pit_with_outputsize(output_size):\n",
    "#     def pit_loss(y_true, y_pred):\n",
    "#         ori_length = tf.shape(y_true)[1]\n",
    "        \n",
    "#         # Label & Length divide\n",
    "#         labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 129]\n",
    "#         lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "        \n",
    "#         # Label value slice\n",
    "#         labels1 = tf.slice(labels, [0, 0, 0], [-1, -1, output_size])\n",
    "#         labels2 = tf.slice(labels, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "#         # Predict value slice\n",
    "#         pred1 = tf.slice(y_pred, [0, 0, 0], [-1, -1, output_size])\n",
    "#         pred2 = tf.slice(y_pred, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "#         # Permute calculate\n",
    "#         cost1 = tf.reduce_mean(tf.reduce_sum(tf.pow(pred1 - labels1, 2), 1) + tf.reduce_sum(tf.pow(pred2 - labels2, 2), 1), 1)\n",
    "#         cost2 = tf.reduce_mean(tf.reduce_sum(tf.pow(pred2 - labels1, 2), 1) + tf.reduce_sum(tf.pow(pred1 - labels2, 2), 1), 1)\n",
    "\n",
    "#         idx = tf.cast(cost1 > cost2, tf.float32) \n",
    "#         pit_loss = tf.reduce_sum(idx * cost2 + (1 - idx) * cost1)\n",
    "        \n",
    "#         return pit_loss\n",
    "    \n",
    "#     return pit_loss\n",
    "\n",
    "def pit_with_outputsize(output_size):\n",
    "    def pit_loss(y_true, y_pred):\n",
    "        ori_length = tf.shape(y_true)[1]\n",
    "\n",
    "        # Label & Length divide\n",
    "        labels = tf.slice(y_true, [0, 0, 0], [-1, ori_length-1, -1]) # [batch_size, length_size, 129]\n",
    "        lengths = tf.slice(y_true, [0, ori_length-1, 0], [-1, -1, 1]) # [batch_size, 1, 1]\n",
    "\n",
    "        mask = tf.cast(tf.sequence_mask(tf.squeeze(lengths), tf.shape(y_pred)[1]), tf.float32)\n",
    "        mask = tf.expand_dims(mask, axis=-1)\n",
    "        mask = tf.tile(mask, [1, 1, output_size])\n",
    "        print(tf.shape(mask))\n",
    "\n",
    "        # Label value slice\n",
    "        labels1 = tf.slice(labels, [0, 0, 0], [-1, -1, output_size])\n",
    "        labels2 = tf.slice(labels, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "        # Predict value slice\n",
    "        pred1 = tf.slice(y_pred, [0, 0, 0], [-1, -1, output_size])\n",
    "        pred2 = tf.slice(y_pred, [0, 0, output_size], [-1, -1, -1])\n",
    "\n",
    "        # Masking\n",
    "        mask_pred1 = pred1 * mask\n",
    "        mask_pred2 = pred2 * mask\n",
    "\n",
    "        # Permute calculate (batch, seqlen, 258) mask = (batch, seq_len)\n",
    "        cost1 = tf.reduce_sum(tf.pow(mask_pred1 - labels1, 2), 1) + tf.reduce_sum(tf.pow(mask_pred2 - labels2, 2), 1)\n",
    "        cost1 = tf.reduce_sum(cost1, 1) / tf.squeeze(lengths)\n",
    "        cost2 = tf.reduce_sum(tf.pow(mask_pred2 - labels1, 2), 1) + tf.reduce_sum(tf.pow(mask_pred1 - labels2, 2), 1)\n",
    "        cost2 = tf.reduce_sum(cost2, 1) / tf.squeeze(lengths)\n",
    "\n",
    "        idx = tf.cast(cost1 > cost2, tf.float32) \n",
    "        pit_loss = tf.reduce_sum(idx * cost2 + (1 - idx) * cost1)\n",
    "\n",
    "        return pit_loss\n",
    "        \n",
    "    return pit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "colonial-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model\n",
    "\n",
    "def uPIT(input_size, output_size, batch):\n",
    "    inputs = Input(shape=(None, input_size))\n",
    "    \n",
    "    outputs = Dense(496, activation = 'tanh')(inputs)\n",
    "    \n",
    "    outputs = Bidirectional(LSTM(496, activation = 'tanh', return_sequences=True),\n",
    "                           input_shape=(None, 496,))(outputs)\n",
    "    drop = Dropout(rate=0.8)(outputs)\n",
    "    outputs = Bidirectional(LSTM(496, activation = 'tanh', return_sequences=True))(drop)\n",
    "    drop = Dropout(rate=0.8)(outputs)\n",
    "    outputs = Bidirectional(LSTM(496, activation = 'tanh', return_sequences=True))(drop)\n",
    "    drop = Dropout(rate=0.8)(outputs)\n",
    "    \n",
    "#     pred = Dense(output_size * 2, activation='relu')(drop)\n",
    "#     input_concat = Concatenate(axis=-1)([inputs, inputs])\n",
    "#     cleaned = Multiply()([pred, input_concat])\n",
    "#     model = cleaned\n",
    "    \n",
    "    pred1 = Dense(output_size, activation = 'relu')(drop)\n",
    "    pred2 = Dense(output_size, activation = 'relu')(drop)\n",
    "    \n",
    "    cleaned1 = Multiply()([pred1, inputs])\n",
    "    cleaned2 = Multiply()([pred2, inputs])\n",
    "    \n",
    "    model = Concatenate()([cleaned1, cleaned2])\n",
    "    \n",
    "    model = keras.Model(inputs, model)\n",
    "    \n",
    "    model.summary()\n",
    "    adam = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(loss=pit_with_outputsize(output_size), optimizer=adam)\n",
    "#     model.compile(loss=keras.losses.mean_squared_error, optimizer=adam)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-jumping",
   "metadata": {},
   "source": [
    "## 3. Training model\n",
    "- 구축한 모델을 기반으로 딥러닝 학습을 진행하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dress-issue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "장치의 수: 1\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 129)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 496)    64480       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 992)    3940224     dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 992)    0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 992)    5908352     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 992)    0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 992)    5908352     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 992)    0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 129)    128097      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 129)    128097      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, 129)    0           dense_3[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, None, 129)    0           dense_4[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 258)    0           multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 16,077,602\n",
      "Trainable params: 16,077,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "Tensor(\"pit_loss/Shape_2:0\", shape=(3,), dtype=int32, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "Tensor(\"pit_loss/Shape_2:0\", shape=(3,), dtype=int32, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "      2/Unknown - 35s 14s/step - loss: 151.2498Tensor(\"pit_loss/Shape_2:0\", shape=(3,), dtype=int32, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "2/2 [==============================] - 39s 18s/step - loss: 151.2498 - val_loss: 138.3128\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 48.67014\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 30s 17s/step - loss: 137.3984 - val_loss: 110.2960\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 48.67014\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 30s 16s/step - loss: 127.7943 - val_loss: 96.2628\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 48.67014\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 30s 16s/step - loss: 118.8462 - val_loss: 81.9746\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 48.67014\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 31s 17s/step - loss: 108.3693 - val_loss: 73.9465\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 48.67014\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 31s 17s/step - loss: 101.0601 - val_loss: 75.8842\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 48.67014\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 30s 17s/step - loss: 92.5778 - val_loss: 61.4730\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 48.67014\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 29s 16s/step - loss: 84.8272 - val_loss: 55.3531\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 48.67014\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 29s 16s/step - loss: 79.0084 - val_loss: 53.0933\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 48.67014\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 30s 16s/step - loss: 74.3490 - val_loss: 46.7111\n",
      "\n",
      "Epoch 00010: val_loss improved from 48.67014 to 46.71107, saving model to ./CKPT\\CKP_ep_10__loss_46.71107_.h5\n"
     ]
    }
   ],
   "source": [
    "# Training part\n",
    "\n",
    "epoch = 10\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('장치의 수: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    # 사용 안할 때는 load_model 주석 처리 하자\n",
    "#     model = load_model('./CKPT/CKP_ep_29__loss_102.63367_.h5', custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "    \n",
    "    model = uPIT(INPUT_SIZE, OUTPUT_SIZE, BATCH_SIZE)\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_dataset,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-boutique",
   "metadata": {},
   "source": [
    "## 4. Training and validation loss plot\n",
    "- 학습한 모델의 loss값을 그래프로 그려봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "southeast-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training and validation loss graph\n",
    "\n",
    "def graph_util(history):\n",
    "    fig = plt.figure()\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plt.plot(history.history['loss'], c='b')\n",
    "    plt.plot(history.history['val_loss'], c='r')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training loss', 'validation loss'], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "important-disney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_util(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-royal",
   "metadata": {},
   "source": [
    "## 5. Test Model\n",
    "- 학습된 모델을 사용해서 테스트를 진행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "handed-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 8000\n",
    "window_size = 256\n",
    "window_shift = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dramatic-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_p('./test_wav/') # Result wav 폴더 만드는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "attempted-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _biorthogonal_window_loopy(analysis_window, shift):\n",
    "    \"\"\"\n",
    "    This version of the synthesis calculation is as close as possible to the\n",
    "    Matlab impelementation in terms of variable names.\n",
    "    The results are equal.\n",
    "    The implementation follows equation A.92 in\n",
    "    Krueger, A. Modellbasierte Merkmalsverbesserung zur robusten automatischen\n",
    "    Spracherkennung in Gegenwart von Nachhall und Hintergrundstoerungen\n",
    "    Paderborn, Universitaet Paderborn, Diss., 2011, 2011\n",
    "    \"\"\"\n",
    "    fft_size = len(analysis_window)\n",
    "    assert np.mod(fft_size, shift) == 0\n",
    "    number_of_shifts = len(analysis_window) // shift\n",
    "\n",
    "    sum_of_squares = np.zeros(shift)\n",
    "    for synthesis_index in range(0, shift):\n",
    "        for sample_index in range(0, number_of_shifts + 1):\n",
    "            analysis_index = synthesis_index + sample_index * shift\n",
    "\n",
    "            if analysis_index + 1 < fft_size:\n",
    "                sum_of_squares[synthesis_index] \\\n",
    "                    += analysis_window[analysis_index] ** 2\n",
    "\n",
    "    sum_of_squares = np.kron(np.ones(number_of_shifts), sum_of_squares)\n",
    "    synthesis_window = analysis_window / sum_of_squares / fft_size\n",
    "    return synthesis_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "north-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def istft(stft_signal, size=1024, shift=256,\n",
    "          window=signal.blackman, fading=True, window_length=None):\n",
    "    \"\"\"\n",
    "    Calculated the inverse short time Fourier transform to exactly reconstruct\n",
    "    the time signal.\n",
    "    :param stft_signal: Single channel complex STFT signal\n",
    "        with dimensions frames times size/2+1.\n",
    "    :param size: Scalar FFT-size.\n",
    "    :param shift: Scalar FFT-shift. Typically shift is a fraction of size.\n",
    "    :param window: Window function handle.\n",
    "    :param fading: Removes the additional padding, if done during STFT.\n",
    "    :param window_length: Sometimes one desires to use a shorter window than\n",
    "        the fft size. In that case, the window is padded with zeros.\n",
    "        The default is to use the fft-size as a window size.\n",
    "    :return: Single channel complex STFT signal\n",
    "    :return: Single channel time signal.\n",
    "    \"\"\"\n",
    "    assert stft_signal.shape[1] == size // 2 + 1\n",
    "\n",
    "    if window_length is None:\n",
    "        window = window(size)\n",
    "    else:\n",
    "        window = window(window_length)\n",
    "        window = np.pad(window, (0, size - window_length), mode='constant')\n",
    "\n",
    "    window = _biorthogonal_window_loopy(window, shift)\n",
    "\n",
    "    # Why? Line created by Hai, Lukas does not know, why it exists.\n",
    "    window *= size\n",
    "    time_signal = scipy.zeros(stft_signal.shape[0] * shift + size - shift)\n",
    "\n",
    "    for j, i in enumerate(range(0, len(time_signal) - size + shift, shift)):\n",
    "        time_signal[i:i + size] += window * np.real(irfft(stft_signal[j]))\n",
    "\n",
    "    # Compensate fade-in and fade-out\n",
    "    if fading:\n",
    "        time_signal = time_signal[size - shift:len(time_signal) - (size - shift)]\n",
    "\n",
    "    return time_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "detailed-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audiowrite(data, path, samplerate=16000, normalize=False, threaded=True):\n",
    "    \"\"\" Write the audio data ``data`` to the wav file ``path``\n",
    "    The file can be written in a threaded mode. In this case, the writing\n",
    "    process will be started at a separate thread. Consequently, the file will\n",
    "    not be written when this function exits.\n",
    "    :param data: A numpy array with the audio data\n",
    "    :param path: The wav file the data should be written to\n",
    "    :param samplerate: Samplerate of the audio data\n",
    "    :param normalize: Normalize the audio first so that the values are within\n",
    "        the range of [INTMIN, INTMAX]. E.g. no clipping occurs\n",
    "    :param threaded: If true, the write process will be started as a separate\n",
    "        thread\n",
    "    :return: The number of clipped samples\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    int16_max = np.iinfo(np.int16).max\n",
    "    int16_min = np.iinfo(np.int16).min\n",
    "\n",
    "    if normalize:\n",
    "        if not data.dtype.kind == 'f':\n",
    "            data = data.astype(np.float)\n",
    "        data /= np.max(np.abs(data))\n",
    "\n",
    "    if data.dtype.kind == 'f':\n",
    "        data *= int16_max\n",
    "\n",
    "    sample_to_clip = np.sum(data > int16_max)\n",
    "    if sample_to_clip > 0:\n",
    "        print('Warning, clipping {} samples'.format(sample_to_clip))\n",
    "    data = np.clip(data, int16_min, int16_max)\n",
    "    data = data.astype(np.int16)\n",
    "\n",
    "    if threaded:\n",
    "        threading.Thread(target=wav_write, args=(path, samplerate, data)).start()\n",
    "    else:\n",
    "        wav_write(path, samplerate, data)\n",
    "\n",
    "    return sample_to_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "textile-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\moon\\anaconda3\\envs\\study\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: scipy.zeros is deprecated and will be removed in SciPy 2.0.0, use numpy.zeros instead\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model_path = './CKPT/CKP_ep_10__loss_46.71107_.h5'\n",
    "    model = load_model(model_path, custom_objects={'pit_loss': pit_with_outputsize(OUTPUT_SIZE)})\n",
    "\n",
    "    cnt = 0\n",
    "    check = 0\n",
    "    for batch in test_dataset:\n",
    "        input_batch, angle_batch, label_batch, name = batch\n",
    "        tf.executing_eagerly() # requires r1.7\n",
    "        angle_numpy = tf.constant(angle_batch)\n",
    "        angle_numpy = angle_numpy.numpy()\n",
    "\n",
    "        result = model.predict(input_batch)\n",
    "        label1 = tf.slice(result, [0, 0, 0], [-1, -1, OUTPUT_SIZE])\n",
    "        label2 = tf.slice(result, [0, 0, OUTPUT_SIZE], [-1, -1, -1])\n",
    "        spec1 = label1 * np.exp(angle_numpy * 1j)\n",
    "        spec2 = label2 * np.exp(angle_numpy * 1j)\n",
    "\n",
    "        num = cnt * BATCH_SIZE\n",
    "        for i in range(BATCH_SIZE):\n",
    "            if i >= input_batch.shape[0]:\n",
    "                check = -1\n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                wav_name = name[i][0].numpy().decode('utf-8')\n",
    "\n",
    "                wav_name1 = './test_wav/' + wav_name + '_s1.wav'\n",
    "                wav_name2 = './test_wav/' + wav_name + '_s2.wav'\n",
    "                wav1 = istft(spec1[i, 0:input_batch[i].shape[0], :], size=window_size, shift=window_shift)\n",
    "                wav2 = istft(spec2[i, 0:input_batch[i].shape[0], :], size=window_size, shift=window_shift)\n",
    "                audiowrite(wav1, wav_name1, sample_rate, True, True)\n",
    "                audiowrite(wav2, wav_name2, sample_rate, True, True)\n",
    "        \n",
    "        if check == -1:\n",
    "            break\n",
    "\n",
    "        if (cnt + 1) % 10 == 0:\n",
    "            print((cnt + 1) * BATCH_SIZE)\n",
    "\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-africa",
   "metadata": {},
   "source": [
    "- 원본(ref)과 모델을 통해 만들어진 파일(est)을 SI-SDR SDR과 같이 정확도를 비교한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "natural-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "agreed-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir = './mycode/wsj0_2mix/use_this/'\n",
    "test_dir = './test_wav/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "liable-arrangement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SI-SDR (db) : -2.4792105052620173\n",
      "The SDR (db) : -0.1265117783214789\n"
     ]
    }
   ],
   "source": [
    "si_sdr = evaluate_metrics.eval_si_sdr(wav_dir, test_dir)\n",
    "sdr = evaluate_metrics.eval_sdr(wav_dir, test_dir)\n",
    "\n",
    "print(\"The SI-SDR (db) :\", si_sdr)\n",
    "print(\"The SDR (db) :\", sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-naples",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
